<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>egse.dpu API documentation</title>
<meta name="description" content="This module defines the commanding interfaces for the DPU—N-FEE interaction …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>egse.dpu</code></h1>
</header>
<section id="section-intro">
<p>This module defines the commanding interfaces for the DPU—N-FEE interaction.</p>
<p>On the <em>client/user side</em>, the <code><a title="egse.dpu.DPUProxy" href="#egse.dpu.DPUProxy">DPUProxy</a></code> class shall be used for user interactions and commanding with both
the DPU simulator and the N-FEE. This class connects to the DPU control server which must be running before
any commands can be processed.</p>
<p>On the <em>server side</em>, the <code>DPUControlServer</code> class is located in the module <code><a title="egse.dpu.dpu_cs" href="dpu_cs.html">egse.dpu.dpu_cs</a></code>.</p>
<p>The top-level classes that are of interest to the developer when inspecting this module are:</p>
<ul>
<li><code><a title="egse.dpu.DPUController" href="#egse.dpu.DPUController">DPUController</a></code> which puts the requested commands on the command queue for the <code><a title="egse.dpu.DPUProcessor" href="#egse.dpu.DPUProcessor">DPUProcessor</a></code></li>
<li><code><a title="egse.dpu.DPUProcessor" href="#egse.dpu.DPUProcessor">DPUProcessor</a></code> is the work horse of the DPU simulator and runs in a separate process. This process communicates
directly with the N-FEE through the SpaceWire interface.</li>
<li><code><a title="egse.dpu.DPUInternals" href="#egse.dpu.DPUInternals">DPUInternals</a></code> keeps critical information about the DPU and provides information on the status of the
readout progress, i.e. where we are in the readout cycle.</li>
<li><code><a title="egse.dpu.DPUMonitoring" href="#egse.dpu.DPUMonitoring">DPUMonitoring</a></code> provides methods to run a function at a certain time, e.g. right after a long pulse, or to wait
for an event, e.g. when an HDF5 file is ready for processing.</li>
</ul>
<p>The actual commanding is done in <code><a title="egse.dpu.dpu" href="dpu.html">egse.dpu.dpu</a></code> module. That module also defines the <code>NFEEState</code> which acts as a
mirror of the FPGA status.</p>
<p>This module also defines a number of functions, but they all are for internal use and are not of any interest
unless you are maintaining this module.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module defines the commanding interfaces for the DPU—N-FEE interaction.


On the *client/user side*, the `DPUProxy` class shall be used for user interactions and commanding with both
the DPU simulator and the N-FEE. This class connects to the DPU control server which must be running before
any commands can be processed.

On the *server side*, the `DPUControlServer` class is located in the module `dpu_cs`.

The top-level classes that are of interest to the developer when inspecting this module are:

* `DPUController` which puts the requested commands on the command queue for the `DPUProcessor`
* `DPUProcessor` is the work horse of the DPU simulator and runs in a separate process. This process communicates
  directly with the N-FEE through the SpaceWire interface.
* `DPUInternals` keeps critical information about the DPU and provides information on the status of the
  readout progress, i.e. where we are in the readout cycle.
* `DPUMonitoring` provides methods to run a function at a certain time, e.g. right after a long pulse, or to wait
  for an event, e.g. when an HDF5 file is ready for processing.

The actual commanding is done in `dpu` module. That module also defines the `NFEEState` which acts as a
mirror of the FPGA status.

This module also defines a number of functions, but they all are for internal use and are not of any interest
unless you are maintaining this module.

&#34;&#34;&#34;

import logging
import multiprocessing
import pickle
import queue
from enum import Enum

import time
import traceback
from dataclasses import dataclass
from pathlib import Path
from typing import Any
from typing import Callable
from typing import Dict
from typing import List
from typing import Mapping
from typing import Tuple
from typing import Type

import zmq

from egse.command import ClientServerCommand
from egse.confman import ConfigurationManagerProxy
from egse.control import ControlServer
from egse.decorators import dynamic_interface
from egse.dpu.dpu import NFEEState, command_set_nfee_fpga_defaults
from egse.dpu.dpu import command_external_clock
from egse.dpu.dpu import command_get_mode
from egse.dpu.dpu import command_internal_clock
from egse.dpu.dpu import command_reset
from egse.dpu.dpu import command_set_charge_injection
from egse.dpu.dpu import command_set_clear_error_flags
from egse.dpu.dpu import command_set_dump_mode
from egse.dpu.dpu import command_set_dump_mode_int_sync
from egse.dpu.dpu import command_set_full_image_mode
from egse.dpu.dpu import command_set_full_image_mode_int_sync
from egse.dpu.dpu import command_set_full_image_pattern_mode
from egse.dpu.dpu import command_set_high_precision_hk_mode
from egse.dpu.dpu import command_set_immediate_on_mode
from egse.dpu.dpu import command_set_on_mode
from egse.dpu.dpu import command_set_register_value
from egse.dpu.dpu import command_set_reverse_clocking
from egse.dpu.dpu import command_set_standby_mode
from egse.dpu.dpu import command_set_vgd
from egse.dpu.dpu import command_sync_register_map
from egse.dpu.dpu import prio_command_get_mode
from egse.dpu.dpu import prio_command_get_register_map
from egse.dpu.dpu import prio_command_get_slicing
from egse.dpu.dpu import prio_command_get_sync_mode
from egse.dpu.dpu import prio_command_is_dump_mode
from egse.dpu.dpu import prio_command_set_slicing
from egse.dsi.esl import is_timecode
from egse.exceptions import Abort
from egse.fee import is_hk_data_packet
from egse.fee import n_fee_mode
from egse.obsid import ObservationIdentifier
from egse.protocol import CommandProtocol
from egse.proxy import Proxy
from egse.reg import RegisterMap
from egse.settings import Settings
from egse.setup import SetupError
from egse.spw import DataDataPacket
from egse.spw import DataPacket
from egse.spw import DataPacketType
from egse.spw import HousekeepingPacket
from egse.spw import OverscanDataPacket
from egse.spw import SpaceWireInterface
from egse.spw import SpaceWirePacket
from egse.spw import TimecodePacket
from egse.spw import to_string
from egse.state import GlobalState
from egse.storage import StorageProxy
from egse.storage.persistence import FITS
from egse.storage.persistence import HDF5
from egse.storage.persistence import PersistenceLayer
from egse.system import SignalCatcher
from egse.system import Timer
from egse.system import format_datetime
from egse.system import wait_until
from egse.zmq import MessageIdentifier
from egse.zmq_ser import bind_address
from egse.zmq_ser import connect_address

LOGGER = logging.getLogger(__name__)

CTRL_SETTINGS = Settings.load(&#34;DPU Control Server&#34;)
N_FEE_SETTINGS = Settings.load(&#34;N-FEE&#34;)
COMMAND_SETTINGS = Settings.load(filename=&#34;dpu.yaml&#34;)
DEVICE_SETTINGS = Settings.load(filename=&#34;dpu.yaml&#34;)

CRUCIAL_REGISTER_PARAMETERS = (
    &#34;ccd_readout_order&#34;, &#34;sensor_sel&#34;, &#34;v_start&#34;, &#34;v_end&#34;, &#34;h_end&#34;, &#34;ccd_mode_config&#34;
)

DATA_TYPE: Dict[str, Type[PersistenceLayer]] = {
    &#34;HDF5&#34;: HDF5,
    &#34;FITS&#34;: FITS,
}


class NoDataPacketError(Exception):
    &#34;&#34;&#34;Raised when the expected data packet turns out to be something else.&#34;&#34;&#34;
    pass


class NoHousekeepingPacketError(Exception):
    &#34;&#34;&#34;Raised when the expected Housekeeping packet turns out to be something else.&#34;&#34;&#34;
    pass


class NoTimeCodeError(Exception):
    &#34;&#34;&#34;Raised when the expected Timecode packet turns out to be something else.&#34;&#34;&#34;
    pass


class NoBytesReceivedError(Exception):
    &#34;&#34;&#34;Raised when the zero or one bytes were received.&#34;&#34;&#34;
    pass


class TimecodeTimeoutError(Exception):
    &#34;&#34;&#34;Raised when the read_packet times out while waiting for a timecode.&#34;&#34;&#34;
    pass


class TimeExceededError(Exception):
    &#34;&#34;&#34;Raised when retrieving the data packets from the N-FEE takes too long.&#34;&#34;&#34;
    pass


class NFEECommandError(Exception):
    &#34;&#34;&#34;Raised when sending a command to the N-FEE failed.&#34;&#34;&#34;
    pass


class DPUInterface:
    &#34;&#34;&#34;
    This interface is for sending commands to the DPU Control Server. The commands are user
    oriented and will be translated by the DPU Controller in proper FEE commands.

    The interface should be implemented by the `DPUController` and the `DPUProxy` (and possibly
    a `DPUSimulator` should we need that e.g. for testing purposes).

    The command shall also be added to the `dpu.yaml` command definitions file.
    &#34;&#34;&#34;

    @dynamic_interface
    def marker(self, mark: str):
        raise NotImplementedError

    @dynamic_interface
    def get_slicing(self) -&gt; int:
        raise NotImplementedError

    @dynamic_interface
    def set_slicing(self, num_cycles: int):
        raise NotImplementedError

    @dynamic_interface
    def is_simulator(self):
        raise NotImplementedError

    @dynamic_interface
    def get_register_map(self) -&gt; RegisterMap:
        &#34;&#34;&#34;
        Returns the RegisterMap
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_sync_register_map(self):
        &#34;&#34;&#34;
        Read the complete register map from the N-FEE.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_get_mode(self):
        &#34;&#34;&#34;
        Returns the N-FEE mode.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_get_sync_mode(self):
        &#34;&#34;&#34;
        Returns the N-FEE mode.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_on_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_is_dump_mode(self):
        &#34;&#34;&#34;
        Returns True if the N-FEE is configured for DUMP mode.

        DUMP mode is not really an N-FEE mode, but more a set of register settings that allow to
        readout/dump all CCDs without transmitting any data. This mode is used in ambient to make
        sure the detectors do not get saturated between tests.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_immediate_on_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_standby_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into STANDBY mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        &#34;&#34;&#34; Command the N-FEE to go into DUMP mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
             n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_dump_mode_int_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34; Command the N-FEE to go into DUMP mode and internal sync.

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer
            * int_sync_period (int): the period of the internal sync in milliseconds

        Args:
             n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_mode(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE mode and internal sync.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_pattern_mode(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE_PATTERN mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_high_precision_hk_mode(self, n_fee_parameters: dict):
        &#34;&#34;&#34;Command the N-FEE to go into high precision housekeeping mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34;
        Command the N-FEE to go into internal sync mode.

        The method expects the following keys in n_fee_parameters:

        * int_sync_period: the internal sync period in milliseconds [default=6250]

        Args:
            n_fee_parameters (dict): N-FEE parameter dictionary
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_external_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34;
        Command the N-FEE to go into external sync mode.
        No keys are expected in n_fee_parameters, pass an empty dict.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_register_value(self, reg_name: str, field_name: str, field_value: int):
        &#34;&#34;&#34;Command the N-FEE to set a register value.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_reset(self):
        &#34;&#34;&#34;Command the N-FEE to reset to its default settings.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_clear_error_flags(self):
        &#34;&#34;&#34;
        Command the N-FEE to clear all error flags for non RMAP/SpW related functions immediately.

        The `clear_error_flag` bit in the register map is set to 1, meaning that all error flags
        that are generated by the N-FEE FPGA for non RMAP-SpW related functions are cleared
        immediately.  This bit is cleared automatically, so that any future error flags can be
        latched again.  If the error conditions persist and no corrective measures are taken,
        then error flags would be set again.
        &#34;&#34;&#34;

        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):

        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_charge_injection(self, n_fee_parameters: dict):
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_vgd(self, n_fee_parameters: dict):
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_fpga_defaults(self):
        raise NotImplementedError


class DPUSimulator(DPUInterface):
    # The DPUSimulator will stand by itself, which means it will not send commands to an FEE
    # nor will it request data or HK from the FEE. The methods in this implementation will return
    # a fake set of data.

    def n_fee_get_mode(self):
        return n_fee_mode.STAND_BY_MODE

    def n_fee_get_sync_mode(self):
        return NotImplemented

    def n_fee_set_on_mode(self):
        pass

    def n_fee_set_standby_mode(self):
        pass

    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        pass

    def n_fee_set_full_image_mode(self, n_fee_parameters):
        import pprint

        LOGGER.debug(f&#34;called: n_fee_set_full_image_mode({pprint.pformat(n_fee_parameters)})&#34;)

    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters):
        import pprint

        LOGGER.debug(f&#34;called: n_fee_set_full_image_mode_int_sync({pprint.pformat(n_fee_parameters)})&#34;)

    def n_fee_set_full_image_pattern_mode(self):
        pass

    def n_fee_high_precision_hk_mode(self, n_fee_parameters: dict):
        pass

    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        pass

    def n_fee_set_external_sync(self):
        pass

    def n_fee_set_clear_error_flags(self):
        pass

    def n_fee_set_fpga_defaults(self):
        pass


class DPUController(DPUInterface):
    &#34;&#34;&#34;
    The DPU Controller puts commands on the command queue for processing by the DPU Processor.
    Any response from the DPU Processor will be available on the response queue as soon as the
    command has been executed. The DPU Processor is a separate process that is started by the
    DPU Command Protocol.
    &#34;&#34;&#34;

    def __init__(self,
                 priority_queue: multiprocessing.Queue,
                 command_queue: multiprocessing.Queue,
                 response_queue: multiprocessing.Queue):
        self._priority_q = priority_queue
        self._command_q = command_queue
        self._response_q = response_queue

        try:
            self.default_ccd_readout_order = GlobalState.setup.camera.fee.ccd_numbering.DEFAULT_CCD_READOUT_ORDER
            self.sensor_sel_both_sides = GlobalState.setup.camera.fee.sensor_sel.enum.BOTH_SIDES.value
        except AttributeError:
            raise SetupError(&#34;No entry in the setup for camera.fee.ccd_numbering.DEFAULT_CCD_READOUT_ORDER&#34;)

    def marker(self, mark: str):
        LOGGER.info(f&#34;{mark = }&#34;)

    def get_slicing(self) -&gt; int:
        self._priority_q.put((prio_command_get_slicing, []))
        LOGGER.debug(&#34;Controller.get_slicing: Put prio_command_get_slicing on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.get_slicing returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def set_slicing(self, num_cycles: int):
        self._priority_q.put((prio_command_set_slicing, [num_cycles]))
        LOGGER.debug(
            &#34;Controller.set_slicing: Put prio_command_set_slicing on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.set_slicing returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def is_simulator(self):
        return True

    def n_fee_sync_register_map(self) -&gt; RegisterMap:
        self._command_q.put((command_sync_register_map, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_sync_register_map: Put command_sync_register_map on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_sync_register_map returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def get_register_map(self) -&gt; RegisterMap:
        self._priority_q.put((prio_command_get_register_map, []))
        LOGGER.debug(&#34;Controller.get_register_map: Put prio_command_get_register_map on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.get_register_map returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_get_mode(self):
        self._priority_q.put((prio_command_get_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_get_mode: Put prio_command_get_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_get_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_get_sync_mode(self):
        self._priority_q.put((prio_command_get_sync_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_get_sync_mode: Put prio_command_get_sync_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_get_sync_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_is_dump_mode(self):
        self._priority_q.put((prio_command_is_dump_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_is_dump_mode: Put prio_command_is_dump_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_is_dump_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_set_immediate_on_mode(self):
        self._command_q.put((command_set_immediate_on_mode, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_immediate_on_mode: Put command_set_immediate_on_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_immediate_on_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_on_mode(self):
        self._command_q.put((command_set_on_mode, [], {}))
        LOGGER.debug(&#34;Controller.n_fee_set_on_mode: Put command_set_on_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_on_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_standby_mode(self):
        self._command_q.put((command_set_standby_mode, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_standby_mode: Put command_set_standby_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_standby_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        sync_sel = n_fee_parameters.get(&#34;sync_sel&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put((command_set_dump_mode,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, sync_sel],
                             {&#39;num_cycles&#39;: num_cycles}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_dump_mode: Put command_set_dump_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_dump_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_dump_mode_int_sync(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        sync_sel = n_fee_parameters.get(&#34;sync_sel&#34;, 1)
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 2500)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put(
            (
                command_set_dump_mode_int_sync,
                [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, int_sync_period, sync_sel],
                {&#39;num_cycles&#39;: num_cycles}
            )
        )
        LOGGER.debug(&#34;Controller.n_fee_set_dump_mode_int_sync: &#34;
                     &#34;Put command_set_dump_mode_int_sync on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_dump_mode_int_sync returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, False)
        self._command_q.put((command_set_full_image_mode,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_mode: Put command_set_full_image_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_full_image_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 6250)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, True)
        self._command_q.put((command_set_full_image_mode_int_sync,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, int_sync_period],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_mode_int_sync: Put command_set_full_image_mode_int_sync on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_full_image_mode_int_sync returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_pattern_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put((command_set_full_image_pattern_mode,
                             [v_start, v_end, sensor_sel_],
                             {&#39;num_cycles&#39;: num_cycles}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_pattern_mode: Put command_set_full_image_pattern_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_full_image_pattern_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_high_precision_hk_mode(self, n_fee_parameters:dict):
        high_hk = n_fee_parameters.get(&#34;high_precision_hk&#34;, False)
        self._command_q.put((command_set_high_precision_hk_mode, [high_hk], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_high_precision_hk_mode: Put command_set_high_precision_hk_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_high_precision_hk_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 6250)
        self._command_q.put((command_internal_clock, [int_sync_period], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_internal_sync: Put command_internal_clock on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_internal_sync returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_external_sync(self, n_fee_parameters: dict):
        self._command_q.put((command_external_clock, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_internal_sync: Put command_internal_clock on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_internal_sync returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_register_value(self, reg_name: str, field_name: str, field_value: int):
        self._command_q.put((command_set_register_value, [reg_name, field_name, field_value], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_register_value: Put command_set_register_value on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_register_value returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_reset(self):
        self._command_q.put((command_reset, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_reset: Put command_reset on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_reset returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_clear_error_flags(self):

        self._command_q.put((command_set_clear_error_flags, [], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_clear_error_flags: &#34;
                     &#34;Put command_set_clear_error_flags on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_clear_error_flags returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        img_clk_dir = n_fee_parameters.get(&#34;img_clk_dir&#34;, 1)
        reg_clk_dir = n_fee_parameters.get(&#34;reg_clk_dir&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, False)

        self._command_q.put((command_set_reverse_clocking,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, img_clk_dir, reg_clk_dir],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_reverse_clocking: Put command_set_reverse_clocking on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_reverse_clocking returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_charge_injection(self, n_fee_parameters: dict):
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        charge_injection_width = n_fee_parameters.get(&#34;charge_injection_width&#34;, 0)
        charge_injection_gap = n_fee_parameters.get(&#34;charge_injection_gap&#34;, 0)

        self._command_q.put(
            (
                command_set_charge_injection,
                [
                    v_start, v_end, n_final_dump, sensor_sel_, ccd_readout_order,
                    charge_injection_width, charge_injection_gap
                ],
                {&#39;num_cycles&#39;: num_cycles}
            ))
        LOGGER.debug(
            &#34;Controller.n_fee_set_dump_mode: Put command_set_charge_injection on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_charge_injection returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_vgd(self, n_fee_parameters: dict):

        # The default value for ccd_vgd_config is 0xCFE = hex(int(19.90/5.983*1000))
        # This value is taken from: PLATO-MSSL-PL-FI-0001_9.0_N-FEE_Register_Map Draft A

        ccd_vgd_config = n_fee_parameters.get(&#34;ccd_vgd_config&#34;, 19.90)

        self._command_q.put((command_set_vgd, [ccd_vgd_config], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_vgd: Put command_set_vgd on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_vgd returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_fpga_defaults(self):
        self._command_q.put((command_set_nfee_fpga_defaults, [], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_fpga_defaults: Put n_fee_set_fpga_defaults on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_fpga_defaults returned: ({cmd.__name__}, {response})&#34;)
        return response


class DPUProxy(Proxy, DPUInterface):
    &#34;&#34;&#34;
    The DPUProxy class is used to connect to the DPU Control Server and send commands to the FEE.
    &#34;&#34;&#34;

    def __init__(
        self,
        protocol=CTRL_SETTINGS.PROTOCOL,
        hostname=CTRL_SETTINGS.HOSTNAME,
        port=CTRL_SETTINGS.COMMANDING_PORT,
    ):
        &#34;&#34;&#34;
        Args:
            protocol: the transport protocol [default is taken from settings file]
            hostname: location of the control server (IP address)
                [default is taken from settings file]
            port: TCP port on which the control server is listening for commands
                [default is taken from settings file]
        &#34;&#34;&#34;
        super().__init__(connect_address(protocol, hostname, port), timeout=10_000)


class DPUCommand(ClientServerCommand):
    pass


class DPUProtocol(CommandProtocol):
    def __init__(self, control_server: ControlServer, transport: SpaceWireInterface):

        super().__init__()

        self.control_server = control_server

        # Set up two queue&#39;s to communicate with the DPU Processor Process.
        # The command queue is joinable because the Controller needs to wait for a response in
        # the response queue.

        self.command_queue = multiprocessing.Queue()
        self.response_queue = multiprocessing.Queue()
        self.priority_queue = multiprocessing.Queue()

        # Start a separate Process to handle FEE communication

        self.processor = DPUProcessor(
            transport, self.priority_queue, self.command_queue, self.response_queue)
        self.processor.name = &#34;dpu.processor&#34;
        self.processor.start()

        self.controller = DPUController(
            self.priority_queue, self.command_queue, self.response_queue)

        self.load_commands(COMMAND_SETTINGS.Commands, DPUCommand, DPUController)

        self.build_device_method_lookup_table(self.controller)

    def get_bind_address(self):
        return bind_address(
            self.control_server.get_communication_protocol(),
            self.control_server.get_commanding_port(),
        )

    def get_status(self) -&gt; dict:
        status = super().get_status()
        status[&#34;DPU Processor&#34;] = &#34;alive&#34; if self.processor.is_alive() else &#34;--&#34;
        return status

    def get_housekeeping(self) -&gt; dict:
        return {
            &#34;timestamp&#34;: format_datetime(),
        }

    def quit(self):
        self.processor.quit()

        def not_alive():
            return not self.processor.is_alive()

        if wait_until(not_alive, timeout=6.5) is False:
            self.processor.join()
            return

        LOGGER.warning(&#34;Terminating DPU Processor&#34;)
        self.processor.terminate()

        # Wait at least 6.25s which is the &#39;normal&#39; readout cycle time

        if wait_until(not_alive, timeout=6.5) is False:
            self.processor.join()
            return

        LOGGER.warning(&#34;Killing DPU Processor&#34;)
        self.processor.kill()
        self.processor.join()

    def is_alive(self) -&gt; bool:
        is_alive = self.processor.is_alive()

        if not is_alive:
            LOGGER.warning(
                f&#34;Process &#39;{self.processor.name}&#39; died for some reason, check for &#34;
                f&#34;an exception in the logging output.&#34;
            )

        return is_alive


DPU_PROCESSOR_SETTINGS = Settings.load(&#34;DPU Processor&#34;)


class DPUMonitoring:
    &#34;&#34;&#34;
    The DPUMonitoring class allows you to execute a function synchronised to the reception of a
    timecode or a housekeeping packet from the N-FEE.

    Args:
        timeout: time to wait for a message before a timeout [default=30s]
    &#34;&#34;&#34;
    def __init__(self, timeout: float = 30):
        self._context = zmq.Context.instance()
        self._endpoint = connect_address(&#39;tcp&#39;, DPU_PROCESSOR_SETTINGS.HOSTNAME, DPU_PROCESSOR_SETTINGS.MONITORING_PORT)
        self._multipart = True
        self._timeout = timeout  # seconds
        self._retries = 3
        self._socket = None
        self._subscriptions = set()

    def __enter__(self):
        self.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if not self._socket.closed:
            self.disconnect()

    def connect(self):
        self._socket = self._context.socket(zmq.SUB)
        self._socket.connect(self._endpoint)

        # subscribe_string = b&#39;&#39;
        # self._socket.subscribe(subscribe_string)
        # self._subscriptions.add(subscribe_string)

    def disconnect(self):
        self._socket.close(linger=0)
        self._subscriptions.clear()

    def unsubscribe_all(self):
        for sub in self._subscriptions:
            self._socket.unsubscribe(sub)
        self._subscriptions.clear()

    def unsubscribe(self, sync_id: int):
        subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;
        try:
            self._subscriptions.remove(subscribe_string)
            self._socket.unsubscribe(subscribe_string)
        except KeyError:
            LOGGER.warning(
                f&#34;Trying to unsubscribe a key that was not previously subscribed: {subscribe_string}&#34;
            )

    def subscribe(self, sync_id: int = None):
        subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;

        if subscribe_string in self._subscriptions:
            return

        self._socket.subscribe(subscribe_string)
        self._subscriptions.add(subscribe_string)

    def wait_for_timecode(self) -&gt; Tuple[int, str]:
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and returns when a TIMECODE
        synchronisation message is received.

        Returns:
            A tuple of the timecode (int) and the corresponding timestamp (str).
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_TIMECODE)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                timecode, timestamp = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode}, {timestamp}&#34;)

                return timecode, timestamp
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_for_hdf5_filename(self, retries: int = None, timeout: float = None) -&gt; List[Path]:
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and returns a list of path names that
        were part of the current registration in the Storage, right before a new registration was
        initiated.

        This method is mainly intended to be used by processes that need to work with the generated
        HDF5 files after they have been closed by the DPU Processor. One of these processes is the
        FITS generation.

        Notes:
            The path names that are returned are absolute filenames that are specific for the
            egse-server on which the DPU Processor is running. These files might not be accessible
            from the machine you are running this monitoring request.

        Returns:
            A list of path names.
        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.HDF5_FILENAMES)

        retries = retries if retries is not None else self._retries
        timeout = timeout or self._timeout

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                filenames = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {filenames}&#34;)

                return filenames
            else:
                retries -= 1
                # LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_number_of_pulses(self, num_pulses: int) -&gt; None:
        &#34;&#34;&#34;
        Wait for a number of pulses (long and short), then return.

        When the number of pulses has been received, the function returns right after the timecode synchronisation
        message. Any command that is sent to the N-FEE immediately after this function returns will be processes within
        that same readout frame, i.e. before the next sync pulse.

        Args:
            num_pulses: the number of sync pulses to wait before returning.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_TIMECODE)

        retries = self._retries

        LOGGER.debug(f&#34;Waiting for {num_pulses} pulses...&#34;)

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                timecode, timestamp = pickle.loads(pickle_string)

                num_pulses -= 1
                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode=}, {timestamp=}, {num_pulses=}&#34;)
                if num_pulses &lt;= 0:
                    return

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_num_cycles(self, num_cycles: int, return_on_frame: int = 3) -&gt; int:
        &#34;&#34;&#34;
        Wait for a number of long pulses (cycles), then return.

        This method will wait for full cycles, i.e. 4 readouts in external sync mode, 1 readout in internal sync mode,
        and will return immediately after receiving the HK sync pulse for the last frame in the requested cycle, i.e.
        frame number == 3 for external sync and frame number == 0 for internal sync. If an RMAP command is then sent
        when the function returns, it will still be executed within that frame and the changed register settings will
        become active on the next pulse, which is a long pulse, the start of the next cycle.
        That way we do not lose a cycle.

        Args:
            num_cycles: the number of full cycles to wait before returning
            return_on_frame: choose the readout frame on which to return [default = 3]

        Returns:
            Zero (0) when no cycles were waited because num_cycles &lt;= 0, otherwise return value &gt; 0.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

        retries = self._retries
        count = 0

        if num_cycles &lt;= 0:
            LOGGER.debug(f&#34;{num_cycles=}, no cycles waited, returned immediately&#34;)
            return count

        LOGGER.debug(f&#34;Waiting for {num_cycles} cycles...&#34;)

        with Timer(&#34;Loop cycles&#34;) as timer, DPUProxy() as dpu_proxy:

            # When we are in external sync mode, we need to skip the current cycle,
            # because the requested changes in the register -&gt; FPGA will ony occur on
            # the next long pulse. No need for this when in internal sync mode.

            sync_mode = dpu_proxy.n_fee_get_sync_mode()
            if sync_mode == 0:
                num_cycles += 1

            while True:
                count += 1
                rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
                if self._socket in rlist:
                    if self._multipart:
                        sync_id, pickle_string = self._socket.recv_multipart()
                        sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                    else:
                        sync_id = MessageIdentifier.ALL
                        pickle_string = self._socket.recv()
                    status = pickle.loads(pickle_string)

                    LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {to_string(status[0])}&#34;)

                    sync_mode = dpu_proxy.n_fee_get_sync_mode()

                    if (sync_mode == 1) or (packet := status[0]) and packet.frame_number == return_on_frame:
                        num_cycles -= 1

                    LOGGER.debug(f&#34;NUM_CYCLES={num_cycles}, {sync_mode=}&#34;)

                    if num_cycles &lt;= 0:
                        return count

                    retries = self._retries  # reset the number of retries
                else:
                    retries -= 1
                    LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                    if retries &lt;= 0:
                        raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

                timer.log_elapsed()

    def monitor_all(self):
        self.subscribe()

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()

                msg = pickle.loads(pickle_string)
                if sync_id == MessageIdentifier.SYNC_TIMECODE:
                    msg = f&#34;timestamp={msg[1]}, timecode={msg[0]}&#34;
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
                elif sync_id == MessageIdentifier.SYNC_HK_PACKET:
                    msg = f&#34;timestamp={msg[1]}, packet type={to_string(msg[0])}&#34;
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
                elif sync_id == MessageIdentifier.NUM_CYCLES:
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, num_cycles={msg}&#34;)

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_until_synced_num_cycles_is_zero(self):
        &#34;&#34;&#34;
        Wait until the synced num_cycles turns zero, then return. The synced num_cycles is
        the num_cycles that is maintained by the DPU Processor and which is distributed by the
        DPU Processor on every 400ms pulse.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.NUM_CYCLES)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()

                synced_num_cycles = pickle.loads(pickle_string)

                LOGGER.info(f&#34;{MessageIdentifier(sync_id).name} = {synced_num_cycles}&#34;)

                if synced_num_cycles &lt;= 0:
                    return

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def do(self, func: Callable, *args, **kwargs):
        return func(*args, **kwargs)

    def on_long_pulse_do(self, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and executes the given function
        when the frame_number == 0, i.e. right after a long pulse.

        Args:
            func (Callable): the function to synchronise
            *args: any arguments to pass to the function
            **kwargs: any keyword arguments to pass to the function

        Returns:
            The return value of the called function.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        return self.on_frame_number_do(0, func, *args, **kwargs)

    def on_frame_number_do(self, frame_number: int, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and executes the given function
        when the given frame_number is reached. This allows to send N-FEE commands right before the long pulse.

        Args:
            frame_number: the frame number on which to execute the function
            func (Callable): the function to synchronise
            *args: any arguments to pass to the function
            **kwargs: any keyword arguments to pass to the function

        Returns:
            The return value of the called function.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                status = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {status[0]}&#34;)

                packet: DataPacketType = status[0]
                if packet and packet.frame_number == frame_number:
                    return func(*args, **kwargs)
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)


@dataclass
class DPUInternals:

    # The number of readout cycles requested by the user. A cycle is the period between two long
    # pulses (400ms). When num_cycle == 0, the N-FEE will be instructed to go to dump mode, when
    # num_cycle &lt; 0 nothing will be done.
    num_cycles: int

    # The expected last packet flags tell you if for a certain ccd side and packet a last packet
    # flag is expected. This is similar to saying if such a packet is to be expected from the N-FEE.
    expected_last_packet_flags: List[int]

    # DUMP mode is not a real N-FEE mode, but is defined in the DPU Processor to make sure the CCDs
    # will not saturate when we are not reading out image data. The conditions for a dump mode are
    # the register map flags &#39;digitise_en&#39; being False and &#39;DG_high&#39; being True.
    dump_mode: bool = False

    # The internal sync flag is set to True whenever the register map parameter &#39;sync_sel&#39; is True.
    internal_sync: bool = False

    # This flag is set to True when the N-FEE shall be put into dump mode internal sync after
    # num_cycles becomes zero.
    dump_mode_int: bool = False

    # The current frame number. This value needs to be updated as soon as the housekeeping packet
    # is received.
    frame_number: int = -1

    # Enumeration with the information about E and F, based on the setup (camera-dependent)
    ccd_sides_enum: Enum = None

    # Enumeration with the sensor_sel
    sensor_sel_enum: Enum = None

    # The clear_error_flags shall be executed on every readout, i.e. every 200ms and 400ms pulse.
    clear_error_flags = False

    # The number of cycles that will be used for slicing the FITS files. This parameter is
    # saved in the HDF5 file upon reception.
    slicing_num_cycles = 0


    def is_start_of_cycle(self):
        &#34;&#34;&#34;
        Returns True if in the first readout in this cycle, i.e. frame number is 0.
        &#34;&#34;&#34;

        return self.frame_number == 0

    def is_end_of_cycle(self):
        &#34;&#34;&#34;
        Returns True if in the last readout in this cycle.
        Note that, when in internal sync mode, this method always returns True.
        &#34;&#34;&#34;
        if self.internal_sync:
            return True
        else:
            return self.frame_number == 3

    def is_400ms_pulse(self):
        return self.frame_number == 0

    def is_200ms_pulse(self):
        return self.frame_number in [1, 2, 3]

    def update(self, n_fee_state: NFEEState.StateTuple):
        self.dump_mode = not bool(n_fee_state.digitise_en)
        self.internal_sync = bool(n_fee_state.sync_sel)
        self.expected_last_packet_flags = create_expected_last_packet_flags(n_fee_state, self.sensor_sel_enum)


class DPUProcessor(multiprocessing.Process):
    &#34;&#34;&#34;
    The DPU Processor handles all interactions with the FEE. It reads the packets from the FEE
    within the readout time frame, and sends commands to the FEE through the RMAP protocol.

    The commands are read from a commanding queue which is shared between the DPU Processor and
    the DPU Controller. Any response from the FEE is put on the response queue which is also
    shared between the processor and the controller.

    The transport mechanism that is used to read and write SpaceWire packets is abstracted into a
    SpaceWireInterface. That allows us to interact with the FEE through different hardware
    channels, e.g. a SpaceWire interface (DSI) or a ZeroMQ DEALER-DEALER protocol for
    communication with the FEE Simulator.
    &#34;&#34;&#34;

    def __init__(
        self,
        transport: SpaceWireInterface,
        priority_queue: multiprocessing.Queue,
        command_queue: multiprocessing.Queue,
        response_queue: multiprocessing.Queue,
    ):

        super().__init__()

        self._transport = transport
        self._priority_q = priority_queue
        self._command_q = command_queue
        self._response_q = response_queue
        self.register_map = RegisterMap(&#34;N-FEE&#34;)
        self._quit_event = multiprocessing.Event()

        # These will be properly initialized when the register map is read from the N-FEE

        self._n_fee_state = NFEEState()


    def run(self):

        self._dpu_internals = DPUInternals(
            num_cycles=-1,
            expected_last_packet_flags=[False, False, False, False],
            dump_mode=False,
            internal_sync=False,
            frame_number=-1,
            ccd_sides_enum=GlobalState.setup.camera.fee.ccd_sides.enum,
            sensor_sel_enum=GlobalState.setup.camera.fee.sensor_sel.enum,
        )

        # The DPU Processor runs in a different process and since ZeroMQ Sockets are not
        # thread/process safe, we have to recreate the ZeroMQHandler attached to the egse.logger
        # in this process.
        import egse.logger
        egse.logger.replace_zmq_handler()

        LOGGER.info(&#34;DPU Processor started.&#34;)

        self._killer = SignalCatcher()

        # Setup a SpaceWire connection with the FEE (Simulator) and
        # open a Storage proxy to save all the data packets.

        origin_spw_data = N_FEE_SETTINGS.ORIGIN_SPW_DATA
        origin_spw_data_type = DATA_TYPE[N_FEE_SETTINGS.ORIGIN_SPW_DATA_TYPE]

        ctx: zmq.Context = zmq.Context().instance()

        # Setup monitoring socket

        mon_sock: zmq.Socket = ctx.socket(zmq.PUB)
        endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.MONITORING_PORT)
        mon_sock.bind(endpoint)
        LOGGER.info(f&#34;DPU Processor sending monitoring sync signals to {endpoint}.&#34;)

        # Setup data distribution socket

        dist_sock: zmq.Socket = ctx.socket(zmq.PUB)
        endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.DATA_DISTRIBUTION_PORT)
        dist_sock.setsockopt(zmq.SNDHWM, 0)  # never block on sending msg
        dist_sock.bind(endpoint)

        LOGGER.info(f&#34;DPU Processor sending SpW data to {endpoint}.&#34;)

        with self._transport, StorageProxy() as storage, ConfigurationManagerProxy() as cm:
            LOGGER.info(&#34;SpaceWire Transport has been connected.&#34;)
            self._transport.configure()
            LOGGER.info(&#34;SpaceWire Transport has been configured.&#34;)

            LOGGER.info(f&#34;Register {origin_spw_data} to Storage&#34;)
            register_to_storage_manager(storage, origin_spw_data)

            # Before going into the wile-loop, read the full register from the N-FEE and initialise
            # the register map.

            try:
                self.initialise_register_map()
                save_register_map(self.register_map, storage, origin_spw_data, dist_sock)
                save_format_version(storage, origin_spw_data)
                save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
            except Abort:
                LOGGER.warning(&#34;The DPU Processor is aborting....&#34;)
                unregister_from_storage_manager(storage, origin_spw_data)
                LOGGER.info(f&#34;The DPU Processor unregistered {origin_spw_data} from the Storage.&#34;)
                return
            except Exception as exc:
                LOGGER.error(exc, exc_info=exc)

            # Initialise the N-FEE state from the register map

            self._n_fee_state.update_at_400ms(self.register_map)

            # Initialise the DPU internals from the N-FEE State

            self._dpu_internals.update(self._n_fee_state.get_state())

            LOGGER.debug(f&#34;{self._dpu_internals.dump_mode=}&#34;)
            LOGGER.debug(f&#34;{self._dpu_internals.internal_sync=}&#34;)
            LOGGER.debug(f&#34;{self._dpu_internals.expected_last_packet_flags=}&#34;)

            # Initialise the data attributes, they will be added as attributes to the data group
            # in the HDF5 file.

            data_attr = self._n_fee_state.get_state()._asdict()

            # Initialise the start_time. This is needed, because when a NoTimeCodeError occurs
            # the variable will not be initialised resulting in a critical error.

            start_time = time.perf_counter()

            try:
                LOGGER.info(&#34;Going into the while True loop...&#34;)
                while True:

                    try:
                        # First two packets are a Timecode and a HK packet  ------------------------

                        tc_packet, timestamp, start_time = read_timecode(self._transport)

                        hk_packet, timestamp = read_hk_packet(self._transport)

                        self._dpu_internals.frame_number = hk_packet.type.frame_number
                        self._dpu_internals.clear_error_flags = True

                        # Create a new HDF5 file for each readout cycle ----------------------------

                        if self._dpu_internals.is_start_of_cycle():
                            with Timer(&#34;Creating a new data file&#34;):
                                new_spw_data_file(storage, self.register_map, origin_spw_data,
                                                  origin_spw_data_type, mon_sock, dist_sock)
                                save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
                                save_num_cycles(storage, origin_spw_data, self._dpu_internals.num_cycles)

                        # Update the N-FEE state (FPGA) --------------------------------------------

                        if self._dpu_internals.is_400ms_pulse():
                            self._n_fee_state.update_at_400ms(self.register_map)
                        elif self._dpu_internals.is_200ms_pulse():
                            self._n_fee_state.update_at_200ms(self.register_map)
                        else:
                            pass  # we are entering the loop for the first time

                        # Update the DPU internals from the N-FEE state

                        self._dpu_internals.update(self._n_fee_state.get_state())

                        # Process and save the timecode and HK packet ------------------------------

                        process_timecode(tc_packet, timestamp, storage, origin_spw_data,
                                         self._dpu_internals.frame_number, mon_sock, dist_sock)

                        process_hk_packet(hk_packet, timestamp, storage, origin_spw_data,
                                          self._dpu_internals.frame_number, mon_sock, dist_sock)

                        process_high_priority_commands(self._priority_q, self._response_q,
                                                       self._n_fee_state.get_state(),
                                                       self._dpu_internals, self.register_map)

                        # On any new readout cycle (400ms pulse), update the state and the internals

                        # FIXME: Why is this test done here and not at the end of the while loop
                        #        when all data has been read?

                        if self._dpu_internals.is_400ms_pulse():

                            pickle_string = pickle.dumps(self._dpu_internals.num_cycles)
                            msg_id = MessageIdentifier.NUM_CYCLES.to_bytes(1, &#39;big&#39;)
                            num_cycles_msg = [msg_id, pickle_string]
                            dist_sock.send_multipart(num_cycles_msg)
                            mon_sock.send_multipart(num_cycles_msg)

                            # decrement num_cycles, this can go negative which is interpreted as
                            # not doing anything...

                            self._dpu_internals.num_cycles -= 1  # check issue #917 before changing this line

                            LOGGER.debug(
                                f&#34;HK: frame number={hk_packet.type.frame_number}, dump mode={self._dpu_internals.dump_mode}, num_cycles={self._dpu_internals.num_cycles}&#34;
                            )

                            LOGGER.debug(
                                f&#34;FEE mode in register map: {n_fee_mode(self.register_map[&#39;ccd_mode_config&#39;]).name}&#34;
                            )

                            save_slicing_parameter(storage, origin_spw_data, self._dpu_internals.slicing_num_cycles)

                        if self._dpu_internals.is_end_of_cycle():

                            # When we are at the end of our requested num_cycles, go to DUMP mode

                            # FIXME: review if this is the right place and if the dump command will
                            #        be executed at the right moment, e.g. are there no commands on
                            #        the queue anymore?

                            if self._dpu_internals.num_cycles == 0:
                                if self._dpu_internals.dump_mode_int:
                                    dump_mode_command = command_set_dump_mode_int_sync
                                else:
                                    dump_mode_command = command_set_dump_mode
                                self._command_q.put((dump_mode_command, [], {&#39;response&#39;: False}))

                        # Then we might get data packets depending on the FEE mode -----------------

                        mode = hk_packet.type.mode
                        LOGGER.debug(f&#34;FEE mode in HK packet: {n_fee_mode(mode).name}&#34;)

                        data_attr = update_data_attributes(data_attr, self._n_fee_state.get_state())

                        with Timer(&#34;Read and process data packets&#34;):
                            read_and_process_data_packets(
                                self._transport, storage, origin_spw_data, start_time, mode,
                                self.register_map, data_attr, self._dpu_internals, dist_sock)

                    except NoBytesReceivedError as exc:
                        # LOGGER.debug(f&#34;No bytes received: {exc}&#34;)
                        pass
                    except NoTimeCodeError as exc:
                        LOGGER.warning(&#34;Reading the next timecode packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoTimecodeError:&#34;, exc_info=exc)
                    except NoHousekeepingPacketError as exc:
                        LOGGER.warning(&#34;Reading the next housekeeping packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoHousekeepingPacketError:&#34;, exc_info=exc)
                    except NoDataPacketError as exc:
                        LOGGER.warning(&#34;Reading the next data packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoDataPacketError:&#34;, exc_info=exc)
                    except TimecodeTimeoutError as exc:
                        # LOGGER.debug(&#34;Waiting for the next timecode.&#34;)
                        pass
                    except TimeExceededError as exc:
                        LOGGER.warning(
                            &#34;Time to retrieve data packets in this readout cycle exceeded &#34;
                            &#34;4.0 seconds.&#34;
                        )
                        LOGGER.debug(&#34;Traceback for TimeExceededError:&#34;, exc_info=exc)
                    # FIXME:
                    #   same here as above, make sure the DPU Processor doesn&#39;t crash. This last
                    #   catching also means that Commands on the Queue will still be executed if
                    #   there is an error. What needs to be checked here is that the Command should
                    #   probably be send in the &#39;save zone&#39; between 4.0s and 6.25s.
                    except Exception as exc:
                        LOGGER.error(exc, exc_info=True)
                        traceback.print_exc()

                    # LOGGER.info(
                    #     f&#34;Time past after reading all packets from FEE:&#34;
                    #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                    # )

                    # Process high priority commands

                    process_high_priority_commands(
                        self._priority_q, self._response_q,
                        self._n_fee_state.get_state(), self._dpu_internals, self.register_map)

                    # Then, we might want to send some RMAP commands -------------------------------

                    # When we are in the 2s RMAP window, send the commands.
                    # Waiting till 4s have passed is apparently not needed, commands can be sent as
                    # soon as no packets will be received anymore, even if the time elapsed is
                    # less than 4s.
                    # But the following two lines might be uncommented for testing purposes.

                    # while time.perf_counter() &lt; start_time + 4.0:
                    #     time.sleep(0.1)

                    try:
                        send_commands_to_n_fee(
                            self._transport, storage, origin_spw_data,
                            self.register_map, self._command_q, self._response_q,
                            self._dpu_internals
                        )
                    except NFEECommandError as exc:
                        # Error is already logged in the send_commands_to_n_fee() function
                        pass

                    # LOGGER.debug(
                    #     f&#34;Time past after sending commands to FEE:&#34;
                    #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                    # )

                    # Terminate the DPU Processor when the quit event flag has been set by the
                    # commanding protocol.

                    if self._quit_event.is_set() or self._killer.term_signal_received:
                        LOGGER.info(&#34;Quit event is set, terminating..&#34;)
                        break

            except (Exception,) as exc:
                LOGGER.critical(
                    &#34;A fatal error occurred in the DPU Processor, needs to be restarted!&#34;,
                    exc_info=exc
                )
                # re-raise the exception such that it will bubble up at a higher level.
                raise
            finally:
                LOGGER.debug(&#34;Unregistering from Storage Manager.&#34;)
                unregister_from_storage_manager(storage, origin_spw_data)

        mon_sock.close(linger=0)
        dist_sock.close(linger=0)
        # ctx.destroy()

    def quit(self):
        LOGGER.warning(&#34;Sending a Quit event to the DPU Processor.&#34;)
        self._quit_event.set()

    def initialise_register_map(self):

        # FIXME:
        #   The DPU Processor shall not crash, therefore we shall catch all Exceptions thrown.
        #   Log the exceptions as an error and continue here. It must be tested what the exact
        #   harm is when doing this and if we need some further action before proceeding.

        # The DPU Processor is only initialised properly after reading the full register from
        # the N-FEE. This can only be done within the time window we have for sending RMAP
        # commands. Therefore we need to make sure we are in a safe time window for sending
        # RMAP commands.

        LOGGER.info(&#39;Initialise Register Map from N-FEE&#39;)

        # First wait until a timecode is received

        while True:
            terminator, packet = self._transport.read_packet(timeout=200)
            if self._killer.term_signal_received:
                raise Abort(&#34;A SIGTERM signal was received for this process&#34;)
            if packet is None or len(packet) in (0, 1):
                continue
            if is_timecode(packet):
                break

        start_time = time.perf_counter()

        LOGGER.debug(f&#34;Timecode received {packet=}&#34;)

        while time.perf_counter() &lt; start_time + 4.2:
            terminator, packet = self._transport.read_packet(timeout=200)
            if packet is None:
                msg = f&#34;time passed {time.perf_counter() - start_time:0.3f}&#34;
            else:
                msg = packet[:10]
            LOGGER.debug(f&#34;Discarding packet: {msg}&#34;)

        LOGGER.info(f&#34;Time passed since last timecode {time.perf_counter() - start_time:0.3f}s&#34;)
        LOGGER.info(
            &#39;In safe time window for sending RMAP command, getting full register..&#39;
        )

        command_sync_register_map(self._transport, self.register_map)

        LOGGER.debug(self.register_map)


def save_register_map(
        reg_map: RegisterMap, storage: StorageProxy, origin: str, dist_socket: zmq.Socket):

    reg_memory_map = reg_map.get_memory_map_as_ndarray()

    LOGGER.debug(&#34;Saving register map&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin,
            &#34;data&#34;: {
                &#34;/register/&#34;: reg_memory_map
            }
        }
    )

    LOGGER.debug(f&#34;Response from saving Register Map: {response}&#34;)

    pickle_string = pickle.dumps(reg_memory_map)
    msg_id = MessageIdentifier.N_FEE_REGISTER_MAP.to_bytes(1, &#39;big&#39;)
    dist_socket.send_multipart([msg_id, pickle_string])


def register_to_storage_manager(proxy: StorageProxy, origin: str):
    rc = proxy.new_registration(
        item={
            &#34;origin&#34;: origin,
            &#34;persistence_class&#34;: HDF5,
            &#34;prep&#34;: {
                &#34;mode&#34;: &#34;w-&#34;,
            },
        },
        use_counter=True
    )
    LOGGER.info(f&#34;{rc=!s}&#34;)
    if rc and not rc.successful:
        LOGGER.warning(f&#34;Couldn&#39;t register to the Storage manager: {rc}&#34;)


def unregister_from_storage_manager(proxy: StorageProxy, origin: str):

    try:
        rc = proxy.unregister({&#34;origin&#34;: origin})
        if not rc.successful:
            LOGGER.warning(f&#34;Couldn&#39;t unregister from the Storage manager: {rc}&#34;)

    except ConnectionError as exc:
        LOGGER.warning(f&#34;Couldn&#39;t connect to the Storage manager for de-registration: {exc}&#34;)


def new_spw_data_file(
        proxy: StorageProxy, reg_map: RegisterMap, origin: str, data_type: Type[PersistenceLayer],
        mon_socket: zmq.Socket, dist_socket: zmq.Socket
):
    &#34;&#34;&#34;
    Open a new data file to store CCD data.

    Args:
        - proxy: Storage manager.
        - origin: the origin for which to create a new file
        - reg_map: Register map.
    &#34;&#34;&#34;

    LOGGER.debug(f&#34;Create a new data file for {origin} in the Storage&#34;)

    # prep = {
    #     &#34;expected_last_packet_flags&#34;: get_expected_last_packet_flags(reg_map),
    # }
    #
    # for name in CRUCIAL_REGISTER_PARAMETERS:
    #     prep[name] = reg_map[name]

    item = {
        &#34;origin&#34;: origin,
        &#34;persistence_class&#34;: data_type,
        &#34;prep&#34;: {},
    }

    # Retrieve the current filenames that will be available for processing as soon as the new
    # HDF5 file is registered and created by the storage manager. This should be done, of course,
    # before the new-registration call!

    hdf5_filenames = proxy.get_filenames(item={&#34;origin&#34;: origin})

    response = proxy.new_registration(item=item, use_counter=True)

    LOGGER.debug(f&#34;Response from new_registration: {response}&#34;)

    save_format_version(proxy, origin)

    # Save the Register Map that is used for the current readout cycle

    save_register_map(reg_map, proxy, origin, dist_socket)

    LOGGER.info(f&#34;HDF5 files ready for processing: {hdf5_filenames=}&#34;)

    pickle_string = pickle.dumps(hdf5_filenames)
    msg_id = MessageIdentifier.HDF5_FILENAMES.to_bytes(1, &#39;big&#39;)
    mon_socket.send_multipart([msg_id, pickle_string])


def save_format_version(proxy: StorageProxy, origin: str):

    # 2.0 - introduced the format_version
    # 2.1 - Added obsid as a dataset to the HDF5 file
    # 2.2 - Multiple commands can now be saved under the same frame number
    # 2.3 - introduced /dpu/num_cycles attribute
    # 2.4 - introduced /dpu/slicing_num_cycles attribute

    major_version = 2
    minor_version = 4

    item_data = {
        &#34;/versions/format_version/&#34;: &#34;format version of HDF5 file&#34;,
        &#34;/versions/format_version:ATTRS&#34;: [
            (&#34;major_version&#34;, major_version),
            (&#34;minor_version&#34;, minor_version)
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving format_version: {response}&#34;)


def save_obsid(proxy: StorageProxy, origin: str, obsid: ObservationIdentifier):

    item_data = {
        &#34;/obsid&#34;: str(obsid),
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving OBSID: {response}&#34;)


def save_num_cycles(proxy: StorageProxy, origin: str, num_cycles: int):
    &#34;&#34;&#34;Save the number of cycles to the storage. This will only save if num_cycles &gt;= 0.&#34;&#34;&#34;

    # Only save num_cycles &gt;= 0, the DPU Processor understands when num_cycles is negative,
    # but for the HDF5 file we want to keep it clean and always have num_cycles &gt;= 0.

    num_cycles = max(num_cycles, 0)

    item_data = {
        &#34;/dpu/&#34;: &#34;DPU specific parameters&#34;,
        &#34;/dpu/:ATTRS&#34;: [
            (&#34;num_cycles&#34;, num_cycles),
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving NUM_CYCLES: {response}&#34;)


def save_slicing_parameter(proxy: StorageProxy, origin: str, slicing_num_cycles: int):
    &#34;&#34;&#34;Save the number of cycles to use for slicing to the storage.&#34;&#34;&#34;

    item_data = {
        &#34;/dpu/:ATTRS&#34;: [
            (&#34;slicing_num_cycles&#34;, slicing_num_cycles),
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving SLICING_NUM_CYCLES: {response}&#34;)


def update_data_attributes(attr: dict, n_fee_state: NFEEState.StateTuple) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;
    Collect parameter/value pairs that will be added to the data group as attributes.

    Args:
        attr (dict): the current attributes that need to be updated
        n_fee_state: the current state of the N-FEE

    Returns:
        Updated data attributes.
    &#34;&#34;&#34;

    attr.update(n_fee_state._asdict())
    return attr


def read_timecode(transport: SpaceWireInterface) -&gt; (TimecodePacket, str, float):
    &#34;&#34;&#34;
    Reads the next Timecode packet from the N-FEE. When the Timecode packet is received,
    the packet and a timestamp is sent to the Storage manager.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin_spw_data: the registration identifier for the Storage manager, for the SpW data
        mon_socket: the ZeroMQ socket to which monitoring sync signals are sent
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Returns:
        The approximate start time for this readout cycle.
    Raises:
        NoTimecodeError when the timecode could not be read.
    &#34;&#34;&#34;
    terminator, packet = transport.read_packet(timeout=100)
    timestamp = format_datetime()

    if terminator is None and packet is None:
        raise TimecodeTimeoutError()

    # Start time taken as closely as possible to timecode reception, this start_time is
    # returned to be used in further functions called in the outer loop.

    start_time = time.perf_counter()
    # LOGGER.debug(f&#34;Time set: {start_time}&#34;)

    bytes_received = len(packet)

    # The following check is to cope with loss of connection when either the
    # FEE simulator crashes or the connection dropped for some other reason.
    # We will receive one packet with 0 or 1 bytes.

    if bytes_received in {0, 1}:
        raise NoBytesReceivedError(f&#34;{bytes_received} bytes received, lost connection to FEE?&#34;)

    if not is_timecode(packet):
        packet = SpaceWirePacket.create_packet(packet)
        raise NoTimeCodeError(f&#34;Expected Timecode Packet, but got {packet.__class__.__name__}&#34;)

    tc_packet: TimecodePacket = SpaceWirePacket.create_packet(packet)

    LOGGER.info(f&#34;Timecode received: {tc_packet.timecode}&#34;)

    return tc_packet, timestamp, start_time


def process_timecode(tc_packet: TimecodePacket, timestamp: str,
                     storage: StorageProxy, origin_spw_data: str, frame_number: int,
                     mon_socket: zmq.Socket, dist_socket: zmq.Socket):

    LOGGER.debug(f&#34;Saving timecode packet: {tc_packet.timecode=}, {frame_number=}&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin_spw_data,
            &#34;data&#34;:
                {
                    f&#34;/{frame_number}/timecode&#34;: tc_packet,
                    f&#34;/{frame_number}/timecode:ATTRS&#34;: [(&#34;timestamp&#34;, timestamp)],
                }
        }
    )

    LOGGER.debug(f&#34;Response from saving Timecode: {response}&#34;)

    pickle_string = pickle.dumps((tc_packet.timecode, timestamp))
    mon_socket.send_multipart([MessageIdentifier.SYNC_TIMECODE.to_bytes(1, &#34;big&#34;), pickle_string])
    dist_socket.send_multipart([MessageIdentifier.SYNC_TIMECODE.to_bytes(1, &#34;big&#34;), pickle_string])


def read_hk_packet(transport: SpaceWireInterface) -&gt; (HousekeepingPacket, str):
    &#34;&#34;&#34;
    Read the next Housekeeping Packet from the N-FEE. The packet is sent to the Storage manager.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin: the registration identifier for the Storage manager
        mon_socket: the ZeroMQ socket to which monitoring sync signals are sent
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Raises:
        NoHousekeepingPacketError when the next packet is not a `HousekeepingPacket`.
    Returns:
        the received housekeeping packet.
    &#34;&#34;&#34;
    terminator, packet = transport.read_packet()
    timestamp = format_datetime()

    if not is_hk_data_packet(packet):
        packet = SpaceWirePacket.create_packet(packet)
        raise NoHousekeepingPacketError(
            f&#34;Expected a Housekeeping packet, but got {packet.__class__.__name__}&#34;)

    hk_packet: HousekeepingPacket = SpaceWirePacket.create_packet(packet)

    LOGGER.info(f&#34;Housekeeping Packet received: {hk_packet.type!s}&#34;)

    return hk_packet, timestamp


def process_hk_packet(hk_packet: HousekeepingPacket, timestamp: str,
                      storage: StorageProxy, origin: str, frame_number: int,
                      mon_socket: zmq.Socket, dist_socket: zmq.Socket):

    LOGGER.debug(f&#34;Saving Housekeeping packet: {hk_packet.type!s}, &#34;
                f&#34;frame counter={hk_packet.frame_counter}, &#34;
                f&#34;sequence counter={hk_packet.sequence_counter}&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin,
            &#34;data&#34;:
                {
                    f&#34;/{frame_number}/hk&#34;: hk_packet,
                }
        }
    )

    LOGGER.debug(f&#34;Response from saving HK Packet: {response}&#34;)

    msg_id = MessageIdentifier.SYNC_HK_PACKET.to_bytes(1, &#39;big&#39;)

    pickle_string = pickle.dumps((hk_packet.type, timestamp))
    mon_socket.send_multipart([msg_id, pickle_string])

    pickle_string = pickle.dumps((hk_packet, timestamp))
    dist_socket.send_multipart([msg_id, pickle_string])


def read_and_process_data_packets(
        transport: SpaceWireInterface, storage: StorageProxy, origin_spw_data: str,
        start_time: float, mode: int, register_map: RegisterMap, data_attr: dict,
        internals: DPUInternals, dist_socket: zmq.Socket
):
    &#34;&#34;&#34;
    Read the data packets when they are available depending on the mode.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin_spw_data: the registration identifier for the Storage manager
        start_time: the approximate time that the readout cycle started
        mode: FPGA mode
        register_map: the DPU Processor&#39;s copy of the N-FEE register map
        data_attr: register values to be saved with the data
        internals: use for expected_last_packet_flags (these will be updated within this function)
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Raises:
        NoDataPacketError when the expected packet is not a data packet.
    &#34;&#34;&#34;

    if internals.dump_mode or mode not in (
            n_fee_mode.FULL_IMAGE_PATTERN_MODE,
            n_fee_mode.WINDOWING_PATTERN_MODE,
            n_fee_mode.FULL_IMAGE_MODE,
    ):
        return

    timestamp = format_datetime()
    msg_id = MessageIdentifier.SYNC_DATA_PACKET.to_bytes(1, &#39;big&#39;)

    data_count = 0

    # Initialise the flags that determine if the last packet has arrived for
    # all expected data packets.

    actual_last_packet_flags = [False, False, False, False]

    # Read the data, until all the expected last packet bits are set.
    # This should be within next 4 seconds.

    LOGGER.debug(&#34;Reading data packets....&#34;)

    terminator, packet = transport.read_packet()

    data_packet: DataPacket = SpaceWirePacket.create_packet(packet)

    if (not isinstance(data_packet, DataDataPacket) and
            not isinstance(data_packet, OverscanDataPacket)):
        LOGGER.critical(f&#34;DataPacket expected, got {data_packet}&#34;)
        raise NoDataPacketError(f&#34;Expected a data packet, but got {data_packet.__class__.__name__}&#34;)

    # LOGGER.debug(f&#34;Got data packet of length {len(packet)}&#34;)

    LOGGER.debug(f&#34;Saving data packets: {data_packet.type!s}&#34;)

    item_data = {f&#34;/{internals.frame_number}/data/{data_count}&#34;: data_packet}

    attrs = [(k, v) for k, v in data_attr.items()]
    item_data.update({f&#34;/{internals.frame_number}/data:ATTRS&#34;: attrs})

    response = storage.save(
        {
            &#34;origin&#34;: origin_spw_data,
            &#34;data&#34;: item_data
        }
    )

    if isinstance(response, Exception):
        LOGGER.warning(f&#34;Response from saving data packet: {response}&#34;)

    pickle_string = pickle.dumps((data_packet, timestamp))
    dist_socket.send_multipart([msg_id, pickle_string])

    data_count += 1

    # Update the expected flags with the possibly new register values, but only
    # after we had the 400ms pulse which updates the settings from the
    # register map. The test is needed because the register here on the DPU
    # processing side can be updated also on 200ms sync pulses, but the changes
    # only take effect on the 400ms pulse in the N-FEE.

    if data_packet.type.frame_number == 0:
        internals.expected_last_packet_flags = get_expected_last_packet_flags(register_map, internals.sensor_sel_enum)
        LOGGER.debug(f&#34;{internals.expected_last_packet_flags=}&#34;)

    idx = get_index_for_last_packet_flags(data_packet.type.packet_type, data_packet.type.ccd_side,
                                          internals.ccd_sides_enum)
    # LOGGER.debug(f&#34;{idx=}, {data_packet.type.packet_type=}, {data_packet.type.ccd_side=}&#34;)
    actual_last_packet_flags[idx] = data_packet.type.last_packet

    while not got_all_last_packets(
            actual_last_packet_flags, internals.expected_last_packet_flags):

        terminator, packet = transport.read_packet()
        data_packet: DataPacket = SpaceWirePacket.create_packet(packet)

        if (not isinstance(data_packet, DataDataPacket) and
                not isinstance(data_packet, OverscanDataPacket)):
            LOGGER.critical(f&#34;DataPacket expected, got {data_packet}&#34;)
            raise NoDataPacketError(
                f&#34;Expected a data packet, but got {data_packet.__class__.__name__}&#34;)

        # LOGGER.debug(f&#34;Saving data packet: {data_packet.type!s}&#34;)

        response = storage.save(
            {
                &#34;origin&#34;: origin_spw_data,
                &#34;data&#34;:
                    {
                        f&#34;/{internals.frame_number}/data/{data_count}&#34;: data_packet,
                    }
            }
        )

        if isinstance(response, Exception):
            LOGGER.warning(f&#34;Response from saving data packet: {response}&#34;)

        pickle_string = pickle.dumps((data_packet, timestamp))
        dist_socket.send_multipart([msg_id, pickle_string])

        data_count += 1

        #LOGGER.debug(f&#34;Got data packet of length {len(packet)}&#34;)
        #LOGGER.debug(f&#34;DataPacketHeader: {data_packet.header.type_as_object}&#34;)

        idx = get_index_for_last_packet_flags(data_packet.type.packet_type, data_packet.type.ccd_side,
                                              internals.ccd_sides_enum)
        actual_last_packet_flags[idx] = data_packet.type.last_packet

        # Sending data packets shall not take more than 4 seconds, and if we
        # wait longer than 6.25 seconds, all RMAP commands that we send will be
        # discarded.

        if time.perf_counter() &gt; start_time + 5.25:
            raise TimeExceededError(
                &#34;Retrieving data packets exceeded the allowed 4.0 seconds, &#34;
                &#34;breaking out of the data loop.&#34;
            )


def send_commands_to_n_fee(
        transport: SpaceWireInterface, storage: StorageProxy, origin: str,
        register_map: RegisterMap,
        command_q: multiprocessing.Queue,
        response_q: multiprocessing.Queue,
        internals: DPUInternals
):
    &#34;&#34;&#34;
    Send RMAP commands to the N-FEE. The commands are read from the command queue that is shared
    with the DPU Controller. The response from the N-FEE is put on the response queue, also shared
    with the DPU Controller.

    !!! note
        The current implementation allows only one command from the command queue per sync cycle.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin: the registration identifier for the Storage manager
        register_map: the DPU Processor&#39;s copy of the N-FEE register map
        command_q: the command queue
        response_q: the response queue
        internals: for some commands we need access to DPUInternals, e.g. num_cycles, dump_mode_int

    Raises:
        Exceptions are caught and put on the response queue.
    &#34;&#34;&#34;

    if internals.clear_error_flags:
        LOGGER.debug(&#34;Clearing error flags&#34;)
        _ = command_set_clear_error_flags(transport, register_map)
        internals.clear_error_flags = False

    command = response = None
    kwargs = {}
    try:
        (command, args, kwargs) = command_q.get_nowait()

        # When num_cycles is not specified, don&#39;t even set it to 0, the N-FEE will stay in the
        # current configuration until commanded otherwise.

        if num_cycles := kwargs.get(&#34;num_cycles&#34;):
            LOGGER.debug(f&#34;Set internals.num_cycle to {num_cycles}.&#34;)
            internals.num_cycles = num_cycles

        # Some commanding requires to go back into internal sync dump mode

        dump_mode_int = kwargs.get(&#34;dump_mode_int&#34;, False)
        LOGGER.debug(f&#34;Set internals.dump_mode_int to {dump_mode_int}.&#34;)
        internals.dump_mode_int = dump_mode_int

        LOGGER.debug(f&#34;Executing Command: {command.__name__}, {args=}&#34;)
        response = command(transport, register_map, *args)
        LOGGER.debug(f&#34;Command executed: {command.__name__}, {args=}, {response=}&#34;)

        LOGGER.debug(f&#34;Saving command: {command.__name__}, {args=}&#34;)

        response_save = storage.save({
            &#34;origin&#34;: origin,
            &#34;data&#34;: {
                f&#34;/{internals.frame_number}/command/&#34;: f&#34;{command.__name__}, {args=}, {kwargs=}&#34;,
            }
        })

        LOGGER.debug(f&#34;Response from saving Command: {response_save}&#34;)

    except queue.Empty:
        pass
    except (Exception,) as exc:
        LOGGER.error(
            f&#34;Exception during command execution in DPU Processor: &#34;
            f&#34;{command}&#34;, exc_info=exc
        )
        raise NFEECommandError(
            f&#34;An exception occurred sending the command {command} &#34;
            f&#34;to the N-FEE.&#34;) from exc
    finally:
        if command is not None and kwargs.get(&#39;response&#39;, True):
            response_q.put((command, response))


def process_high_priority_commands(
        priority_q: multiprocessing.Queue,
        response_q: multiprocessing.Queue,
        n_fee_state: tuple, dpu_internals: DPUInternals, reg_map: RegisterMap):
    &#34;&#34;&#34;
    Execute high priority commands from the DPU Control Server /  Controller. The `n_fee_state` and
    the `dpu_internals` tuples are passed to the high priority commands before any other arguments
    that were passed on the command queue.

    Args:
        priority_q: the command queue with priority
        response_q: the response queue
        n_fee_state: a namedtuple containing the current state of the N-FEE
        dpu_internals: the internal settings of the DPU might be requested or set
            by a high priority command
        reg_map: the current register map from the DPU Processor
    &#34;&#34;&#34;

    command = response = None
    try:
        (command, args) = priority_q.get_nowait()
        response = command(n_fee_state, dpu_internals, reg_map, *args)
        LOGGER.debug(f&#34;Command executed: {command.__name__}, {args=}, {response=}&#34;)
    except queue.Empty:
        pass
    except (Exception,) as exc:
        LOGGER.error(
            f&#34;Exception during command execution in DPU Processor: &#34;
            f&#34;{command}&#34;, exc_info=exc
        )
        raise NFEECommandError(
            f&#34;An exception occurred sending the command {command} &#34;
            f&#34;to the N-FEE.&#34;) from exc
    finally:
        if command is not None:
            response_q.put((command, response))


def get_index_for_last_packet_flags(packet_type: int, ccd_side: int, ccd_sides_enum):
    &#34;&#34;&#34;
    Returns the index into the last packet flags list.

    The last packet flags list is organised as follows:

        * index 0: data packet, E-side
        * index 1: data packet, F-side
        * index 2: overscan data packet, E-side
        * index:3: overscan data packet, F-side

    Args:
        packet_type: the packet type as read from the packet header [datapacket=0, overscan=1,
            housekeeping=2]
        ccd_side: the ccd side as read from the packet header
        ccd_sides_enum: Enumeration with information on E and F

    Returns:
        The index for the last packet flags list.
    &#34;&#34;&#34;
    if ccd_side == ccd_sides_enum.E_SIDE.value:
        return packet_type * 2
    else:
        return packet_type * 2 + 1


def get_expected_last_packet_flags(register_map: Mapping, sensor_sel_enum: Enum) -&gt; List[bool]:
    &#34;&#34;&#34;
    Build and returns a list of flags that define if a last packet is expected.

    A last packet flag is expected for normal data packets and overscan data
    packets. For both these data packets we can expect E-side and F-side packets
    with a last packet flag. That brings the total expected flags to four. This
    function examines the register values `v_start`, `v_end`, and `sensor_sel`.

    The flags are ordered as follows:

    1. data packet and E-side
    2. data packet and F-side
    3. overscan data packet and E-side
    4. overscan data packet and F-side

    Housekeeping packets are not considered here.

    For comparing the flags with the actual data,
    use the function `got_all_last_packets(actual, expected)`.

    Args:
        register_map: the current Register map for the N-FEE
        sensor_sel_enum:
    Returns:
        a list of flags.
    &#34;&#34;&#34;
    sensor_sel_from_register = register_map[&#34;sensor_sel&#34;]

    e_side = bool(sensor_sel_from_register &amp; sensor_sel_enum.E_SIDE)
    f_side = bool(sensor_sel_from_register &amp; sensor_sel_enum.F_SIDE)
    v_start = register_map[&#34;v_start&#34;]
    v_end = register_map[&#34;v_end&#34;]
    data_packet = v_start &lt; 4510
    overscan_packet = v_end &gt; 4509

    return [
        data_packet and e_side,
        data_packet and f_side,
        overscan_packet and e_side,
        overscan_packet and f_side
    ]

def create_expected_last_packet_flags(n_fee_state: NFEEState.StateTuple, sensor_sel_enum: Enum):
    &#34;&#34;&#34;
    Build and returns a list of flags that define if a last packet is expected.

    A last packet flag is expected for normal data packets and overscan data
    packets. For both these data packets we can expect E-side and F-side packets
    with a last packet flag. That brings the total expected flags to four. This
    function examines the register values `v_start`, `v_end`, and `sensor_sel`.

    The flags are ordered as follows:

    1. data packet and E-side
    2. data packet and F-side
    3. overscan data packet and E-side
    4. overscan data packet and F-side

    Housekeeping packets are not considered here.

    For comparing the flags with the actual data,
    use the function `got_all_last_packets(actual, expected)`.

    Args:
        n_fee_state: a namedtuple containing the current N-FEE State
        sensor_sel_enum: Enumeration with the sensor_sel
    Returns:
        a list of flags.
    &#34;&#34;&#34;
    sensor_sel_from_nfee_state = n_fee_state.sensor_sel

    v_start = n_fee_state.v_start
    v_end = n_fee_state.v_end

    e_side = bool(sensor_sel_from_nfee_state &amp; sensor_sel_enum.E_SIDE)
    f_side = bool(sensor_sel_from_nfee_state &amp; sensor_sel_enum.F_SIDE)
    data_packet = v_start &lt; 4510
    overscan_packet = v_end &gt; 4509

    return [
        data_packet and e_side,
        data_packet and f_side,
        overscan_packet and e_side,
        overscan_packet and f_side
    ]


def got_all_last_packets(actual, expected):
    &#34;&#34;&#34;
    Returns True if all the expected last packet flags have been seen.

    Args:
        actual: the flags that have been seen so far
        expected: the expected flags

    Returns:
        True if &#39;actual&#39; matches &#39;expected&#39;, False otherwise.
    &#34;&#34;&#34;
    rc = all([x == y for (x, y) in zip(actual, expected)])
    # LOGGER.info(f&#34;{expected=}, {actual=}, {rc=}&#34;)
    return rc


if __name__ == &#34;__main__&#34;:

    def do_something(idx):
        LOGGER.info(f&#34;Hello! {idx=}&#34;)

    moni = DPUMonitoring()
    moni.connect()

    for idx in range(3):
        # moni.on_long_pulse_do(do_something, idx)

        # timecode, timestamp = moni.wait_for_timecode()
        # LOGGER.info(f&#34;{timecode=}, {timestamp=}&#34;)

        filenames = moni.wait_for_hdf5_filename()
        LOGGER.info(f&#34;{filenames=}&#34;)

    moni.disconnect()</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="egse.dpu.ccd_ui" href="ccd_ui.html">egse.dpu.ccd_ui</a></code></dt>
<dd>
<div class="desc"><p>This module defines widgets that are common to the DPU GUI and the HDF5 GUI.</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.dpu" href="dpu.html">egse.dpu.dpu</a></code></dt>
<dd>
<div class="desc"><p>This module contains commanding functions that are used by the DPU Controller / Processor …</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.dpu_cs" href="dpu_cs.html">egse.dpu.dpu_cs</a></code></dt>
<dd>
<div class="desc"><p>The DPU Control Server will receive commands from the DPU Proxy and executes those commands via
the DPU Controller …</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.dpu_ui" href="dpu_ui.html">egse.dpu.dpu_ui</a></code></dt>
<dd>
<div class="desc"><p>This module implements the image display for the N-FEE data and housekeeping …</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.fitsgen" href="fitsgen.html">egse.dpu.fitsgen</a></code></dt>
<dd>
<div class="desc"><p>This module define the FITS generation process …</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.fitsgen_test" href="fitsgen_test.html">egse.dpu.fitsgen_test</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="egse.dpu.fitsgen_ui" href="fitsgen_ui.html">egse.dpu.fitsgen_ui</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="egse.dpu.hdf5_model" href="hdf5_model.html">egse.dpu.hdf5_model</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="egse.dpu.hdf5_ui" href="hdf5_ui.html">egse.dpu.hdf5_ui</a></code></dt>
<dd>
<div class="desc"><p>This module provides all the code to generate the main GUI and the GUI components
used by the HDF5 Viewer.</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.hdf5_viewer" href="hdf5_viewer.html">egse.dpu.hdf5_viewer</a></code></dt>
<dd>
<div class="desc"><p>A simple GUI application to visualise the content of an HDF5 file that contains N-FEE SpceWire data.</p></div>
</dd>
<dt><code class="name"><a title="egse.dpu.hk_ui" href="hk_ui.html">egse.dpu.hk_ui</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="egse.dpu.create_expected_last_packet_flags"><code class="name flex">
<span>def <span class="ident">create_expected_last_packet_flags</span></span>(<span>n_fee_state: egse.dpu.dpu.StateTuple, sensor_sel_enum: enum.Enum)</span>
</code></dt>
<dd>
<div class="desc"><p>Build and returns a list of flags that define if a last packet is expected.</p>
<p>A last packet flag is expected for normal data packets and overscan data
packets. For both these data packets we can expect E-side and F-side packets
with a last packet flag. That brings the total expected flags to four. This
function examines the register values <code>v_start</code>, <code>v_end</code>, and <code>sensor_sel</code>.</p>
<p>The flags are ordered as follows:</p>
<ol>
<li>data packet and E-side</li>
<li>data packet and F-side</li>
<li>overscan data packet and E-side</li>
<li>overscan data packet and F-side</li>
</ol>
<p>Housekeeping packets are not considered here.</p>
<p>For comparing the flags with the actual data,
use the function <code><a title="egse.dpu.got_all_last_packets" href="#egse.dpu.got_all_last_packets">got_all_last_packets()</a>(actual, expected)</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_state</code></strong></dt>
<dd>a namedtuple containing the current N-FEE State</dd>
<dt><strong><code>sensor_sel_enum</code></strong></dt>
<dd>Enumeration with the sensor_sel</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>a list of flags.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_expected_last_packet_flags(n_fee_state: NFEEState.StateTuple, sensor_sel_enum: Enum):
    &#34;&#34;&#34;
    Build and returns a list of flags that define if a last packet is expected.

    A last packet flag is expected for normal data packets and overscan data
    packets. For both these data packets we can expect E-side and F-side packets
    with a last packet flag. That brings the total expected flags to four. This
    function examines the register values `v_start`, `v_end`, and `sensor_sel`.

    The flags are ordered as follows:

    1. data packet and E-side
    2. data packet and F-side
    3. overscan data packet and E-side
    4. overscan data packet and F-side

    Housekeeping packets are not considered here.

    For comparing the flags with the actual data,
    use the function `got_all_last_packets(actual, expected)`.

    Args:
        n_fee_state: a namedtuple containing the current N-FEE State
        sensor_sel_enum: Enumeration with the sensor_sel
    Returns:
        a list of flags.
    &#34;&#34;&#34;
    sensor_sel_from_nfee_state = n_fee_state.sensor_sel

    v_start = n_fee_state.v_start
    v_end = n_fee_state.v_end

    e_side = bool(sensor_sel_from_nfee_state &amp; sensor_sel_enum.E_SIDE)
    f_side = bool(sensor_sel_from_nfee_state &amp; sensor_sel_enum.F_SIDE)
    data_packet = v_start &lt; 4510
    overscan_packet = v_end &gt; 4509

    return [
        data_packet and e_side,
        data_packet and f_side,
        overscan_packet and e_side,
        overscan_packet and f_side
    ]</code></pre>
</details>
</dd>
<dt id="egse.dpu.get_expected_last_packet_flags"><code class="name flex">
<span>def <span class="ident">get_expected_last_packet_flags</span></span>(<span>register_map: Mapping[~KT, +VT_co], sensor_sel_enum: enum.Enum) ‑> List[bool]</span>
</code></dt>
<dd>
<div class="desc"><p>Build and returns a list of flags that define if a last packet is expected.</p>
<p>A last packet flag is expected for normal data packets and overscan data
packets. For both these data packets we can expect E-side and F-side packets
with a last packet flag. That brings the total expected flags to four. This
function examines the register values <code>v_start</code>, <code>v_end</code>, and <code>sensor_sel</code>.</p>
<p>The flags are ordered as follows:</p>
<ol>
<li>data packet and E-side</li>
<li>data packet and F-side</li>
<li>overscan data packet and E-side</li>
<li>overscan data packet and F-side</li>
</ol>
<p>Housekeeping packets are not considered here.</p>
<p>For comparing the flags with the actual data,
use the function <code><a title="egse.dpu.got_all_last_packets" href="#egse.dpu.got_all_last_packets">got_all_last_packets()</a>(actual, expected)</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>register_map</code></strong></dt>
<dd>the current Register map for the N-FEE</dd>
</dl>
<p>sensor_sel_enum:</p>
<h2 id="returns">Returns</h2>
<p>a list of flags.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_expected_last_packet_flags(register_map: Mapping, sensor_sel_enum: Enum) -&gt; List[bool]:
    &#34;&#34;&#34;
    Build and returns a list of flags that define if a last packet is expected.

    A last packet flag is expected for normal data packets and overscan data
    packets. For both these data packets we can expect E-side and F-side packets
    with a last packet flag. That brings the total expected flags to four. This
    function examines the register values `v_start`, `v_end`, and `sensor_sel`.

    The flags are ordered as follows:

    1. data packet and E-side
    2. data packet and F-side
    3. overscan data packet and E-side
    4. overscan data packet and F-side

    Housekeeping packets are not considered here.

    For comparing the flags with the actual data,
    use the function `got_all_last_packets(actual, expected)`.

    Args:
        register_map: the current Register map for the N-FEE
        sensor_sel_enum:
    Returns:
        a list of flags.
    &#34;&#34;&#34;
    sensor_sel_from_register = register_map[&#34;sensor_sel&#34;]

    e_side = bool(sensor_sel_from_register &amp; sensor_sel_enum.E_SIDE)
    f_side = bool(sensor_sel_from_register &amp; sensor_sel_enum.F_SIDE)
    v_start = register_map[&#34;v_start&#34;]
    v_end = register_map[&#34;v_end&#34;]
    data_packet = v_start &lt; 4510
    overscan_packet = v_end &gt; 4509

    return [
        data_packet and e_side,
        data_packet and f_side,
        overscan_packet and e_side,
        overscan_packet and f_side
    ]</code></pre>
</details>
</dd>
<dt id="egse.dpu.get_index_for_last_packet_flags"><code class="name flex">
<span>def <span class="ident">get_index_for_last_packet_flags</span></span>(<span>packet_type: int, ccd_side: int, ccd_sides_enum)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the index into the last packet flags list.</p>
<p>The last packet flags list is organised as follows:</p>
<pre><code>* index 0: data packet, E-side
* index 1: data packet, F-side
* index 2: overscan data packet, E-side
* index:3: overscan data packet, F-side
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>packet_type</code></strong></dt>
<dd>the packet type as read from the packet header [datapacket=0, overscan=1,
housekeeping=2]</dd>
<dt><strong><code>ccd_side</code></strong></dt>
<dd>the ccd side as read from the packet header</dd>
<dt><strong><code>ccd_sides_enum</code></strong></dt>
<dd>Enumeration with information on E and F</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The index for the last packet flags list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_index_for_last_packet_flags(packet_type: int, ccd_side: int, ccd_sides_enum):
    &#34;&#34;&#34;
    Returns the index into the last packet flags list.

    The last packet flags list is organised as follows:

        * index 0: data packet, E-side
        * index 1: data packet, F-side
        * index 2: overscan data packet, E-side
        * index:3: overscan data packet, F-side

    Args:
        packet_type: the packet type as read from the packet header [datapacket=0, overscan=1,
            housekeeping=2]
        ccd_side: the ccd side as read from the packet header
        ccd_sides_enum: Enumeration with information on E and F

    Returns:
        The index for the last packet flags list.
    &#34;&#34;&#34;
    if ccd_side == ccd_sides_enum.E_SIDE.value:
        return packet_type * 2
    else:
        return packet_type * 2 + 1</code></pre>
</details>
</dd>
<dt id="egse.dpu.got_all_last_packets"><code class="name flex">
<span>def <span class="ident">got_all_last_packets</span></span>(<span>actual, expected)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if all the expected last packet flags have been seen.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>actual</code></strong></dt>
<dd>the flags that have been seen so far</dd>
<dt><strong><code>expected</code></strong></dt>
<dd>the expected flags</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>True if 'actual' matches 'expected', False otherwise.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def got_all_last_packets(actual, expected):
    &#34;&#34;&#34;
    Returns True if all the expected last packet flags have been seen.

    Args:
        actual: the flags that have been seen so far
        expected: the expected flags

    Returns:
        True if &#39;actual&#39; matches &#39;expected&#39;, False otherwise.
    &#34;&#34;&#34;
    rc = all([x == y for (x, y) in zip(actual, expected)])
    # LOGGER.info(f&#34;{expected=}, {actual=}, {rc=}&#34;)
    return rc</code></pre>
</details>
</dd>
<dt id="egse.dpu.new_spw_data_file"><code class="name flex">
<span>def <span class="ident">new_spw_data_file</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, reg_map: <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a>, origin: str, data_type: Type[<a title="egse.storage.persistence.PersistenceLayer" href="../storage/persistence.html#egse.storage.persistence.PersistenceLayer">PersistenceLayer</a>], mon_socket: zmq.sugar.socket.Socket, dist_socket: zmq.sugar.socket.Socket)</span>
</code></dt>
<dd>
<div class="desc"><p>Open a new data file to store CCD data.</p>
<h2 id="args">Args</h2>
<ul>
<li>proxy: Storage manager.</li>
<li>origin: the origin for which to create a new file</li>
<li>reg_map: Register map.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_spw_data_file(
        proxy: StorageProxy, reg_map: RegisterMap, origin: str, data_type: Type[PersistenceLayer],
        mon_socket: zmq.Socket, dist_socket: zmq.Socket
):
    &#34;&#34;&#34;
    Open a new data file to store CCD data.

    Args:
        - proxy: Storage manager.
        - origin: the origin for which to create a new file
        - reg_map: Register map.
    &#34;&#34;&#34;

    LOGGER.debug(f&#34;Create a new data file for {origin} in the Storage&#34;)

    # prep = {
    #     &#34;expected_last_packet_flags&#34;: get_expected_last_packet_flags(reg_map),
    # }
    #
    # for name in CRUCIAL_REGISTER_PARAMETERS:
    #     prep[name] = reg_map[name]

    item = {
        &#34;origin&#34;: origin,
        &#34;persistence_class&#34;: data_type,
        &#34;prep&#34;: {},
    }

    # Retrieve the current filenames that will be available for processing as soon as the new
    # HDF5 file is registered and created by the storage manager. This should be done, of course,
    # before the new-registration call!

    hdf5_filenames = proxy.get_filenames(item={&#34;origin&#34;: origin})

    response = proxy.new_registration(item=item, use_counter=True)

    LOGGER.debug(f&#34;Response from new_registration: {response}&#34;)

    save_format_version(proxy, origin)

    # Save the Register Map that is used for the current readout cycle

    save_register_map(reg_map, proxy, origin, dist_socket)

    LOGGER.info(f&#34;HDF5 files ready for processing: {hdf5_filenames=}&#34;)

    pickle_string = pickle.dumps(hdf5_filenames)
    msg_id = MessageIdentifier.HDF5_FILENAMES.to_bytes(1, &#39;big&#39;)
    mon_socket.send_multipart([msg_id, pickle_string])</code></pre>
</details>
</dd>
<dt id="egse.dpu.process_high_priority_commands"><code class="name flex">
<span>def <span class="ident">process_high_priority_commands</span></span>(<span>priority_q: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, response_q: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, n_fee_state: tuple, dpu_internals: <a title="egse.dpu.DPUInternals" href="#egse.dpu.DPUInternals">DPUInternals</a>, reg_map: <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute high priority commands from the DPU Control Server /
Controller. The <code>n_fee_state</code> and
the <code>dpu_internals</code> tuples are passed to the high priority commands before any other arguments
that were passed on the command queue.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>priority_q</code></strong></dt>
<dd>the command queue with priority</dd>
<dt><strong><code>response_q</code></strong></dt>
<dd>the response queue</dd>
<dt><strong><code>n_fee_state</code></strong></dt>
<dd>a namedtuple containing the current state of the N-FEE</dd>
<dt><strong><code>dpu_internals</code></strong></dt>
<dd>the internal settings of the DPU might be requested or set
by a high priority command</dd>
<dt><strong><code>reg_map</code></strong></dt>
<dd>the current register map from the DPU Processor</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_high_priority_commands(
        priority_q: multiprocessing.Queue,
        response_q: multiprocessing.Queue,
        n_fee_state: tuple, dpu_internals: DPUInternals, reg_map: RegisterMap):
    &#34;&#34;&#34;
    Execute high priority commands from the DPU Control Server /  Controller. The `n_fee_state` and
    the `dpu_internals` tuples are passed to the high priority commands before any other arguments
    that were passed on the command queue.

    Args:
        priority_q: the command queue with priority
        response_q: the response queue
        n_fee_state: a namedtuple containing the current state of the N-FEE
        dpu_internals: the internal settings of the DPU might be requested or set
            by a high priority command
        reg_map: the current register map from the DPU Processor
    &#34;&#34;&#34;

    command = response = None
    try:
        (command, args) = priority_q.get_nowait()
        response = command(n_fee_state, dpu_internals, reg_map, *args)
        LOGGER.debug(f&#34;Command executed: {command.__name__}, {args=}, {response=}&#34;)
    except queue.Empty:
        pass
    except (Exception,) as exc:
        LOGGER.error(
            f&#34;Exception during command execution in DPU Processor: &#34;
            f&#34;{command}&#34;, exc_info=exc
        )
        raise NFEECommandError(
            f&#34;An exception occurred sending the command {command} &#34;
            f&#34;to the N-FEE.&#34;) from exc
    finally:
        if command is not None:
            response_q.put((command, response))</code></pre>
</details>
</dd>
<dt id="egse.dpu.process_hk_packet"><code class="name flex">
<span>def <span class="ident">process_hk_packet</span></span>(<span>hk_packet: <a title="egse.spw.HousekeepingPacket" href="../spw.html#egse.spw.HousekeepingPacket">HousekeepingPacket</a>, timestamp: str, storage: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, frame_number: int, mon_socket: zmq.sugar.socket.Socket, dist_socket: zmq.sugar.socket.Socket)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_hk_packet(hk_packet: HousekeepingPacket, timestamp: str,
                      storage: StorageProxy, origin: str, frame_number: int,
                      mon_socket: zmq.Socket, dist_socket: zmq.Socket):

    LOGGER.debug(f&#34;Saving Housekeeping packet: {hk_packet.type!s}, &#34;
                f&#34;frame counter={hk_packet.frame_counter}, &#34;
                f&#34;sequence counter={hk_packet.sequence_counter}&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin,
            &#34;data&#34;:
                {
                    f&#34;/{frame_number}/hk&#34;: hk_packet,
                }
        }
    )

    LOGGER.debug(f&#34;Response from saving HK Packet: {response}&#34;)

    msg_id = MessageIdentifier.SYNC_HK_PACKET.to_bytes(1, &#39;big&#39;)

    pickle_string = pickle.dumps((hk_packet.type, timestamp))
    mon_socket.send_multipart([msg_id, pickle_string])

    pickle_string = pickle.dumps((hk_packet, timestamp))
    dist_socket.send_multipart([msg_id, pickle_string])</code></pre>
</details>
</dd>
<dt id="egse.dpu.process_timecode"><code class="name flex">
<span>def <span class="ident">process_timecode</span></span>(<span>tc_packet: <a title="egse.spw.TimecodePacket" href="../spw.html#egse.spw.TimecodePacket">TimecodePacket</a>, timestamp: str, storage: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin_spw_data: str, frame_number: int, mon_socket: zmq.sugar.socket.Socket, dist_socket: zmq.sugar.socket.Socket)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_timecode(tc_packet: TimecodePacket, timestamp: str,
                     storage: StorageProxy, origin_spw_data: str, frame_number: int,
                     mon_socket: zmq.Socket, dist_socket: zmq.Socket):

    LOGGER.debug(f&#34;Saving timecode packet: {tc_packet.timecode=}, {frame_number=}&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin_spw_data,
            &#34;data&#34;:
                {
                    f&#34;/{frame_number}/timecode&#34;: tc_packet,
                    f&#34;/{frame_number}/timecode:ATTRS&#34;: [(&#34;timestamp&#34;, timestamp)],
                }
        }
    )

    LOGGER.debug(f&#34;Response from saving Timecode: {response}&#34;)

    pickle_string = pickle.dumps((tc_packet.timecode, timestamp))
    mon_socket.send_multipart([MessageIdentifier.SYNC_TIMECODE.to_bytes(1, &#34;big&#34;), pickle_string])
    dist_socket.send_multipart([MessageIdentifier.SYNC_TIMECODE.to_bytes(1, &#34;big&#34;), pickle_string])</code></pre>
</details>
</dd>
<dt id="egse.dpu.read_and_process_data_packets"><code class="name flex">
<span>def <span class="ident">read_and_process_data_packets</span></span>(<span>transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>, storage: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin_spw_data: str, start_time: float, mode: int, register_map: <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a>, data_attr: dict, internals: <a title="egse.dpu.DPUInternals" href="#egse.dpu.DPUInternals">DPUInternals</a>, dist_socket: zmq.sugar.socket.Socket)</span>
</code></dt>
<dd>
<div class="desc"><p>Read the data packets when they are available depending on the mode.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transport</code></strong></dt>
<dd>the SpaceWire interfaces that is used for communication to the N-FEE</dd>
<dt><strong><code>storage</code></strong></dt>
<dd>the proxy that is used to communicate with the Storage manager</dd>
<dt><strong><code>origin_spw_data</code></strong></dt>
<dd>the registration identifier for the Storage manager</dd>
<dt><strong><code>start_time</code></strong></dt>
<dd>the approximate time that the readout cycle started</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>FPGA mode</dd>
<dt><strong><code>register_map</code></strong></dt>
<dd>the DPU Processor's copy of the N-FEE register map</dd>
<dt><strong><code>data_attr</code></strong></dt>
<dd>register values to be saved with the data</dd>
<dt><strong><code>internals</code></strong></dt>
<dd>use for expected_last_packet_flags (these will be updated within this function)</dd>
<dt><strong><code>dist_socket</code></strong></dt>
<dd>the ZeroMQ socket to which SpW data is sent (for real-time view)</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>NoDataPacketError when the expected packet is not a data packet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_and_process_data_packets(
        transport: SpaceWireInterface, storage: StorageProxy, origin_spw_data: str,
        start_time: float, mode: int, register_map: RegisterMap, data_attr: dict,
        internals: DPUInternals, dist_socket: zmq.Socket
):
    &#34;&#34;&#34;
    Read the data packets when they are available depending on the mode.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin_spw_data: the registration identifier for the Storage manager
        start_time: the approximate time that the readout cycle started
        mode: FPGA mode
        register_map: the DPU Processor&#39;s copy of the N-FEE register map
        data_attr: register values to be saved with the data
        internals: use for expected_last_packet_flags (these will be updated within this function)
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Raises:
        NoDataPacketError when the expected packet is not a data packet.
    &#34;&#34;&#34;

    if internals.dump_mode or mode not in (
            n_fee_mode.FULL_IMAGE_PATTERN_MODE,
            n_fee_mode.WINDOWING_PATTERN_MODE,
            n_fee_mode.FULL_IMAGE_MODE,
    ):
        return

    timestamp = format_datetime()
    msg_id = MessageIdentifier.SYNC_DATA_PACKET.to_bytes(1, &#39;big&#39;)

    data_count = 0

    # Initialise the flags that determine if the last packet has arrived for
    # all expected data packets.

    actual_last_packet_flags = [False, False, False, False]

    # Read the data, until all the expected last packet bits are set.
    # This should be within next 4 seconds.

    LOGGER.debug(&#34;Reading data packets....&#34;)

    terminator, packet = transport.read_packet()

    data_packet: DataPacket = SpaceWirePacket.create_packet(packet)

    if (not isinstance(data_packet, DataDataPacket) and
            not isinstance(data_packet, OverscanDataPacket)):
        LOGGER.critical(f&#34;DataPacket expected, got {data_packet}&#34;)
        raise NoDataPacketError(f&#34;Expected a data packet, but got {data_packet.__class__.__name__}&#34;)

    # LOGGER.debug(f&#34;Got data packet of length {len(packet)}&#34;)

    LOGGER.debug(f&#34;Saving data packets: {data_packet.type!s}&#34;)

    item_data = {f&#34;/{internals.frame_number}/data/{data_count}&#34;: data_packet}

    attrs = [(k, v) for k, v in data_attr.items()]
    item_data.update({f&#34;/{internals.frame_number}/data:ATTRS&#34;: attrs})

    response = storage.save(
        {
            &#34;origin&#34;: origin_spw_data,
            &#34;data&#34;: item_data
        }
    )

    if isinstance(response, Exception):
        LOGGER.warning(f&#34;Response from saving data packet: {response}&#34;)

    pickle_string = pickle.dumps((data_packet, timestamp))
    dist_socket.send_multipart([msg_id, pickle_string])

    data_count += 1

    # Update the expected flags with the possibly new register values, but only
    # after we had the 400ms pulse which updates the settings from the
    # register map. The test is needed because the register here on the DPU
    # processing side can be updated also on 200ms sync pulses, but the changes
    # only take effect on the 400ms pulse in the N-FEE.

    if data_packet.type.frame_number == 0:
        internals.expected_last_packet_flags = get_expected_last_packet_flags(register_map, internals.sensor_sel_enum)
        LOGGER.debug(f&#34;{internals.expected_last_packet_flags=}&#34;)

    idx = get_index_for_last_packet_flags(data_packet.type.packet_type, data_packet.type.ccd_side,
                                          internals.ccd_sides_enum)
    # LOGGER.debug(f&#34;{idx=}, {data_packet.type.packet_type=}, {data_packet.type.ccd_side=}&#34;)
    actual_last_packet_flags[idx] = data_packet.type.last_packet

    while not got_all_last_packets(
            actual_last_packet_flags, internals.expected_last_packet_flags):

        terminator, packet = transport.read_packet()
        data_packet: DataPacket = SpaceWirePacket.create_packet(packet)

        if (not isinstance(data_packet, DataDataPacket) and
                not isinstance(data_packet, OverscanDataPacket)):
            LOGGER.critical(f&#34;DataPacket expected, got {data_packet}&#34;)
            raise NoDataPacketError(
                f&#34;Expected a data packet, but got {data_packet.__class__.__name__}&#34;)

        # LOGGER.debug(f&#34;Saving data packet: {data_packet.type!s}&#34;)

        response = storage.save(
            {
                &#34;origin&#34;: origin_spw_data,
                &#34;data&#34;:
                    {
                        f&#34;/{internals.frame_number}/data/{data_count}&#34;: data_packet,
                    }
            }
        )

        if isinstance(response, Exception):
            LOGGER.warning(f&#34;Response from saving data packet: {response}&#34;)

        pickle_string = pickle.dumps((data_packet, timestamp))
        dist_socket.send_multipart([msg_id, pickle_string])

        data_count += 1

        #LOGGER.debug(f&#34;Got data packet of length {len(packet)}&#34;)
        #LOGGER.debug(f&#34;DataPacketHeader: {data_packet.header.type_as_object}&#34;)

        idx = get_index_for_last_packet_flags(data_packet.type.packet_type, data_packet.type.ccd_side,
                                              internals.ccd_sides_enum)
        actual_last_packet_flags[idx] = data_packet.type.last_packet

        # Sending data packets shall not take more than 4 seconds, and if we
        # wait longer than 6.25 seconds, all RMAP commands that we send will be
        # discarded.

        if time.perf_counter() &gt; start_time + 5.25:
            raise TimeExceededError(
                &#34;Retrieving data packets exceeded the allowed 4.0 seconds, &#34;
                &#34;breaking out of the data loop.&#34;
            )</code></pre>
</details>
</dd>
<dt id="egse.dpu.read_hk_packet"><code class="name flex">
<span>def <span class="ident">read_hk_packet</span></span>(<span>transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>) ‑> (<class '<a title="egse.spw.HousekeepingPacket" href="../spw.html#egse.spw.HousekeepingPacket">HousekeepingPacket</a>'>, <class 'str'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Read the next Housekeeping Packet from the N-FEE. The packet is sent to the Storage manager.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transport</code></strong></dt>
<dd>the SpaceWire interfaces that is used for communication to the N-FEE</dd>
<dt><strong><code>storage</code></strong></dt>
<dd>the proxy that is used to communicate with the Storage manager</dd>
<dt><strong><code>origin</code></strong></dt>
<dd>the registration identifier for the Storage manager</dd>
<dt><strong><code>mon_socket</code></strong></dt>
<dd>the ZeroMQ socket to which monitoring sync signals are sent</dd>
<dt><strong><code>dist_socket</code></strong></dt>
<dd>the ZeroMQ socket to which SpW data is sent (for real-time view)</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>NoHousekeepingPacketError when the next packet is not a <code>HousekeepingPacket</code>.</p>
<h2 id="returns">Returns</h2>
<p>the received housekeeping packet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_hk_packet(transport: SpaceWireInterface) -&gt; (HousekeepingPacket, str):
    &#34;&#34;&#34;
    Read the next Housekeeping Packet from the N-FEE. The packet is sent to the Storage manager.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin: the registration identifier for the Storage manager
        mon_socket: the ZeroMQ socket to which monitoring sync signals are sent
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Raises:
        NoHousekeepingPacketError when the next packet is not a `HousekeepingPacket`.
    Returns:
        the received housekeeping packet.
    &#34;&#34;&#34;
    terminator, packet = transport.read_packet()
    timestamp = format_datetime()

    if not is_hk_data_packet(packet):
        packet = SpaceWirePacket.create_packet(packet)
        raise NoHousekeepingPacketError(
            f&#34;Expected a Housekeeping packet, but got {packet.__class__.__name__}&#34;)

    hk_packet: HousekeepingPacket = SpaceWirePacket.create_packet(packet)

    LOGGER.info(f&#34;Housekeeping Packet received: {hk_packet.type!s}&#34;)

    return hk_packet, timestamp</code></pre>
</details>
</dd>
<dt id="egse.dpu.read_timecode"><code class="name flex">
<span>def <span class="ident">read_timecode</span></span>(<span>transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>) ‑> (<class '<a title="egse.spw.TimecodePacket" href="../spw.html#egse.spw.TimecodePacket">TimecodePacket</a>'>, <class 'str'>, <class 'float'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads the next Timecode packet from the N-FEE. When the Timecode packet is received,
the packet and a timestamp is sent to the Storage manager.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transport</code></strong></dt>
<dd>the SpaceWire interfaces that is used for communication to the N-FEE</dd>
<dt><strong><code>storage</code></strong></dt>
<dd>the proxy that is used to communicate with the Storage manager</dd>
<dt><strong><code>origin_spw_data</code></strong></dt>
<dd>the registration identifier for the Storage manager, for the SpW data</dd>
<dt><strong><code>mon_socket</code></strong></dt>
<dd>the ZeroMQ socket to which monitoring sync signals are sent</dd>
<dt><strong><code>dist_socket</code></strong></dt>
<dd>the ZeroMQ socket to which SpW data is sent (for real-time view)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The approximate start time for this readout cycle.</p>
<h2 id="raises">Raises</h2>
<p>NoTimecodeError when the timecode could not be read.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_timecode(transport: SpaceWireInterface) -&gt; (TimecodePacket, str, float):
    &#34;&#34;&#34;
    Reads the next Timecode packet from the N-FEE. When the Timecode packet is received,
    the packet and a timestamp is sent to the Storage manager.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin_spw_data: the registration identifier for the Storage manager, for the SpW data
        mon_socket: the ZeroMQ socket to which monitoring sync signals are sent
        dist_socket: the ZeroMQ socket to which SpW data is sent (for real-time view)

    Returns:
        The approximate start time for this readout cycle.
    Raises:
        NoTimecodeError when the timecode could not be read.
    &#34;&#34;&#34;
    terminator, packet = transport.read_packet(timeout=100)
    timestamp = format_datetime()

    if terminator is None and packet is None:
        raise TimecodeTimeoutError()

    # Start time taken as closely as possible to timecode reception, this start_time is
    # returned to be used in further functions called in the outer loop.

    start_time = time.perf_counter()
    # LOGGER.debug(f&#34;Time set: {start_time}&#34;)

    bytes_received = len(packet)

    # The following check is to cope with loss of connection when either the
    # FEE simulator crashes or the connection dropped for some other reason.
    # We will receive one packet with 0 or 1 bytes.

    if bytes_received in {0, 1}:
        raise NoBytesReceivedError(f&#34;{bytes_received} bytes received, lost connection to FEE?&#34;)

    if not is_timecode(packet):
        packet = SpaceWirePacket.create_packet(packet)
        raise NoTimeCodeError(f&#34;Expected Timecode Packet, but got {packet.__class__.__name__}&#34;)

    tc_packet: TimecodePacket = SpaceWirePacket.create_packet(packet)

    LOGGER.info(f&#34;Timecode received: {tc_packet.timecode}&#34;)

    return tc_packet, timestamp, start_time</code></pre>
</details>
</dd>
<dt id="egse.dpu.register_to_storage_manager"><code class="name flex">
<span>def <span class="ident">register_to_storage_manager</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_to_storage_manager(proxy: StorageProxy, origin: str):
    rc = proxy.new_registration(
        item={
            &#34;origin&#34;: origin,
            &#34;persistence_class&#34;: HDF5,
            &#34;prep&#34;: {
                &#34;mode&#34;: &#34;w-&#34;,
            },
        },
        use_counter=True
    )
    LOGGER.info(f&#34;{rc=!s}&#34;)
    if rc and not rc.successful:
        LOGGER.warning(f&#34;Couldn&#39;t register to the Storage manager: {rc}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.save_format_version"><code class="name flex">
<span>def <span class="ident">save_format_version</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_format_version(proxy: StorageProxy, origin: str):

    # 2.0 - introduced the format_version
    # 2.1 - Added obsid as a dataset to the HDF5 file
    # 2.2 - Multiple commands can now be saved under the same frame number
    # 2.3 - introduced /dpu/num_cycles attribute
    # 2.4 - introduced /dpu/slicing_num_cycles attribute

    major_version = 2
    minor_version = 4

    item_data = {
        &#34;/versions/format_version/&#34;: &#34;format version of HDF5 file&#34;,
        &#34;/versions/format_version:ATTRS&#34;: [
            (&#34;major_version&#34;, major_version),
            (&#34;minor_version&#34;, minor_version)
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving format_version: {response}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.save_num_cycles"><code class="name flex">
<span>def <span class="ident">save_num_cycles</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, num_cycles: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the number of cycles to the storage. This will only save if num_cycles &gt;= 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_num_cycles(proxy: StorageProxy, origin: str, num_cycles: int):
    &#34;&#34;&#34;Save the number of cycles to the storage. This will only save if num_cycles &gt;= 0.&#34;&#34;&#34;

    # Only save num_cycles &gt;= 0, the DPU Processor understands when num_cycles is negative,
    # but for the HDF5 file we want to keep it clean and always have num_cycles &gt;= 0.

    num_cycles = max(num_cycles, 0)

    item_data = {
        &#34;/dpu/&#34;: &#34;DPU specific parameters&#34;,
        &#34;/dpu/:ATTRS&#34;: [
            (&#34;num_cycles&#34;, num_cycles),
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving NUM_CYCLES: {response}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.save_obsid"><code class="name flex">
<span>def <span class="ident">save_obsid</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, obsid: <a title="egse.obsid.ObservationIdentifier" href="../obsid.html#egse.obsid.ObservationIdentifier">ObservationIdentifier</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_obsid(proxy: StorageProxy, origin: str, obsid: ObservationIdentifier):

    item_data = {
        &#34;/obsid&#34;: str(obsid),
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving OBSID: {response}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.save_register_map"><code class="name flex">
<span>def <span class="ident">save_register_map</span></span>(<span>reg_map: <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a>, storage: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, dist_socket: zmq.sugar.socket.Socket)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_register_map(
        reg_map: RegisterMap, storage: StorageProxy, origin: str, dist_socket: zmq.Socket):

    reg_memory_map = reg_map.get_memory_map_as_ndarray()

    LOGGER.debug(&#34;Saving register map&#34;)

    response = storage.save(
        {
            &#34;origin&#34;: origin,
            &#34;data&#34;: {
                &#34;/register/&#34;: reg_memory_map
            }
        }
    )

    LOGGER.debug(f&#34;Response from saving Register Map: {response}&#34;)

    pickle_string = pickle.dumps(reg_memory_map)
    msg_id = MessageIdentifier.N_FEE_REGISTER_MAP.to_bytes(1, &#39;big&#39;)
    dist_socket.send_multipart([msg_id, pickle_string])</code></pre>
</details>
</dd>
<dt id="egse.dpu.save_slicing_parameter"><code class="name flex">
<span>def <span class="ident">save_slicing_parameter</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, slicing_num_cycles: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the number of cycles to use for slicing to the storage.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_slicing_parameter(proxy: StorageProxy, origin: str, slicing_num_cycles: int):
    &#34;&#34;&#34;Save the number of cycles to use for slicing to the storage.&#34;&#34;&#34;

    item_data = {
        &#34;/dpu/:ATTRS&#34;: [
            (&#34;slicing_num_cycles&#34;, slicing_num_cycles),
        ]
    }
    item = {
        &#34;origin&#34;: origin,
        &#34;data&#34;: item_data,
    }
    response = proxy.save(item)
    LOGGER.debug(f&#34;Response from saving SLICING_NUM_CYCLES: {response}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.send_commands_to_n_fee"><code class="name flex">
<span>def <span class="ident">send_commands_to_n_fee</span></span>(<span>transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>, storage: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str, register_map: <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a>, command_q: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, response_q: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, internals: <a title="egse.dpu.DPUInternals" href="#egse.dpu.DPUInternals">DPUInternals</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Send RMAP commands to the N-FEE. The commands are read from the command queue that is shared
with the DPU Controller. The response from the N-FEE is put on the response queue, also shared
with the DPU Controller.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The current implementation allows only one command from the command queue per sync cycle.</p>
</div>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transport</code></strong></dt>
<dd>the SpaceWire interfaces that is used for communication to the N-FEE</dd>
<dt><strong><code>storage</code></strong></dt>
<dd>the proxy that is used to communicate with the Storage manager</dd>
<dt><strong><code>origin</code></strong></dt>
<dd>the registration identifier for the Storage manager</dd>
<dt><strong><code>register_map</code></strong></dt>
<dd>the DPU Processor's copy of the N-FEE register map</dd>
<dt><strong><code>command_q</code></strong></dt>
<dd>the command queue</dd>
<dt><strong><code>response_q</code></strong></dt>
<dd>the response queue</dd>
<dt><strong><code>internals</code></strong></dt>
<dd>for some commands we need access to DPUInternals, e.g. num_cycles, dump_mode_int</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>Exceptions are caught and put on the response queue.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_commands_to_n_fee(
        transport: SpaceWireInterface, storage: StorageProxy, origin: str,
        register_map: RegisterMap,
        command_q: multiprocessing.Queue,
        response_q: multiprocessing.Queue,
        internals: DPUInternals
):
    &#34;&#34;&#34;
    Send RMAP commands to the N-FEE. The commands are read from the command queue that is shared
    with the DPU Controller. The response from the N-FEE is put on the response queue, also shared
    with the DPU Controller.

    !!! note
        The current implementation allows only one command from the command queue per sync cycle.

    Args:
        transport: the SpaceWire interfaces that is used for communication to the N-FEE
        storage: the proxy that is used to communicate with the Storage manager
        origin: the registration identifier for the Storage manager
        register_map: the DPU Processor&#39;s copy of the N-FEE register map
        command_q: the command queue
        response_q: the response queue
        internals: for some commands we need access to DPUInternals, e.g. num_cycles, dump_mode_int

    Raises:
        Exceptions are caught and put on the response queue.
    &#34;&#34;&#34;

    if internals.clear_error_flags:
        LOGGER.debug(&#34;Clearing error flags&#34;)
        _ = command_set_clear_error_flags(transport, register_map)
        internals.clear_error_flags = False

    command = response = None
    kwargs = {}
    try:
        (command, args, kwargs) = command_q.get_nowait()

        # When num_cycles is not specified, don&#39;t even set it to 0, the N-FEE will stay in the
        # current configuration until commanded otherwise.

        if num_cycles := kwargs.get(&#34;num_cycles&#34;):
            LOGGER.debug(f&#34;Set internals.num_cycle to {num_cycles}.&#34;)
            internals.num_cycles = num_cycles

        # Some commanding requires to go back into internal sync dump mode

        dump_mode_int = kwargs.get(&#34;dump_mode_int&#34;, False)
        LOGGER.debug(f&#34;Set internals.dump_mode_int to {dump_mode_int}.&#34;)
        internals.dump_mode_int = dump_mode_int

        LOGGER.debug(f&#34;Executing Command: {command.__name__}, {args=}&#34;)
        response = command(transport, register_map, *args)
        LOGGER.debug(f&#34;Command executed: {command.__name__}, {args=}, {response=}&#34;)

        LOGGER.debug(f&#34;Saving command: {command.__name__}, {args=}&#34;)

        response_save = storage.save({
            &#34;origin&#34;: origin,
            &#34;data&#34;: {
                f&#34;/{internals.frame_number}/command/&#34;: f&#34;{command.__name__}, {args=}, {kwargs=}&#34;,
            }
        })

        LOGGER.debug(f&#34;Response from saving Command: {response_save}&#34;)

    except queue.Empty:
        pass
    except (Exception,) as exc:
        LOGGER.error(
            f&#34;Exception during command execution in DPU Processor: &#34;
            f&#34;{command}&#34;, exc_info=exc
        )
        raise NFEECommandError(
            f&#34;An exception occurred sending the command {command} &#34;
            f&#34;to the N-FEE.&#34;) from exc
    finally:
        if command is not None and kwargs.get(&#39;response&#39;, True):
            response_q.put((command, response))</code></pre>
</details>
</dd>
<dt id="egse.dpu.unregister_from_storage_manager"><code class="name flex">
<span>def <span class="ident">unregister_from_storage_manager</span></span>(<span>proxy: <a title="egse.storage.StorageProxy" href="../storage/index.html#egse.storage.StorageProxy">StorageProxy</a>, origin: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unregister_from_storage_manager(proxy: StorageProxy, origin: str):

    try:
        rc = proxy.unregister({&#34;origin&#34;: origin})
        if not rc.successful:
            LOGGER.warning(f&#34;Couldn&#39;t unregister from the Storage manager: {rc}&#34;)

    except ConnectionError as exc:
        LOGGER.warning(f&#34;Couldn&#39;t connect to the Storage manager for de-registration: {exc}&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.update_data_attributes"><code class="name flex">
<span>def <span class="ident">update_data_attributes</span></span>(<span>attr: dict, n_fee_state: egse.dpu.dpu.StateTuple) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Collect parameter/value pairs that will be added to the data group as attributes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>attr</code></strong> :&ensp;<code>dict</code></dt>
<dd>the current attributes that need to be updated</dd>
<dt><strong><code>n_fee_state</code></strong></dt>
<dd>the current state of the N-FEE</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Updated data attributes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_data_attributes(attr: dict, n_fee_state: NFEEState.StateTuple) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;
    Collect parameter/value pairs that will be added to the data group as attributes.

    Args:
        attr (dict): the current attributes that need to be updated
        n_fee_state: the current state of the N-FEE

    Returns:
        Updated data attributes.
    &#34;&#34;&#34;

    attr.update(n_fee_state._asdict())
    return attr</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="egse.dpu.DPUCommand"><code class="flex name class">
<span>class <span class="ident">DPUCommand</span></span>
<span>(</span><span>name, cmd, response=None, wait=None, check=None, description=None, device_method=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Command is basically a string that is send to a device and for which the
device returns a response.</p>
<p>The command string can contain placeholders that will be filled when the
command is 'called'.</p>
<p>The arguments that are given will be filled into the formatted string.
Arguments can be positional or keyword arguments, not both.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUCommand(ClientServerCommand):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="egse.command.ClientServerCommand" href="../command.html#egse.command.ClientServerCommand">ClientServerCommand</a></li>
<li><a title="egse.command.Command" href="../command.html#egse.command.Command">Command</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="egse.command.ClientServerCommand" href="../command.html#egse.command.ClientServerCommand">ClientServerCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.command.ClientServerCommand.client_call" href="../command.html#egse.command.ClientServerCommand.client_call">client_call</a></code></li>
<li><code><a title="egse.command.ClientServerCommand.server_call" href="../command.html#egse.command.ClientServerCommand.server_call">server_call</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="egse.dpu.DPUController"><code class="flex name class">
<span>class <span class="ident">DPUController</span></span>
<span>(</span><span>priority_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, command_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, response_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>)</span>
</code></dt>
<dd>
<div class="desc"><p>The DPU Controller puts commands on the command queue for processing by the DPU Processor.
Any response from the DPU Processor will be available on the response queue as soon as the
command has been executed. The DPU Processor is a separate process that is started by the
DPU Command Protocol.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUController(DPUInterface):
    &#34;&#34;&#34;
    The DPU Controller puts commands on the command queue for processing by the DPU Processor.
    Any response from the DPU Processor will be available on the response queue as soon as the
    command has been executed. The DPU Processor is a separate process that is started by the
    DPU Command Protocol.
    &#34;&#34;&#34;

    def __init__(self,
                 priority_queue: multiprocessing.Queue,
                 command_queue: multiprocessing.Queue,
                 response_queue: multiprocessing.Queue):
        self._priority_q = priority_queue
        self._command_q = command_queue
        self._response_q = response_queue

        try:
            self.default_ccd_readout_order = GlobalState.setup.camera.fee.ccd_numbering.DEFAULT_CCD_READOUT_ORDER
            self.sensor_sel_both_sides = GlobalState.setup.camera.fee.sensor_sel.enum.BOTH_SIDES.value
        except AttributeError:
            raise SetupError(&#34;No entry in the setup for camera.fee.ccd_numbering.DEFAULT_CCD_READOUT_ORDER&#34;)

    def marker(self, mark: str):
        LOGGER.info(f&#34;{mark = }&#34;)

    def get_slicing(self) -&gt; int:
        self._priority_q.put((prio_command_get_slicing, []))
        LOGGER.debug(&#34;Controller.get_slicing: Put prio_command_get_slicing on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.get_slicing returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def set_slicing(self, num_cycles: int):
        self._priority_q.put((prio_command_set_slicing, [num_cycles]))
        LOGGER.debug(
            &#34;Controller.set_slicing: Put prio_command_set_slicing on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.set_slicing returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def is_simulator(self):
        return True

    def n_fee_sync_register_map(self) -&gt; RegisterMap:
        self._command_q.put((command_sync_register_map, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_sync_register_map: Put command_sync_register_map on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_sync_register_map returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def get_register_map(self) -&gt; RegisterMap:
        self._priority_q.put((prio_command_get_register_map, []))
        LOGGER.debug(&#34;Controller.get_register_map: Put prio_command_get_register_map on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.get_register_map returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_get_mode(self):
        self._priority_q.put((prio_command_get_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_get_mode: Put prio_command_get_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_get_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_get_sync_mode(self):
        self._priority_q.put((prio_command_get_sync_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_get_sync_mode: Put prio_command_get_sync_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_get_sync_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_is_dump_mode(self):
        self._priority_q.put((prio_command_is_dump_mode, []))
        LOGGER.debug(&#34;Controller.n_fee_is_dump_mode: Put prio_command_is_dump_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_is_dump_mode returned: ({cmd.__name__}, {response}).&#34;)
        return response

    def n_fee_set_immediate_on_mode(self):
        self._command_q.put((command_set_immediate_on_mode, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_immediate_on_mode: Put command_set_immediate_on_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_immediate_on_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_on_mode(self):
        self._command_q.put((command_set_on_mode, [], {}))
        LOGGER.debug(&#34;Controller.n_fee_set_on_mode: Put command_set_on_mode on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_on_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_standby_mode(self):
        self._command_q.put((command_set_standby_mode, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_standby_mode: Put command_set_standby_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_standby_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        sync_sel = n_fee_parameters.get(&#34;sync_sel&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put((command_set_dump_mode,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, sync_sel],
                             {&#39;num_cycles&#39;: num_cycles}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_dump_mode: Put command_set_dump_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_dump_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_dump_mode_int_sync(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        sync_sel = n_fee_parameters.get(&#34;sync_sel&#34;, 1)
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 2500)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put(
            (
                command_set_dump_mode_int_sync,
                [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, int_sync_period, sync_sel],
                {&#39;num_cycles&#39;: num_cycles}
            )
        )
        LOGGER.debug(&#34;Controller.n_fee_set_dump_mode_int_sync: &#34;
                     &#34;Put command_set_dump_mode_int_sync on the Queue.&#34;)
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_dump_mode_int_sync returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, False)
        self._command_q.put((command_set_full_image_mode,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_mode: Put command_set_full_image_mode on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_full_image_mode returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 6250)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, True)
        self._command_q.put((command_set_full_image_mode_int_sync,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, int_sync_period],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_mode_int_sync: Put command_set_full_image_mode_int_sync on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_full_image_mode_int_sync returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_full_image_pattern_mode(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 1)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        self._command_q.put((command_set_full_image_pattern_mode,
                             [v_start, v_end, sensor_sel_],
                             {&#39;num_cycles&#39;: num_cycles}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_full_image_pattern_mode: Put command_set_full_image_pattern_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_full_image_pattern_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_high_precision_hk_mode(self, n_fee_parameters:dict):
        high_hk = n_fee_parameters.get(&#34;high_precision_hk&#34;, False)
        self._command_q.put((command_set_high_precision_hk_mode, [high_hk], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_high_precision_hk_mode: Put command_set_high_precision_hk_mode &#34;
            &#34;on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_high_precision_hk_mode returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        int_sync_period = n_fee_parameters.get(&#34;int_sync_period&#34;, 6250)
        self._command_q.put((command_internal_clock, [int_sync_period], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_internal_sync: Put command_internal_clock on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_internal_sync returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_external_sync(self, n_fee_parameters: dict):
        self._command_q.put((command_external_clock, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_internal_sync: Put command_internal_clock on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_internal_sync returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_set_register_value(self, reg_name: str, field_name: str, field_value: int):
        self._command_q.put((command_set_register_value, [reg_name, field_name, field_value], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_register_value: Put command_set_register_value on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(
            f&#34;Controller.n_fee_set_register_value returned: ({cmd.__name__}, {response})&#34;
        )
        return response

    def n_fee_reset(self):
        self._command_q.put((command_reset, [], {}))
        LOGGER.debug(
            &#34;Controller.n_fee_reset: Put command_reset on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_reset returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_clear_error_flags(self):

        self._command_q.put((command_set_clear_error_flags, [], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_clear_error_flags: &#34;
                     &#34;Put command_set_clear_error_flags on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_clear_error_flags returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        img_clk_dir = n_fee_parameters.get(&#34;img_clk_dir&#34;, 1)
        reg_clk_dir = n_fee_parameters.get(&#34;reg_clk_dir&#34;, 0)
        dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, False)

        self._command_q.put((command_set_reverse_clocking,
                             [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, img_clk_dir, reg_clk_dir],
                             {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
        LOGGER.debug(
            &#34;Controller.n_fee_set_reverse_clocking: Put command_set_reverse_clocking on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_reverse_clocking returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_charge_injection(self, n_fee_parameters: dict):
        num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
        v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
        v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
        n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
        sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
        ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
        charge_injection_width = n_fee_parameters.get(&#34;charge_injection_width&#34;, 0)
        charge_injection_gap = n_fee_parameters.get(&#34;charge_injection_gap&#34;, 0)

        self._command_q.put(
            (
                command_set_charge_injection,
                [
                    v_start, v_end, n_final_dump, sensor_sel_, ccd_readout_order,
                    charge_injection_width, charge_injection_gap
                ],
                {&#39;num_cycles&#39;: num_cycles}
            ))
        LOGGER.debug(
            &#34;Controller.n_fee_set_dump_mode: Put command_set_charge_injection on the Queue.&#34;
        )
        (cmd, response) = self._response_q.get()
        LOGGER.debug(f&#34;Controller.n_fee_set_charge_injection returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_vgd(self, n_fee_parameters: dict):

        # The default value for ccd_vgd_config is 0xCFE = hex(int(19.90/5.983*1000))
        # This value is taken from: PLATO-MSSL-PL-FI-0001_9.0_N-FEE_Register_Map Draft A

        ccd_vgd_config = n_fee_parameters.get(&#34;ccd_vgd_config&#34;, 19.90)

        self._command_q.put((command_set_vgd, [ccd_vgd_config], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_vgd: Put command_set_vgd on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_vgd returned: ({cmd.__name__}, {response})&#34;)
        return response

    def n_fee_set_fpga_defaults(self):
        self._command_q.put((command_set_nfee_fpga_defaults, [], {}))

        LOGGER.debug(&#34;Controller.n_fee_set_fpga_defaults: Put n_fee_set_fpga_defaults on the Queue.&#34;)

        (cmd, response) = self._response_q.get()

        LOGGER.debug(f&#34;Controller.n_fee_set_fpga_defaults returned: ({cmd.__name__}, {response})&#34;)
        return response</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUController.get_slicing"><code class="name flex">
<span>def <span class="ident">get_slicing</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_slicing(self) -&gt; int:
    self._priority_q.put((prio_command_get_slicing, []))
    LOGGER.debug(&#34;Controller.get_slicing: Put prio_command_get_slicing on the Queue.&#34;)
    (cmd, response) = self._response_q.get()
    LOGGER.debug(f&#34;Controller.get_slicing returned: ({cmd.__name__}, {response}).&#34;)
    return response</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.is_simulator"><code class="name flex">
<span>def <span class="ident">is_simulator</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_simulator(self):
    return True</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.marker"><code class="name flex">
<span>def <span class="ident">marker</span></span>(<span>self, mark: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def marker(self, mark: str):
    LOGGER.info(f&#34;{mark = }&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.n_fee_set_charge_injection"><code class="name flex">
<span>def <span class="ident">n_fee_set_charge_injection</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_fee_set_charge_injection(self, n_fee_parameters: dict):
    num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
    v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
    v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
    n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
    sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
    ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
    charge_injection_width = n_fee_parameters.get(&#34;charge_injection_width&#34;, 0)
    charge_injection_gap = n_fee_parameters.get(&#34;charge_injection_gap&#34;, 0)

    self._command_q.put(
        (
            command_set_charge_injection,
            [
                v_start, v_end, n_final_dump, sensor_sel_, ccd_readout_order,
                charge_injection_width, charge_injection_gap
            ],
            {&#39;num_cycles&#39;: num_cycles}
        ))
    LOGGER.debug(
        &#34;Controller.n_fee_set_dump_mode: Put command_set_charge_injection on the Queue.&#34;
    )
    (cmd, response) = self._response_q.get()
    LOGGER.debug(f&#34;Controller.n_fee_set_charge_injection returned: ({cmd.__name__}, {response})&#34;)
    return response</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.n_fee_set_fpga_defaults"><code class="name flex">
<span>def <span class="ident">n_fee_set_fpga_defaults</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_fee_set_fpga_defaults(self):
    self._command_q.put((command_set_nfee_fpga_defaults, [], {}))

    LOGGER.debug(&#34;Controller.n_fee_set_fpga_defaults: Put n_fee_set_fpga_defaults on the Queue.&#34;)

    (cmd, response) = self._response_q.get()

    LOGGER.debug(f&#34;Controller.n_fee_set_fpga_defaults returned: ({cmd.__name__}, {response})&#34;)
    return response</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.n_fee_set_reverse_clocking"><code class="name flex">
<span>def <span class="ident">n_fee_set_reverse_clocking</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):
    v_start = n_fee_parameters.get(&#34;v_start&#34;, 0)
    v_end = n_fee_parameters.get(&#34;v_end&#34;, 4509)
    sensor_sel_ = n_fee_parameters.get(&#34;sensor_sel&#34;, self.sensor_sel_both_sides)
    ccd_readout_order = n_fee_parameters.get(&#34;ccd_readout_order&#34;, self.default_ccd_readout_order)
    n_final_dump = n_fee_parameters.get(&#34;n_final_dump&#34;, 0)
    num_cycles = n_fee_parameters.get(&#34;num_cycles&#34;, 0)
    img_clk_dir = n_fee_parameters.get(&#34;img_clk_dir&#34;, 1)
    reg_clk_dir = n_fee_parameters.get(&#34;reg_clk_dir&#34;, 0)
    dump_mode_int = n_fee_parameters.get(&#34;dump_mode_int&#34;, False)

    self._command_q.put((command_set_reverse_clocking,
                         [v_start, v_end, sensor_sel_, ccd_readout_order, n_final_dump, img_clk_dir, reg_clk_dir],
                         {&#39;num_cycles&#39;: num_cycles, &#39;dump_mode_int&#39;: dump_mode_int}))
    LOGGER.debug(
        &#34;Controller.n_fee_set_reverse_clocking: Put command_set_reverse_clocking on the Queue.&#34;
    )
    (cmd, response) = self._response_q.get()
    LOGGER.debug(f&#34;Controller.n_fee_set_reverse_clocking returned: ({cmd.__name__}, {response})&#34;)
    return response</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.n_fee_set_vgd"><code class="name flex">
<span>def <span class="ident">n_fee_set_vgd</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_fee_set_vgd(self, n_fee_parameters: dict):

    # The default value for ccd_vgd_config is 0xCFE = hex(int(19.90/5.983*1000))
    # This value is taken from: PLATO-MSSL-PL-FI-0001_9.0_N-FEE_Register_Map Draft A

    ccd_vgd_config = n_fee_parameters.get(&#34;ccd_vgd_config&#34;, 19.90)

    self._command_q.put((command_set_vgd, [ccd_vgd_config], {}))

    LOGGER.debug(&#34;Controller.n_fee_set_vgd: Put command_set_vgd on the Queue.&#34;)

    (cmd, response) = self._response_q.get()

    LOGGER.debug(f&#34;Controller.n_fee_set_vgd returned: ({cmd.__name__}, {response})&#34;)
    return response</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUController.set_slicing"><code class="name flex">
<span>def <span class="ident">set_slicing</span></span>(<span>self, num_cycles: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_slicing(self, num_cycles: int):
    self._priority_q.put((prio_command_set_slicing, [num_cycles]))
    LOGGER.debug(
        &#34;Controller.set_slicing: Put prio_command_set_slicing on the Queue.&#34;
    )
    (cmd, response) = self._response_q.get()
    LOGGER.debug(f&#34;Controller.set_slicing returned: ({cmd.__name__}, {response}).&#34;)
    return response</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.dpu.DPUInterface.get_register_map" href="#egse.dpu.DPUInterface.get_register_map">get_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_mode" href="#egse.dpu.DPUInterface.n_fee_get_mode">n_fee_get_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_sync_mode" href="#egse.dpu.DPUInterface.n_fee_get_sync_mode">n_fee_get_sync_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_high_precision_hk_mode" href="#egse.dpu.DPUInterface.n_fee_high_precision_hk_mode">n_fee_high_precision_hk_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_is_dump_mode" href="#egse.dpu.DPUInterface.n_fee_is_dump_mode">n_fee_is_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_reset" href="#egse.dpu.DPUInterface.n_fee_reset">n_fee_reset</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_clear_error_flags" href="#egse.dpu.DPUInterface.n_fee_set_clear_error_flags">n_fee_set_clear_error_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode">n_fee_set_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync">n_fee_set_dump_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_external_sync" href="#egse.dpu.DPUInterface.n_fee_set_external_sync">n_fee_set_external_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode">n_fee_set_full_image_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync">n_fee_set_full_image_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode">n_fee_set_full_image_pattern_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_immediate_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_immediate_on_mode">n_fee_set_immediate_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_internal_sync" href="#egse.dpu.DPUInterface.n_fee_set_internal_sync">n_fee_set_internal_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_on_mode">n_fee_set_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_register_value" href="#egse.dpu.DPUInterface.n_fee_set_register_value">n_fee_set_register_value</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_standby_mode" href="#egse.dpu.DPUInterface.n_fee_set_standby_mode">n_fee_set_standby_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_sync_register_map" href="#egse.dpu.DPUInterface.n_fee_sync_register_map">n_fee_sync_register_map</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="egse.dpu.DPUInterface"><code class="flex name class">
<span>class <span class="ident">DPUInterface</span></span>
</code></dt>
<dd>
<div class="desc"><p>This interface is for sending commands to the DPU Control Server. The commands are user
oriented and will be translated by the DPU Controller in proper FEE commands.</p>
<p>The interface should be implemented by the <code><a title="egse.dpu.DPUController" href="#egse.dpu.DPUController">DPUController</a></code> and the <code><a title="egse.dpu.DPUProxy" href="#egse.dpu.DPUProxy">DPUProxy</a></code> (and possibly
a <code><a title="egse.dpu.DPUSimulator" href="#egse.dpu.DPUSimulator">DPUSimulator</a></code> should we need that e.g. for testing purposes).</p>
<p>The command shall also be added to the <code>dpu.yaml</code> command definitions file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUInterface:
    &#34;&#34;&#34;
    This interface is for sending commands to the DPU Control Server. The commands are user
    oriented and will be translated by the DPU Controller in proper FEE commands.

    The interface should be implemented by the `DPUController` and the `DPUProxy` (and possibly
    a `DPUSimulator` should we need that e.g. for testing purposes).

    The command shall also be added to the `dpu.yaml` command definitions file.
    &#34;&#34;&#34;

    @dynamic_interface
    def marker(self, mark: str):
        raise NotImplementedError

    @dynamic_interface
    def get_slicing(self) -&gt; int:
        raise NotImplementedError

    @dynamic_interface
    def set_slicing(self, num_cycles: int):
        raise NotImplementedError

    @dynamic_interface
    def is_simulator(self):
        raise NotImplementedError

    @dynamic_interface
    def get_register_map(self) -&gt; RegisterMap:
        &#34;&#34;&#34;
        Returns the RegisterMap
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_sync_register_map(self):
        &#34;&#34;&#34;
        Read the complete register map from the N-FEE.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_get_mode(self):
        &#34;&#34;&#34;
        Returns the N-FEE mode.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_get_sync_mode(self):
        &#34;&#34;&#34;
        Returns the N-FEE mode.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_on_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_is_dump_mode(self):
        &#34;&#34;&#34;
        Returns True if the N-FEE is configured for DUMP mode.

        DUMP mode is not really an N-FEE mode, but more a set of register settings that allow to
        readout/dump all CCDs without transmitting any data. This mode is used in ambient to make
        sure the detectors do not get saturated between tests.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_immediate_on_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_standby_mode(self):
        &#34;&#34;&#34;Command the N-FEE to go into STANDBY mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        &#34;&#34;&#34; Command the N-FEE to go into DUMP mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
             n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_dump_mode_int_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34; Command the N-FEE to go into DUMP mode and internal sync.

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer
            * int_sync_period (int): the period of the internal sync in milliseconds

        Args:
             n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_mode(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE mode and internal sync.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_full_image_pattern_mode(self, n_fee_parameters):
        &#34;&#34;&#34;
        Command the N-FEE to go into FULL_IMAGE_PATTERN mode.

        n_fee_parameters:

        The n_fee_parameters argument is a dictionary with additional/specific parameters to
        set in the register when moving to full image pattern mode.

            * num_cycles (int): the number of readout cycles
            * v_start (int): the first line to readout
            * v_end (int): the last line to readout
            * sensor_sel (int): the CCD side to select for transfer

        Args:
            n_fee_parameters (dict): dictionary with N-FEE parameters to be set
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_high_precision_hk_mode(self, n_fee_parameters: dict):
        &#34;&#34;&#34;Command the N-FEE to go into high precision housekeeping mode.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34;
        Command the N-FEE to go into internal sync mode.

        The method expects the following keys in n_fee_parameters:

        * int_sync_period: the internal sync period in milliseconds [default=6250]

        Args:
            n_fee_parameters (dict): N-FEE parameter dictionary
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_external_sync(self, n_fee_parameters: dict):
        &#34;&#34;&#34;
        Command the N-FEE to go into external sync mode.
        No keys are expected in n_fee_parameters, pass an empty dict.
        &#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_register_value(self, reg_name: str, field_name: str, field_value: int):
        &#34;&#34;&#34;Command the N-FEE to set a register value.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_reset(self):
        &#34;&#34;&#34;Command the N-FEE to reset to its default settings.&#34;&#34;&#34;
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_clear_error_flags(self):
        &#34;&#34;&#34;
        Command the N-FEE to clear all error flags for non RMAP/SpW related functions immediately.

        The `clear_error_flag` bit in the register map is set to 1, meaning that all error flags
        that are generated by the N-FEE FPGA for non RMAP-SpW related functions are cleared
        immediately.  This bit is cleared automatically, so that any future error flags can be
        latched again.  If the error conditions persist and no corrective measures are taken,
        then error flags would be set again.
        &#34;&#34;&#34;

        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):

        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_charge_injection(self, n_fee_parameters: dict):
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_vgd(self, n_fee_parameters: dict):
        raise NotImplementedError

    @dynamic_interface
    def n_fee_set_fpga_defaults(self):
        raise NotImplementedError</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="egse.dpu.DPUController" href="#egse.dpu.DPUController">DPUController</a></li>
<li><a title="egse.dpu.DPUProxy" href="#egse.dpu.DPUProxy">DPUProxy</a></li>
<li><a title="egse.dpu.DPUSimulator" href="#egse.dpu.DPUSimulator">DPUSimulator</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUInterface.get_register_map"><code class="name flex">
<span>def <span class="ident">get_register_map</span></span>(<span>self) ‑> <a title="egse.reg.RegisterMap" href="../reg.html#egse.reg.RegisterMap">RegisterMap</a></span>
</code></dt>
<dd>
<div class="desc"><p>Returns the RegisterMap</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def get_register_map(self) -&gt; RegisterMap:
    &#34;&#34;&#34;
    Returns the RegisterMap
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.get_slicing"><code class="name flex">
<span>def <span class="ident">get_slicing</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def get_slicing(self) -&gt; int:
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.is_simulator"><code class="name flex">
<span>def <span class="ident">is_simulator</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def is_simulator(self):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.marker"><code class="name flex">
<span>def <span class="ident">marker</span></span>(<span>self, mark: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def marker(self, mark: str):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_get_mode"><code class="name flex">
<span>def <span class="ident">n_fee_get_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the N-FEE mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_get_mode(self):
    &#34;&#34;&#34;
    Returns the N-FEE mode.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_get_sync_mode"><code class="name flex">
<span>def <span class="ident">n_fee_get_sync_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the N-FEE mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_get_sync_mode(self):
    &#34;&#34;&#34;
    Returns the N-FEE mode.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_high_precision_hk_mode"><code class="name flex">
<span>def <span class="ident">n_fee_high_precision_hk_mode</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into high precision housekeeping mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_high_precision_hk_mode(self, n_fee_parameters: dict):
    &#34;&#34;&#34;Command the N-FEE to go into high precision housekeeping mode.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_is_dump_mode"><code class="name flex">
<span>def <span class="ident">n_fee_is_dump_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if the N-FEE is configured for DUMP mode.</p>
<p>DUMP mode is not really an N-FEE mode, but more a set of register settings that allow to
readout/dump all CCDs without transmitting any data. This mode is used in ambient to make
sure the detectors do not get saturated between tests.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_is_dump_mode(self):
    &#34;&#34;&#34;
    Returns True if the N-FEE is configured for DUMP mode.

    DUMP mode is not really an N-FEE mode, but more a set of register settings that allow to
    readout/dump all CCDs without transmitting any data. This mode is used in ambient to make
    sure the detectors do not get saturated between tests.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_reset"><code class="name flex">
<span>def <span class="ident">n_fee_reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to reset to its default settings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_reset(self):
    &#34;&#34;&#34;Command the N-FEE to reset to its default settings.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_charge_injection"><code class="name flex">
<span>def <span class="ident">n_fee_set_charge_injection</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_charge_injection(self, n_fee_parameters: dict):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_clear_error_flags"><code class="name flex">
<span>def <span class="ident">n_fee_set_clear_error_flags</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to clear all error flags for non RMAP/SpW related functions immediately.</p>
<p>The <code>clear_error_flag</code> bit in the register map is set to 1, meaning that all error flags
that are generated by the N-FEE FPGA for non RMAP-SpW related functions are cleared
immediately.
This bit is cleared automatically, so that any future error flags can be
latched again.
If the error conditions persist and no corrective measures are taken,
then error flags would be set again.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_clear_error_flags(self):
    &#34;&#34;&#34;
    Command the N-FEE to clear all error flags for non RMAP/SpW related functions immediately.

    The `clear_error_flag` bit in the register map is set to 1, meaning that all error flags
    that are generated by the N-FEE FPGA for non RMAP-SpW related functions are cleared
    immediately.  This bit is cleared automatically, so that any future error flags can be
    latched again.  If the error conditions persist and no corrective measures are taken,
    then error flags would be set again.
    &#34;&#34;&#34;

    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_dump_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_dump_mode</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into DUMP mode.</p>
<p>n_fee_parameters:</p>
<p>The n_fee_parameters argument is a dictionary with additional/specific parameters to
set in the register when moving to full image pattern mode.</p>
<pre><code>* num_cycles (int): the number of readout cycles
* v_start (int): the first line to readout
* v_end (int): the last line to readout
* sensor_sel (int): the CCD side to select for transfer
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with N-FEE parameters to be set_</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_dump_mode(self, n_fee_parameters: dict):
    &#34;&#34;&#34; Command the N-FEE to go into DUMP mode.

    n_fee_parameters:

    The n_fee_parameters argument is a dictionary with additional/specific parameters to
    set in the register when moving to full image pattern mode.

        * num_cycles (int): the number of readout cycles
        * v_start (int): the first line to readout
        * v_end (int): the last line to readout
        * sensor_sel (int): the CCD side to select for transfer

    Args:
         n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync"><code class="name flex">
<span>def <span class="ident">n_fee_set_dump_mode_int_sync</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into DUMP mode and internal sync.</p>
<p>The n_fee_parameters argument is a dictionary with additional/specific parameters to
set in the register when moving to full image pattern mode.</p>
<pre><code>* num_cycles (int): the number of readout cycles
* v_start (int): the first line to readout
* v_end (int): the last line to readout
* sensor_sel (int): the CCD side to select for transfer
* int_sync_period (int): the period of the internal sync in milliseconds
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with N-FEE parameters to be set_</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_dump_mode_int_sync(self, n_fee_parameters: dict):
    &#34;&#34;&#34; Command the N-FEE to go into DUMP mode and internal sync.

    The n_fee_parameters argument is a dictionary with additional/specific parameters to
    set in the register when moving to full image pattern mode.

        * num_cycles (int): the number of readout cycles
        * v_start (int): the first line to readout
        * v_end (int): the last line to readout
        * sensor_sel (int): the CCD side to select for transfer
        * int_sync_period (int): the period of the internal sync in milliseconds

    Args:
         n_fee_parameters (dict): dictionary with N-FEE parameters to be set_
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_external_sync"><code class="name flex">
<span>def <span class="ident">n_fee_set_external_sync</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into external sync mode.
No keys are expected in n_fee_parameters, pass an empty dict.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_external_sync(self, n_fee_parameters: dict):
    &#34;&#34;&#34;
    Command the N-FEE to go into external sync mode.
    No keys are expected in n_fee_parameters, pass an empty dict.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_fpga_defaults"><code class="name flex">
<span>def <span class="ident">n_fee_set_fpga_defaults</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_fpga_defaults(self):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_full_image_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_full_image_mode</span></span>(<span>self, n_fee_parameters)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into FULL_IMAGE mode.</p>
<p>n_fee_parameters:</p>
<p>The n_fee_parameters argument is a dictionary with additional/specific parameters to
set in the register when moving to full image pattern mode.</p>
<pre><code>* num_cycles (int): the number of readout cycles
* v_start (int): the first line to readout
* v_end (int): the last line to readout
* sensor_sel (int): the CCD side to select for transfer
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with N-FEE parameters to be set</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_full_image_mode(self, n_fee_parameters):
    &#34;&#34;&#34;
    Command the N-FEE to go into FULL_IMAGE mode.

    n_fee_parameters:

    The n_fee_parameters argument is a dictionary with additional/specific parameters to
    set in the register when moving to full image pattern mode.

        * num_cycles (int): the number of readout cycles
        * v_start (int): the first line to readout
        * v_end (int): the last line to readout
        * sensor_sel (int): the CCD side to select for transfer

    Args:
        n_fee_parameters (dict): dictionary with N-FEE parameters to be set
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync"><code class="name flex">
<span>def <span class="ident">n_fee_set_full_image_mode_int_sync</span></span>(<span>self, n_fee_parameters)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into FULL_IMAGE mode and internal sync.</p>
<p>n_fee_parameters:</p>
<p>The n_fee_parameters argument is a dictionary with additional/specific parameters to
set in the register when moving to full image pattern mode.</p>
<pre><code>* num_cycles (int): the number of readout cycles
* v_start (int): the first line to readout
* v_end (int): the last line to readout
* sensor_sel (int): the CCD side to select for transfer
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with N-FEE parameters to be set</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters):
    &#34;&#34;&#34;
    Command the N-FEE to go into FULL_IMAGE mode and internal sync.

    n_fee_parameters:

    The n_fee_parameters argument is a dictionary with additional/specific parameters to
    set in the register when moving to full image pattern mode.

        * num_cycles (int): the number of readout cycles
        * v_start (int): the first line to readout
        * v_end (int): the last line to readout
        * sensor_sel (int): the CCD side to select for transfer

    Args:
        n_fee_parameters (dict): dictionary with N-FEE parameters to be set
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_full_image_pattern_mode</span></span>(<span>self, n_fee_parameters)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into FULL_IMAGE_PATTERN mode.</p>
<p>n_fee_parameters:</p>
<p>The n_fee_parameters argument is a dictionary with additional/specific parameters to
set in the register when moving to full image pattern mode.</p>
<pre><code>* num_cycles (int): the number of readout cycles
* v_start (int): the first line to readout
* v_end (int): the last line to readout
* sensor_sel (int): the CCD side to select for transfer
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with N-FEE parameters to be set</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_full_image_pattern_mode(self, n_fee_parameters):
    &#34;&#34;&#34;
    Command the N-FEE to go into FULL_IMAGE_PATTERN mode.

    n_fee_parameters:

    The n_fee_parameters argument is a dictionary with additional/specific parameters to
    set in the register when moving to full image pattern mode.

        * num_cycles (int): the number of readout cycles
        * v_start (int): the first line to readout
        * v_end (int): the last line to readout
        * sensor_sel (int): the CCD side to select for transfer

    Args:
        n_fee_parameters (dict): dictionary with N-FEE parameters to be set
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_immediate_on_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_immediate_on_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into ON mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_immediate_on_mode(self):
    &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_internal_sync"><code class="name flex">
<span>def <span class="ident">n_fee_set_internal_sync</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into internal sync mode.</p>
<p>The method expects the following keys in n_fee_parameters:</p>
<ul>
<li>int_sync_period: the internal sync period in milliseconds [default=6250]</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_fee_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>N-FEE parameter dictionary</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_internal_sync(self, n_fee_parameters: dict):
    &#34;&#34;&#34;
    Command the N-FEE to go into internal sync mode.

    The method expects the following keys in n_fee_parameters:

    * int_sync_period: the internal sync period in milliseconds [default=6250]

    Args:
        n_fee_parameters (dict): N-FEE parameter dictionary
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_on_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_on_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into ON mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_on_mode(self):
    &#34;&#34;&#34;Command the N-FEE to go into ON mode.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_register_value"><code class="name flex">
<span>def <span class="ident">n_fee_set_register_value</span></span>(<span>self, reg_name: str, field_name: str, field_value: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to set a register value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_register_value(self, reg_name: str, field_name: str, field_value: int):
    &#34;&#34;&#34;Command the N-FEE to set a register value.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_reverse_clocking"><code class="name flex">
<span>def <span class="ident">n_fee_set_reverse_clocking</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_reverse_clocking(self, n_fee_parameters: dict):

    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_standby_mode"><code class="name flex">
<span>def <span class="ident">n_fee_set_standby_mode</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Command the N-FEE to go into STANDBY mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_standby_mode(self):
    &#34;&#34;&#34;Command the N-FEE to go into STANDBY mode.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_set_vgd"><code class="name flex">
<span>def <span class="ident">n_fee_set_vgd</span></span>(<span>self, n_fee_parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_set_vgd(self, n_fee_parameters: dict):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.n_fee_sync_register_map"><code class="name flex">
<span>def <span class="ident">n_fee_sync_register_map</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Read the complete register map from the N-FEE.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def n_fee_sync_register_map(self):
    &#34;&#34;&#34;
    Read the complete register map from the N-FEE.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInterface.set_slicing"><code class="name flex">
<span>def <span class="ident">set_slicing</span></span>(<span>self, num_cycles: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dynamic_interface
def set_slicing(self, num_cycles: int):
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="egse.dpu.DPUInternals"><code class="flex name class">
<span>class <span class="ident">DPUInternals</span></span>
<span>(</span><span>num_cycles: int, expected_last_packet_flags: List[int], dump_mode: bool = False, internal_sync: bool = False, dump_mode_int: bool = False, frame_number: int = -1, ccd_sides_enum: enum.Enum = None, sensor_sel_enum: enum.Enum = None)</span>
</code></dt>
<dd>
<div class="desc"><p>DPUInternals(num_cycles: int, expected_last_packet_flags: List[int], dump_mode: bool = False, internal_sync: bool = False, dump_mode_int: bool = False, frame_number: int = -1, ccd_sides_enum: enum.Enum = None, sensor_sel_enum: enum.Enum = None)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUInternals:

    # The number of readout cycles requested by the user. A cycle is the period between two long
    # pulses (400ms). When num_cycle == 0, the N-FEE will be instructed to go to dump mode, when
    # num_cycle &lt; 0 nothing will be done.
    num_cycles: int

    # The expected last packet flags tell you if for a certain ccd side and packet a last packet
    # flag is expected. This is similar to saying if such a packet is to be expected from the N-FEE.
    expected_last_packet_flags: List[int]

    # DUMP mode is not a real N-FEE mode, but is defined in the DPU Processor to make sure the CCDs
    # will not saturate when we are not reading out image data. The conditions for a dump mode are
    # the register map flags &#39;digitise_en&#39; being False and &#39;DG_high&#39; being True.
    dump_mode: bool = False

    # The internal sync flag is set to True whenever the register map parameter &#39;sync_sel&#39; is True.
    internal_sync: bool = False

    # This flag is set to True when the N-FEE shall be put into dump mode internal sync after
    # num_cycles becomes zero.
    dump_mode_int: bool = False

    # The current frame number. This value needs to be updated as soon as the housekeeping packet
    # is received.
    frame_number: int = -1

    # Enumeration with the information about E and F, based on the setup (camera-dependent)
    ccd_sides_enum: Enum = None

    # Enumeration with the sensor_sel
    sensor_sel_enum: Enum = None

    # The clear_error_flags shall be executed on every readout, i.e. every 200ms and 400ms pulse.
    clear_error_flags = False

    # The number of cycles that will be used for slicing the FITS files. This parameter is
    # saved in the HDF5 file upon reception.
    slicing_num_cycles = 0


    def is_start_of_cycle(self):
        &#34;&#34;&#34;
        Returns True if in the first readout in this cycle, i.e. frame number is 0.
        &#34;&#34;&#34;

        return self.frame_number == 0

    def is_end_of_cycle(self):
        &#34;&#34;&#34;
        Returns True if in the last readout in this cycle.
        Note that, when in internal sync mode, this method always returns True.
        &#34;&#34;&#34;
        if self.internal_sync:
            return True
        else:
            return self.frame_number == 3

    def is_400ms_pulse(self):
        return self.frame_number == 0

    def is_200ms_pulse(self):
        return self.frame_number in [1, 2, 3]

    def update(self, n_fee_state: NFEEState.StateTuple):
        self.dump_mode = not bool(n_fee_state.digitise_en)
        self.internal_sync = bool(n_fee_state.sync_sel)
        self.expected_last_packet_flags = create_expected_last_packet_flags(n_fee_state, self.sensor_sel_enum)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="egse.dpu.DPUInternals.ccd_sides_enum"><code class="name">var <span class="ident">ccd_sides_enum</span> : enum.Enum</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.clear_error_flags"><code class="name">var <span class="ident">clear_error_flags</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.dump_mode"><code class="name">var <span class="ident">dump_mode</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.dump_mode_int"><code class="name">var <span class="ident">dump_mode_int</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.expected_last_packet_flags"><code class="name">var <span class="ident">expected_last_packet_flags</span> : List[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.frame_number"><code class="name">var <span class="ident">frame_number</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.internal_sync"><code class="name">var <span class="ident">internal_sync</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.num_cycles"><code class="name">var <span class="ident">num_cycles</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.sensor_sel_enum"><code class="name">var <span class="ident">sensor_sel_enum</span> : enum.Enum</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="egse.dpu.DPUInternals.slicing_num_cycles"><code class="name">var <span class="ident">slicing_num_cycles</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUInternals.is_200ms_pulse"><code class="name flex">
<span>def <span class="ident">is_200ms_pulse</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_200ms_pulse(self):
    return self.frame_number in [1, 2, 3]</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInternals.is_400ms_pulse"><code class="name flex">
<span>def <span class="ident">is_400ms_pulse</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_400ms_pulse(self):
    return self.frame_number == 0</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInternals.is_end_of_cycle"><code class="name flex">
<span>def <span class="ident">is_end_of_cycle</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if in the last readout in this cycle.
Note that, when in internal sync mode, this method always returns True.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_end_of_cycle(self):
    &#34;&#34;&#34;
    Returns True if in the last readout in this cycle.
    Note that, when in internal sync mode, this method always returns True.
    &#34;&#34;&#34;
    if self.internal_sync:
        return True
    else:
        return self.frame_number == 3</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInternals.is_start_of_cycle"><code class="name flex">
<span>def <span class="ident">is_start_of_cycle</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if in the first readout in this cycle, i.e. frame number is 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_start_of_cycle(self):
    &#34;&#34;&#34;
    Returns True if in the first readout in this cycle, i.e. frame number is 0.
    &#34;&#34;&#34;

    return self.frame_number == 0</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUInternals.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, n_fee_state: egse.dpu.dpu.StateTuple)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self, n_fee_state: NFEEState.StateTuple):
    self.dump_mode = not bool(n_fee_state.digitise_en)
    self.internal_sync = bool(n_fee_state.sync_sel)
    self.expected_last_packet_flags = create_expected_last_packet_flags(n_fee_state, self.sensor_sel_enum)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="egse.dpu.DPUMonitoring"><code class="flex name class">
<span>class <span class="ident">DPUMonitoring</span></span>
<span>(</span><span>timeout: float = 30)</span>
</code></dt>
<dd>
<div class="desc"><p>The DPUMonitoring class allows you to execute a function synchronised to the reception of a
timecode or a housekeeping packet from the N-FEE.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>timeout</code></strong></dt>
<dd>time to wait for a message before a timeout [default=30s]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUMonitoring:
    &#34;&#34;&#34;
    The DPUMonitoring class allows you to execute a function synchronised to the reception of a
    timecode or a housekeeping packet from the N-FEE.

    Args:
        timeout: time to wait for a message before a timeout [default=30s]
    &#34;&#34;&#34;
    def __init__(self, timeout: float = 30):
        self._context = zmq.Context.instance()
        self._endpoint = connect_address(&#39;tcp&#39;, DPU_PROCESSOR_SETTINGS.HOSTNAME, DPU_PROCESSOR_SETTINGS.MONITORING_PORT)
        self._multipart = True
        self._timeout = timeout  # seconds
        self._retries = 3
        self._socket = None
        self._subscriptions = set()

    def __enter__(self):
        self.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if not self._socket.closed:
            self.disconnect()

    def connect(self):
        self._socket = self._context.socket(zmq.SUB)
        self._socket.connect(self._endpoint)

        # subscribe_string = b&#39;&#39;
        # self._socket.subscribe(subscribe_string)
        # self._subscriptions.add(subscribe_string)

    def disconnect(self):
        self._socket.close(linger=0)
        self._subscriptions.clear()

    def unsubscribe_all(self):
        for sub in self._subscriptions:
            self._socket.unsubscribe(sub)
        self._subscriptions.clear()

    def unsubscribe(self, sync_id: int):
        subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;
        try:
            self._subscriptions.remove(subscribe_string)
            self._socket.unsubscribe(subscribe_string)
        except KeyError:
            LOGGER.warning(
                f&#34;Trying to unsubscribe a key that was not previously subscribed: {subscribe_string}&#34;
            )

    def subscribe(self, sync_id: int = None):
        subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;

        if subscribe_string in self._subscriptions:
            return

        self._socket.subscribe(subscribe_string)
        self._subscriptions.add(subscribe_string)

    def wait_for_timecode(self) -&gt; Tuple[int, str]:
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and returns when a TIMECODE
        synchronisation message is received.

        Returns:
            A tuple of the timecode (int) and the corresponding timestamp (str).
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_TIMECODE)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                timecode, timestamp = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode}, {timestamp}&#34;)

                return timecode, timestamp
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_for_hdf5_filename(self, retries: int = None, timeout: float = None) -&gt; List[Path]:
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and returns a list of path names that
        were part of the current registration in the Storage, right before a new registration was
        initiated.

        This method is mainly intended to be used by processes that need to work with the generated
        HDF5 files after they have been closed by the DPU Processor. One of these processes is the
        FITS generation.

        Notes:
            The path names that are returned are absolute filenames that are specific for the
            egse-server on which the DPU Processor is running. These files might not be accessible
            from the machine you are running this monitoring request.

        Returns:
            A list of path names.
        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.HDF5_FILENAMES)

        retries = retries if retries is not None else self._retries
        timeout = timeout or self._timeout

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                filenames = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {filenames}&#34;)

                return filenames
            else:
                retries -= 1
                # LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_number_of_pulses(self, num_pulses: int) -&gt; None:
        &#34;&#34;&#34;
        Wait for a number of pulses (long and short), then return.

        When the number of pulses has been received, the function returns right after the timecode synchronisation
        message. Any command that is sent to the N-FEE immediately after this function returns will be processes within
        that same readout frame, i.e. before the next sync pulse.

        Args:
            num_pulses: the number of sync pulses to wait before returning.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_TIMECODE)

        retries = self._retries

        LOGGER.debug(f&#34;Waiting for {num_pulses} pulses...&#34;)

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                timecode, timestamp = pickle.loads(pickle_string)

                num_pulses -= 1
                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode=}, {timestamp=}, {num_pulses=}&#34;)
                if num_pulses &lt;= 0:
                    return

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_num_cycles(self, num_cycles: int, return_on_frame: int = 3) -&gt; int:
        &#34;&#34;&#34;
        Wait for a number of long pulses (cycles), then return.

        This method will wait for full cycles, i.e. 4 readouts in external sync mode, 1 readout in internal sync mode,
        and will return immediately after receiving the HK sync pulse for the last frame in the requested cycle, i.e.
        frame number == 3 for external sync and frame number == 0 for internal sync. If an RMAP command is then sent
        when the function returns, it will still be executed within that frame and the changed register settings will
        become active on the next pulse, which is a long pulse, the start of the next cycle.
        That way we do not lose a cycle.

        Args:
            num_cycles: the number of full cycles to wait before returning
            return_on_frame: choose the readout frame on which to return [default = 3]

        Returns:
            Zero (0) when no cycles were waited because num_cycles &lt;= 0, otherwise return value &gt; 0.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

        retries = self._retries
        count = 0

        if num_cycles &lt;= 0:
            LOGGER.debug(f&#34;{num_cycles=}, no cycles waited, returned immediately&#34;)
            return count

        LOGGER.debug(f&#34;Waiting for {num_cycles} cycles...&#34;)

        with Timer(&#34;Loop cycles&#34;) as timer, DPUProxy() as dpu_proxy:

            # When we are in external sync mode, we need to skip the current cycle,
            # because the requested changes in the register -&gt; FPGA will ony occur on
            # the next long pulse. No need for this when in internal sync mode.

            sync_mode = dpu_proxy.n_fee_get_sync_mode()
            if sync_mode == 0:
                num_cycles += 1

            while True:
                count += 1
                rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
                if self._socket in rlist:
                    if self._multipart:
                        sync_id, pickle_string = self._socket.recv_multipart()
                        sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                    else:
                        sync_id = MessageIdentifier.ALL
                        pickle_string = self._socket.recv()
                    status = pickle.loads(pickle_string)

                    LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {to_string(status[0])}&#34;)

                    sync_mode = dpu_proxy.n_fee_get_sync_mode()

                    if (sync_mode == 1) or (packet := status[0]) and packet.frame_number == return_on_frame:
                        num_cycles -= 1

                    LOGGER.debug(f&#34;NUM_CYCLES={num_cycles}, {sync_mode=}&#34;)

                    if num_cycles &lt;= 0:
                        return count

                    retries = self._retries  # reset the number of retries
                else:
                    retries -= 1
                    LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                    if retries &lt;= 0:
                        raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

                timer.log_elapsed()

    def monitor_all(self):
        self.subscribe()

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()

                msg = pickle.loads(pickle_string)
                if sync_id == MessageIdentifier.SYNC_TIMECODE:
                    msg = f&#34;timestamp={msg[1]}, timecode={msg[0]}&#34;
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
                elif sync_id == MessageIdentifier.SYNC_HK_PACKET:
                    msg = f&#34;timestamp={msg[1]}, packet type={to_string(msg[0])}&#34;
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
                elif sync_id == MessageIdentifier.NUM_CYCLES:
                    LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, num_cycles={msg}&#34;)

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def wait_until_synced_num_cycles_is_zero(self):
        &#34;&#34;&#34;
        Wait until the synced num_cycles turns zero, then return. The synced num_cycles is
        the num_cycles that is maintained by the DPU Processor and which is distributed by the
        DPU Processor on every 400ms pulse.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.NUM_CYCLES)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()

                synced_num_cycles = pickle.loads(pickle_string)

                LOGGER.info(f&#34;{MessageIdentifier(sync_id).name} = {synced_num_cycles}&#34;)

                if synced_num_cycles &lt;= 0:
                    return

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

    def do(self, func: Callable, *args, **kwargs):
        return func(*args, **kwargs)

    def on_long_pulse_do(self, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and executes the given function
        when the frame_number == 0, i.e. right after a long pulse.

        Args:
            func (Callable): the function to synchronise
            *args: any arguments to pass to the function
            **kwargs: any keyword arguments to pass to the function

        Returns:
            The return value of the called function.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        return self.on_frame_number_do(0, func, *args, **kwargs)

    def on_frame_number_do(self, frame_number: int, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Connects to the monitoring socket of the DPU Processor and executes the given function
        when the given frame_number is reached. This allows to send N-FEE commands right before the long pulse.

        Args:
            frame_number: the frame number on which to execute the function
            func (Callable): the function to synchronise
            *args: any arguments to pass to the function
            **kwargs: any keyword arguments to pass to the function

        Returns:
            The return value of the called function.

        Raises:
            A TimeoutError when no sync data was received from the monitoring socket after 30s.
        &#34;&#34;&#34;
        self.unsubscribe_all()
        self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

        retries = self._retries

        while True:
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                status = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {status[0]}&#34;)

                packet: DataPacketType = status[0]
                if packet and packet.frame_number == frame_number:
                    return func(*args, **kwargs)
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUMonitoring.connect"><code class="name flex">
<span>def <span class="ident">connect</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def connect(self):
    self._socket = self._context.socket(zmq.SUB)
    self._socket.connect(self._endpoint)

    # subscribe_string = b&#39;&#39;
    # self._socket.subscribe(subscribe_string)
    # self._subscriptions.add(subscribe_string)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.disconnect"><code class="name flex">
<span>def <span class="ident">disconnect</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def disconnect(self):
    self._socket.close(linger=0)
    self._subscriptions.clear()</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.do"><code class="name flex">
<span>def <span class="ident">do</span></span>(<span>self, func: Callable, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def do(self, func: Callable, *args, **kwargs):
    return func(*args, **kwargs)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.monitor_all"><code class="name flex">
<span>def <span class="ident">monitor_all</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def monitor_all(self):
    self.subscribe()

    retries = self._retries

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()

            msg = pickle.loads(pickle_string)
            if sync_id == MessageIdentifier.SYNC_TIMECODE:
                msg = f&#34;timestamp={msg[1]}, timecode={msg[0]}&#34;
                LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
            elif sync_id == MessageIdentifier.SYNC_HK_PACKET:
                msg = f&#34;timestamp={msg[1]}, packet type={to_string(msg[0])}&#34;
                LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, {msg}&#34;)
            elif sync_id == MessageIdentifier.NUM_CYCLES:
                LOGGER.info(f&#34;{MessageIdentifier(sync_id).name}, num_cycles={msg}&#34;)

            retries = self._retries  # reset the number of retries
        else:
            retries -= 1
            LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.on_frame_number_do"><code class="name flex">
<span>def <span class="ident">on_frame_number_do</span></span>(<span>self, frame_number: int, func: Callable, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Connects to the monitoring socket of the DPU Processor and executes the given function
when the given frame_number is reached. This allows to send N-FEE commands right before the long pulse.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>frame_number</code></strong></dt>
<dd>the frame number on which to execute the function</dd>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable</code></dt>
<dd>the function to synchronise</dd>
<dt><strong><code>*args</code></strong></dt>
<dd>any arguments to pass to the function</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>any keyword arguments to pass to the function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The return value of the called function.</p>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_frame_number_do(self, frame_number: int, func: Callable, *args, **kwargs):
    &#34;&#34;&#34;
    Connects to the monitoring socket of the DPU Processor and executes the given function
    when the given frame_number is reached. This allows to send N-FEE commands right before the long pulse.

    Args:
        frame_number: the frame number on which to execute the function
        func (Callable): the function to synchronise
        *args: any arguments to pass to the function
        **kwargs: any keyword arguments to pass to the function

    Returns:
        The return value of the called function.

    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

    retries = self._retries

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()
            status = pickle.loads(pickle_string)

            LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {status[0]}&#34;)

            packet: DataPacketType = status[0]
            if packet and packet.frame_number == frame_number:
                return func(*args, **kwargs)
        else:
            retries -= 1
            LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.on_long_pulse_do"><code class="name flex">
<span>def <span class="ident">on_long_pulse_do</span></span>(<span>self, func: Callable, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Connects to the monitoring socket of the DPU Processor and executes the given function
when the frame_number == 0, i.e. right after a long pulse.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable</code></dt>
<dd>the function to synchronise</dd>
<dt><strong><code>*args</code></strong></dt>
<dd>any arguments to pass to the function</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>any keyword arguments to pass to the function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The return value of the called function.</p>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_long_pulse_do(self, func: Callable, *args, **kwargs):
    &#34;&#34;&#34;
    Connects to the monitoring socket of the DPU Processor and executes the given function
    when the frame_number == 0, i.e. right after a long pulse.

    Args:
        func (Callable): the function to synchronise
        *args: any arguments to pass to the function
        **kwargs: any keyword arguments to pass to the function

    Returns:
        The return value of the called function.

    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    return self.on_frame_number_do(0, func, *args, **kwargs)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.subscribe"><code class="name flex">
<span>def <span class="ident">subscribe</span></span>(<span>self, sync_id: int = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subscribe(self, sync_id: int = None):
    subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;

    if subscribe_string in self._subscriptions:
        return

    self._socket.subscribe(subscribe_string)
    self._subscriptions.add(subscribe_string)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.unsubscribe"><code class="name flex">
<span>def <span class="ident">unsubscribe</span></span>(<span>self, sync_id: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unsubscribe(self, sync_id: int):
    subscribe_string = sync_id.to_bytes(1, byteorder=&#39;big&#39;) if sync_id else b&#39;&#39;
    try:
        self._subscriptions.remove(subscribe_string)
        self._socket.unsubscribe(subscribe_string)
    except KeyError:
        LOGGER.warning(
            f&#34;Trying to unsubscribe a key that was not previously subscribed: {subscribe_string}&#34;
        )</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.unsubscribe_all"><code class="name flex">
<span>def <span class="ident">unsubscribe_all</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unsubscribe_all(self):
    for sub in self._subscriptions:
        self._socket.unsubscribe(sub)
    self._subscriptions.clear()</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.wait_for_hdf5_filename"><code class="name flex">
<span>def <span class="ident">wait_for_hdf5_filename</span></span>(<span>self, retries: int = None, timeout: float = None) ‑> List[pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Connects to the monitoring socket of the DPU Processor and returns a list of path names that
were part of the current registration in the Storage, right before a new registration was
initiated.</p>
<p>This method is mainly intended to be used by processes that need to work with the generated
HDF5 files after they have been closed by the DPU Processor. One of these processes is the
FITS generation.</p>
<h2 id="notes">Notes</h2>
<p>The path names that are returned are absolute filenames that are specific for the
egse-server on which the DPU Processor is running. These files might not be accessible
from the machine you are running this monitoring request.</p>
<h2 id="returns">Returns</h2>
<p>A list of path names.</p>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_hdf5_filename(self, retries: int = None, timeout: float = None) -&gt; List[Path]:
    &#34;&#34;&#34;
    Connects to the monitoring socket of the DPU Processor and returns a list of path names that
    were part of the current registration in the Storage, right before a new registration was
    initiated.

    This method is mainly intended to be used by processes that need to work with the generated
    HDF5 files after they have been closed by the DPU Processor. One of these processes is the
    FITS generation.

    Notes:
        The path names that are returned are absolute filenames that are specific for the
        egse-server on which the DPU Processor is running. These files might not be accessible
        from the machine you are running this monitoring request.

    Returns:
        A list of path names.
    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.HDF5_FILENAMES)

    retries = retries if retries is not None else self._retries
    timeout = timeout or self._timeout

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()
            filenames = pickle.loads(pickle_string)

            LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {filenames}&#34;)

            return filenames
        else:
            retries -= 1
            # LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.wait_for_timecode"><code class="name flex">
<span>def <span class="ident">wait_for_timecode</span></span>(<span>self) ‑> Tuple[int, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Connects to the monitoring socket of the DPU Processor and returns when a TIMECODE
synchronisation message is received.</p>
<h2 id="returns">Returns</h2>
<p>A tuple of the timecode (int) and the corresponding timestamp (str).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_for_timecode(self) -&gt; Tuple[int, str]:
    &#34;&#34;&#34;
    Connects to the monitoring socket of the DPU Processor and returns when a TIMECODE
    synchronisation message is received.

    Returns:
        A tuple of the timecode (int) and the corresponding timestamp (str).
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.SYNC_TIMECODE)

    retries = self._retries

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()
            timecode, timestamp = pickle.loads(pickle_string)

            LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode}, {timestamp}&#34;)

            return timecode, timestamp
        else:
            retries -= 1
            LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.wait_num_cycles"><code class="name flex">
<span>def <span class="ident">wait_num_cycles</span></span>(<span>self, num_cycles: int, return_on_frame: int = 3) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Wait for a number of long pulses (cycles), then return.</p>
<p>This method will wait for full cycles, i.e. 4 readouts in external sync mode, 1 readout in internal sync mode,
and will return immediately after receiving the HK sync pulse for the last frame in the requested cycle, i.e.
frame number == 3 for external sync and frame number == 0 for internal sync. If an RMAP command is then sent
when the function returns, it will still be executed within that frame and the changed register settings will
become active on the next pulse, which is a long pulse, the start of the next cycle.
That way we do not lose a cycle.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_cycles</code></strong></dt>
<dd>the number of full cycles to wait before returning</dd>
<dt><strong><code>return_on_frame</code></strong></dt>
<dd>choose the readout frame on which to return [default = 3]</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Zero (0) when no cycles were waited because num_cycles &lt;= 0, otherwise return value &gt; 0.</p>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_num_cycles(self, num_cycles: int, return_on_frame: int = 3) -&gt; int:
    &#34;&#34;&#34;
    Wait for a number of long pulses (cycles), then return.

    This method will wait for full cycles, i.e. 4 readouts in external sync mode, 1 readout in internal sync mode,
    and will return immediately after receiving the HK sync pulse for the last frame in the requested cycle, i.e.
    frame number == 3 for external sync and frame number == 0 for internal sync. If an RMAP command is then sent
    when the function returns, it will still be executed within that frame and the changed register settings will
    become active on the next pulse, which is a long pulse, the start of the next cycle.
    That way we do not lose a cycle.

    Args:
        num_cycles: the number of full cycles to wait before returning
        return_on_frame: choose the readout frame on which to return [default = 3]

    Returns:
        Zero (0) when no cycles were waited because num_cycles &lt;= 0, otherwise return value &gt; 0.

    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.SYNC_HK_PACKET)

    retries = self._retries
    count = 0

    if num_cycles &lt;= 0:
        LOGGER.debug(f&#34;{num_cycles=}, no cycles waited, returned immediately&#34;)
        return count

    LOGGER.debug(f&#34;Waiting for {num_cycles} cycles...&#34;)

    with Timer(&#34;Loop cycles&#34;) as timer, DPUProxy() as dpu_proxy:

        # When we are in external sync mode, we need to skip the current cycle,
        # because the requested changes in the register -&gt; FPGA will ony occur on
        # the next long pulse. No need for this when in internal sync mode.

        sync_mode = dpu_proxy.n_fee_get_sync_mode()
        if sync_mode == 0:
            num_cycles += 1

        while True:
            count += 1
            rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
            if self._socket in rlist:
                if self._multipart:
                    sync_id, pickle_string = self._socket.recv_multipart()
                    sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
                else:
                    sync_id = MessageIdentifier.ALL
                    pickle_string = self._socket.recv()
                status = pickle.loads(pickle_string)

                LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {to_string(status[0])}&#34;)

                sync_mode = dpu_proxy.n_fee_get_sync_mode()

                if (sync_mode == 1) or (packet := status[0]) and packet.frame_number == return_on_frame:
                    num_cycles -= 1

                LOGGER.debug(f&#34;NUM_CYCLES={num_cycles}, {sync_mode=}&#34;)

                if num_cycles &lt;= 0:
                    return count

                retries = self._retries  # reset the number of retries
            else:
                retries -= 1
                LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
                if retries &lt;= 0:
                    raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)

            timer.log_elapsed()</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.wait_number_of_pulses"><code class="name flex">
<span>def <span class="ident">wait_number_of_pulses</span></span>(<span>self, num_pulses: int) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Wait for a number of pulses (long and short), then return.</p>
<p>When the number of pulses has been received, the function returns right after the timecode synchronisation
message. Any command that is sent to the N-FEE immediately after this function returns will be processes within
that same readout frame, i.e. before the next sync pulse.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_pulses</code></strong></dt>
<dd>the number of sync pulses to wait before returning.</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_number_of_pulses(self, num_pulses: int) -&gt; None:
    &#34;&#34;&#34;
    Wait for a number of pulses (long and short), then return.

    When the number of pulses has been received, the function returns right after the timecode synchronisation
    message. Any command that is sent to the N-FEE immediately after this function returns will be processes within
    that same readout frame, i.e. before the next sync pulse.

    Args:
        num_pulses: the number of sync pulses to wait before returning.

    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.SYNC_TIMECODE)

    retries = self._retries

    LOGGER.debug(f&#34;Waiting for {num_pulses} pulses...&#34;)

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()
            timecode, timestamp = pickle.loads(pickle_string)

            num_pulses -= 1
            LOGGER.debug(f&#34;{MessageIdentifier(sync_id).name}, {timecode=}, {timestamp=}, {num_pulses=}&#34;)
            if num_pulses &lt;= 0:
                return

            retries = self._retries  # reset the number of retries
        else:
            retries -= 1
            LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUMonitoring.wait_until_synced_num_cycles_is_zero"><code class="name flex">
<span>def <span class="ident">wait_until_synced_num_cycles_is_zero</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Wait until the synced num_cycles turns zero, then return. The synced num_cycles is
the num_cycles that is maintained by the DPU Processor and which is distributed by the
DPU Processor on every 400ms pulse.</p>
<h2 id="raises">Raises</h2>
<p>A TimeoutError when no sync data was received from the monitoring socket after 30s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_until_synced_num_cycles_is_zero(self):
    &#34;&#34;&#34;
    Wait until the synced num_cycles turns zero, then return. The synced num_cycles is
    the num_cycles that is maintained by the DPU Processor and which is distributed by the
    DPU Processor on every 400ms pulse.

    Raises:
        A TimeoutError when no sync data was received from the monitoring socket after 30s.
    &#34;&#34;&#34;
    self.unsubscribe_all()
    self.subscribe(MessageIdentifier.NUM_CYCLES)

    retries = self._retries

    while True:
        rlist, _, _ = zmq.select([self._socket], [], [], timeout=self._timeout)
        if self._socket in rlist:
            if self._multipart:
                sync_id, pickle_string = self._socket.recv_multipart()
                sync_id = int.from_bytes(sync_id, byteorder=&#39;big&#39;)
            else:
                sync_id = MessageIdentifier.ALL
                pickle_string = self._socket.recv()

            synced_num_cycles = pickle.loads(pickle_string)

            LOGGER.info(f&#34;{MessageIdentifier(sync_id).name} = {synced_num_cycles}&#34;)

            if synced_num_cycles &lt;= 0:
                return

            retries = self._retries  # reset the number of retries
        else:
            retries -= 1
            LOGGER.warning(f&#34;Monitoring timeout, {retries} retries to go&#34;)
            if retries &lt;= 0:
                raise TimeoutError(f&#34;DPUMonitoring timed out after {self._retries * self._timeout} seconds.&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="egse.dpu.DPUProcessor"><code class="flex name class">
<span>class <span class="ident">DPUProcessor</span></span>
<span>(</span><span>transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>, priority_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, command_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>, response_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7fd530351850>>)</span>
</code></dt>
<dd>
<div class="desc"><p>The DPU Processor handles all interactions with the FEE. It reads the packets from the FEE
within the readout time frame, and sends commands to the FEE through the RMAP protocol.</p>
<p>The commands are read from a commanding queue which is shared between the DPU Processor and
the DPU Controller. Any response from the FEE is put on the response queue which is also
shared between the processor and the controller.</p>
<p>The transport mechanism that is used to read and write SpaceWire packets is abstracted into a
SpaceWireInterface. That allows us to interact with the FEE through different hardware
channels, e.g. a SpaceWire interface (DSI) or a ZeroMQ DEALER-DEALER protocol for
communication with the FEE Simulator.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUProcessor(multiprocessing.Process):
    &#34;&#34;&#34;
    The DPU Processor handles all interactions with the FEE. It reads the packets from the FEE
    within the readout time frame, and sends commands to the FEE through the RMAP protocol.

    The commands are read from a commanding queue which is shared between the DPU Processor and
    the DPU Controller. Any response from the FEE is put on the response queue which is also
    shared between the processor and the controller.

    The transport mechanism that is used to read and write SpaceWire packets is abstracted into a
    SpaceWireInterface. That allows us to interact with the FEE through different hardware
    channels, e.g. a SpaceWire interface (DSI) or a ZeroMQ DEALER-DEALER protocol for
    communication with the FEE Simulator.
    &#34;&#34;&#34;

    def __init__(
        self,
        transport: SpaceWireInterface,
        priority_queue: multiprocessing.Queue,
        command_queue: multiprocessing.Queue,
        response_queue: multiprocessing.Queue,
    ):

        super().__init__()

        self._transport = transport
        self._priority_q = priority_queue
        self._command_q = command_queue
        self._response_q = response_queue
        self.register_map = RegisterMap(&#34;N-FEE&#34;)
        self._quit_event = multiprocessing.Event()

        # These will be properly initialized when the register map is read from the N-FEE

        self._n_fee_state = NFEEState()


    def run(self):

        self._dpu_internals = DPUInternals(
            num_cycles=-1,
            expected_last_packet_flags=[False, False, False, False],
            dump_mode=False,
            internal_sync=False,
            frame_number=-1,
            ccd_sides_enum=GlobalState.setup.camera.fee.ccd_sides.enum,
            sensor_sel_enum=GlobalState.setup.camera.fee.sensor_sel.enum,
        )

        # The DPU Processor runs in a different process and since ZeroMQ Sockets are not
        # thread/process safe, we have to recreate the ZeroMQHandler attached to the egse.logger
        # in this process.
        import egse.logger
        egse.logger.replace_zmq_handler()

        LOGGER.info(&#34;DPU Processor started.&#34;)

        self._killer = SignalCatcher()

        # Setup a SpaceWire connection with the FEE (Simulator) and
        # open a Storage proxy to save all the data packets.

        origin_spw_data = N_FEE_SETTINGS.ORIGIN_SPW_DATA
        origin_spw_data_type = DATA_TYPE[N_FEE_SETTINGS.ORIGIN_SPW_DATA_TYPE]

        ctx: zmq.Context = zmq.Context().instance()

        # Setup monitoring socket

        mon_sock: zmq.Socket = ctx.socket(zmq.PUB)
        endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.MONITORING_PORT)
        mon_sock.bind(endpoint)
        LOGGER.info(f&#34;DPU Processor sending monitoring sync signals to {endpoint}.&#34;)

        # Setup data distribution socket

        dist_sock: zmq.Socket = ctx.socket(zmq.PUB)
        endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.DATA_DISTRIBUTION_PORT)
        dist_sock.setsockopt(zmq.SNDHWM, 0)  # never block on sending msg
        dist_sock.bind(endpoint)

        LOGGER.info(f&#34;DPU Processor sending SpW data to {endpoint}.&#34;)

        with self._transport, StorageProxy() as storage, ConfigurationManagerProxy() as cm:
            LOGGER.info(&#34;SpaceWire Transport has been connected.&#34;)
            self._transport.configure()
            LOGGER.info(&#34;SpaceWire Transport has been configured.&#34;)

            LOGGER.info(f&#34;Register {origin_spw_data} to Storage&#34;)
            register_to_storage_manager(storage, origin_spw_data)

            # Before going into the wile-loop, read the full register from the N-FEE and initialise
            # the register map.

            try:
                self.initialise_register_map()
                save_register_map(self.register_map, storage, origin_spw_data, dist_sock)
                save_format_version(storage, origin_spw_data)
                save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
            except Abort:
                LOGGER.warning(&#34;The DPU Processor is aborting....&#34;)
                unregister_from_storage_manager(storage, origin_spw_data)
                LOGGER.info(f&#34;The DPU Processor unregistered {origin_spw_data} from the Storage.&#34;)
                return
            except Exception as exc:
                LOGGER.error(exc, exc_info=exc)

            # Initialise the N-FEE state from the register map

            self._n_fee_state.update_at_400ms(self.register_map)

            # Initialise the DPU internals from the N-FEE State

            self._dpu_internals.update(self._n_fee_state.get_state())

            LOGGER.debug(f&#34;{self._dpu_internals.dump_mode=}&#34;)
            LOGGER.debug(f&#34;{self._dpu_internals.internal_sync=}&#34;)
            LOGGER.debug(f&#34;{self._dpu_internals.expected_last_packet_flags=}&#34;)

            # Initialise the data attributes, they will be added as attributes to the data group
            # in the HDF5 file.

            data_attr = self._n_fee_state.get_state()._asdict()

            # Initialise the start_time. This is needed, because when a NoTimeCodeError occurs
            # the variable will not be initialised resulting in a critical error.

            start_time = time.perf_counter()

            try:
                LOGGER.info(&#34;Going into the while True loop...&#34;)
                while True:

                    try:
                        # First two packets are a Timecode and a HK packet  ------------------------

                        tc_packet, timestamp, start_time = read_timecode(self._transport)

                        hk_packet, timestamp = read_hk_packet(self._transport)

                        self._dpu_internals.frame_number = hk_packet.type.frame_number
                        self._dpu_internals.clear_error_flags = True

                        # Create a new HDF5 file for each readout cycle ----------------------------

                        if self._dpu_internals.is_start_of_cycle():
                            with Timer(&#34;Creating a new data file&#34;):
                                new_spw_data_file(storage, self.register_map, origin_spw_data,
                                                  origin_spw_data_type, mon_sock, dist_sock)
                                save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
                                save_num_cycles(storage, origin_spw_data, self._dpu_internals.num_cycles)

                        # Update the N-FEE state (FPGA) --------------------------------------------

                        if self._dpu_internals.is_400ms_pulse():
                            self._n_fee_state.update_at_400ms(self.register_map)
                        elif self._dpu_internals.is_200ms_pulse():
                            self._n_fee_state.update_at_200ms(self.register_map)
                        else:
                            pass  # we are entering the loop for the first time

                        # Update the DPU internals from the N-FEE state

                        self._dpu_internals.update(self._n_fee_state.get_state())

                        # Process and save the timecode and HK packet ------------------------------

                        process_timecode(tc_packet, timestamp, storage, origin_spw_data,
                                         self._dpu_internals.frame_number, mon_sock, dist_sock)

                        process_hk_packet(hk_packet, timestamp, storage, origin_spw_data,
                                          self._dpu_internals.frame_number, mon_sock, dist_sock)

                        process_high_priority_commands(self._priority_q, self._response_q,
                                                       self._n_fee_state.get_state(),
                                                       self._dpu_internals, self.register_map)

                        # On any new readout cycle (400ms pulse), update the state and the internals

                        # FIXME: Why is this test done here and not at the end of the while loop
                        #        when all data has been read?

                        if self._dpu_internals.is_400ms_pulse():

                            pickle_string = pickle.dumps(self._dpu_internals.num_cycles)
                            msg_id = MessageIdentifier.NUM_CYCLES.to_bytes(1, &#39;big&#39;)
                            num_cycles_msg = [msg_id, pickle_string]
                            dist_sock.send_multipart(num_cycles_msg)
                            mon_sock.send_multipart(num_cycles_msg)

                            # decrement num_cycles, this can go negative which is interpreted as
                            # not doing anything...

                            self._dpu_internals.num_cycles -= 1  # check issue #917 before changing this line

                            LOGGER.debug(
                                f&#34;HK: frame number={hk_packet.type.frame_number}, dump mode={self._dpu_internals.dump_mode}, num_cycles={self._dpu_internals.num_cycles}&#34;
                            )

                            LOGGER.debug(
                                f&#34;FEE mode in register map: {n_fee_mode(self.register_map[&#39;ccd_mode_config&#39;]).name}&#34;
                            )

                            save_slicing_parameter(storage, origin_spw_data, self._dpu_internals.slicing_num_cycles)

                        if self._dpu_internals.is_end_of_cycle():

                            # When we are at the end of our requested num_cycles, go to DUMP mode

                            # FIXME: review if this is the right place and if the dump command will
                            #        be executed at the right moment, e.g. are there no commands on
                            #        the queue anymore?

                            if self._dpu_internals.num_cycles == 0:
                                if self._dpu_internals.dump_mode_int:
                                    dump_mode_command = command_set_dump_mode_int_sync
                                else:
                                    dump_mode_command = command_set_dump_mode
                                self._command_q.put((dump_mode_command, [], {&#39;response&#39;: False}))

                        # Then we might get data packets depending on the FEE mode -----------------

                        mode = hk_packet.type.mode
                        LOGGER.debug(f&#34;FEE mode in HK packet: {n_fee_mode(mode).name}&#34;)

                        data_attr = update_data_attributes(data_attr, self._n_fee_state.get_state())

                        with Timer(&#34;Read and process data packets&#34;):
                            read_and_process_data_packets(
                                self._transport, storage, origin_spw_data, start_time, mode,
                                self.register_map, data_attr, self._dpu_internals, dist_sock)

                    except NoBytesReceivedError as exc:
                        # LOGGER.debug(f&#34;No bytes received: {exc}&#34;)
                        pass
                    except NoTimeCodeError as exc:
                        LOGGER.warning(&#34;Reading the next timecode packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoTimecodeError:&#34;, exc_info=exc)
                    except NoHousekeepingPacketError as exc:
                        LOGGER.warning(&#34;Reading the next housekeeping packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoHousekeepingPacketError:&#34;, exc_info=exc)
                    except NoDataPacketError as exc:
                        LOGGER.warning(&#34;Reading the next data packet failed.&#34;)
                        LOGGER.debug(&#34;Traceback for NoDataPacketError:&#34;, exc_info=exc)
                    except TimecodeTimeoutError as exc:
                        # LOGGER.debug(&#34;Waiting for the next timecode.&#34;)
                        pass
                    except TimeExceededError as exc:
                        LOGGER.warning(
                            &#34;Time to retrieve data packets in this readout cycle exceeded &#34;
                            &#34;4.0 seconds.&#34;
                        )
                        LOGGER.debug(&#34;Traceback for TimeExceededError:&#34;, exc_info=exc)
                    # FIXME:
                    #   same here as above, make sure the DPU Processor doesn&#39;t crash. This last
                    #   catching also means that Commands on the Queue will still be executed if
                    #   there is an error. What needs to be checked here is that the Command should
                    #   probably be send in the &#39;save zone&#39; between 4.0s and 6.25s.
                    except Exception as exc:
                        LOGGER.error(exc, exc_info=True)
                        traceback.print_exc()

                    # LOGGER.info(
                    #     f&#34;Time past after reading all packets from FEE:&#34;
                    #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                    # )

                    # Process high priority commands

                    process_high_priority_commands(
                        self._priority_q, self._response_q,
                        self._n_fee_state.get_state(), self._dpu_internals, self.register_map)

                    # Then, we might want to send some RMAP commands -------------------------------

                    # When we are in the 2s RMAP window, send the commands.
                    # Waiting till 4s have passed is apparently not needed, commands can be sent as
                    # soon as no packets will be received anymore, even if the time elapsed is
                    # less than 4s.
                    # But the following two lines might be uncommented for testing purposes.

                    # while time.perf_counter() &lt; start_time + 4.0:
                    #     time.sleep(0.1)

                    try:
                        send_commands_to_n_fee(
                            self._transport, storage, origin_spw_data,
                            self.register_map, self._command_q, self._response_q,
                            self._dpu_internals
                        )
                    except NFEECommandError as exc:
                        # Error is already logged in the send_commands_to_n_fee() function
                        pass

                    # LOGGER.debug(
                    #     f&#34;Time past after sending commands to FEE:&#34;
                    #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                    # )

                    # Terminate the DPU Processor when the quit event flag has been set by the
                    # commanding protocol.

                    if self._quit_event.is_set() or self._killer.term_signal_received:
                        LOGGER.info(&#34;Quit event is set, terminating..&#34;)
                        break

            except (Exception,) as exc:
                LOGGER.critical(
                    &#34;A fatal error occurred in the DPU Processor, needs to be restarted!&#34;,
                    exc_info=exc
                )
                # re-raise the exception such that it will bubble up at a higher level.
                raise
            finally:
                LOGGER.debug(&#34;Unregistering from Storage Manager.&#34;)
                unregister_from_storage_manager(storage, origin_spw_data)

        mon_sock.close(linger=0)
        dist_sock.close(linger=0)
        # ctx.destroy()

    def quit(self):
        LOGGER.warning(&#34;Sending a Quit event to the DPU Processor.&#34;)
        self._quit_event.set()

    def initialise_register_map(self):

        # FIXME:
        #   The DPU Processor shall not crash, therefore we shall catch all Exceptions thrown.
        #   Log the exceptions as an error and continue here. It must be tested what the exact
        #   harm is when doing this and if we need some further action before proceeding.

        # The DPU Processor is only initialised properly after reading the full register from
        # the N-FEE. This can only be done within the time window we have for sending RMAP
        # commands. Therefore we need to make sure we are in a safe time window for sending
        # RMAP commands.

        LOGGER.info(&#39;Initialise Register Map from N-FEE&#39;)

        # First wait until a timecode is received

        while True:
            terminator, packet = self._transport.read_packet(timeout=200)
            if self._killer.term_signal_received:
                raise Abort(&#34;A SIGTERM signal was received for this process&#34;)
            if packet is None or len(packet) in (0, 1):
                continue
            if is_timecode(packet):
                break

        start_time = time.perf_counter()

        LOGGER.debug(f&#34;Timecode received {packet=}&#34;)

        while time.perf_counter() &lt; start_time + 4.2:
            terminator, packet = self._transport.read_packet(timeout=200)
            if packet is None:
                msg = f&#34;time passed {time.perf_counter() - start_time:0.3f}&#34;
            else:
                msg = packet[:10]
            LOGGER.debug(f&#34;Discarding packet: {msg}&#34;)

        LOGGER.info(f&#34;Time passed since last timecode {time.perf_counter() - start_time:0.3f}s&#34;)
        LOGGER.info(
            &#39;In safe time window for sending RMAP command, getting full register..&#39;
        )

        command_sync_register_map(self._transport, self.register_map)

        LOGGER.debug(self.register_map)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>multiprocessing.context.Process</li>
<li>multiprocessing.process.BaseProcess</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUProcessor.initialise_register_map"><code class="name flex">
<span>def <span class="ident">initialise_register_map</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialise_register_map(self):

    # FIXME:
    #   The DPU Processor shall not crash, therefore we shall catch all Exceptions thrown.
    #   Log the exceptions as an error and continue here. It must be tested what the exact
    #   harm is when doing this and if we need some further action before proceeding.

    # The DPU Processor is only initialised properly after reading the full register from
    # the N-FEE. This can only be done within the time window we have for sending RMAP
    # commands. Therefore we need to make sure we are in a safe time window for sending
    # RMAP commands.

    LOGGER.info(&#39;Initialise Register Map from N-FEE&#39;)

    # First wait until a timecode is received

    while True:
        terminator, packet = self._transport.read_packet(timeout=200)
        if self._killer.term_signal_received:
            raise Abort(&#34;A SIGTERM signal was received for this process&#34;)
        if packet is None or len(packet) in (0, 1):
            continue
        if is_timecode(packet):
            break

    start_time = time.perf_counter()

    LOGGER.debug(f&#34;Timecode received {packet=}&#34;)

    while time.perf_counter() &lt; start_time + 4.2:
        terminator, packet = self._transport.read_packet(timeout=200)
        if packet is None:
            msg = f&#34;time passed {time.perf_counter() - start_time:0.3f}&#34;
        else:
            msg = packet[:10]
        LOGGER.debug(f&#34;Discarding packet: {msg}&#34;)

    LOGGER.info(f&#34;Time passed since last timecode {time.perf_counter() - start_time:0.3f}s&#34;)
    LOGGER.info(
        &#39;In safe time window for sending RMAP command, getting full register..&#39;
    )

    command_sync_register_map(self._transport, self.register_map)

    LOGGER.debug(self.register_map)</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUProcessor.quit"><code class="name flex">
<span>def <span class="ident">quit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quit(self):
    LOGGER.warning(&#34;Sending a Quit event to the DPU Processor.&#34;)
    self._quit_event.set()</code></pre>
</details>
</dd>
<dt id="egse.dpu.DPUProcessor.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to be run in sub-process; can be overridden in sub-class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):

    self._dpu_internals = DPUInternals(
        num_cycles=-1,
        expected_last_packet_flags=[False, False, False, False],
        dump_mode=False,
        internal_sync=False,
        frame_number=-1,
        ccd_sides_enum=GlobalState.setup.camera.fee.ccd_sides.enum,
        sensor_sel_enum=GlobalState.setup.camera.fee.sensor_sel.enum,
    )

    # The DPU Processor runs in a different process and since ZeroMQ Sockets are not
    # thread/process safe, we have to recreate the ZeroMQHandler attached to the egse.logger
    # in this process.
    import egse.logger
    egse.logger.replace_zmq_handler()

    LOGGER.info(&#34;DPU Processor started.&#34;)

    self._killer = SignalCatcher()

    # Setup a SpaceWire connection with the FEE (Simulator) and
    # open a Storage proxy to save all the data packets.

    origin_spw_data = N_FEE_SETTINGS.ORIGIN_SPW_DATA
    origin_spw_data_type = DATA_TYPE[N_FEE_SETTINGS.ORIGIN_SPW_DATA_TYPE]

    ctx: zmq.Context = zmq.Context().instance()

    # Setup monitoring socket

    mon_sock: zmq.Socket = ctx.socket(zmq.PUB)
    endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.MONITORING_PORT)
    mon_sock.bind(endpoint)
    LOGGER.info(f&#34;DPU Processor sending monitoring sync signals to {endpoint}.&#34;)

    # Setup data distribution socket

    dist_sock: zmq.Socket = ctx.socket(zmq.PUB)
    endpoint = bind_address(&#34;tcp&#34;, DPU_PROCESSOR_SETTINGS.DATA_DISTRIBUTION_PORT)
    dist_sock.setsockopt(zmq.SNDHWM, 0)  # never block on sending msg
    dist_sock.bind(endpoint)

    LOGGER.info(f&#34;DPU Processor sending SpW data to {endpoint}.&#34;)

    with self._transport, StorageProxy() as storage, ConfigurationManagerProxy() as cm:
        LOGGER.info(&#34;SpaceWire Transport has been connected.&#34;)
        self._transport.configure()
        LOGGER.info(&#34;SpaceWire Transport has been configured.&#34;)

        LOGGER.info(f&#34;Register {origin_spw_data} to Storage&#34;)
        register_to_storage_manager(storage, origin_spw_data)

        # Before going into the wile-loop, read the full register from the N-FEE and initialise
        # the register map.

        try:
            self.initialise_register_map()
            save_register_map(self.register_map, storage, origin_spw_data, dist_sock)
            save_format_version(storage, origin_spw_data)
            save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
        except Abort:
            LOGGER.warning(&#34;The DPU Processor is aborting....&#34;)
            unregister_from_storage_manager(storage, origin_spw_data)
            LOGGER.info(f&#34;The DPU Processor unregistered {origin_spw_data} from the Storage.&#34;)
            return
        except Exception as exc:
            LOGGER.error(exc, exc_info=exc)

        # Initialise the N-FEE state from the register map

        self._n_fee_state.update_at_400ms(self.register_map)

        # Initialise the DPU internals from the N-FEE State

        self._dpu_internals.update(self._n_fee_state.get_state())

        LOGGER.debug(f&#34;{self._dpu_internals.dump_mode=}&#34;)
        LOGGER.debug(f&#34;{self._dpu_internals.internal_sync=}&#34;)
        LOGGER.debug(f&#34;{self._dpu_internals.expected_last_packet_flags=}&#34;)

        # Initialise the data attributes, they will be added as attributes to the data group
        # in the HDF5 file.

        data_attr = self._n_fee_state.get_state()._asdict()

        # Initialise the start_time. This is needed, because when a NoTimeCodeError occurs
        # the variable will not be initialised resulting in a critical error.

        start_time = time.perf_counter()

        try:
            LOGGER.info(&#34;Going into the while True loop...&#34;)
            while True:

                try:
                    # First two packets are a Timecode and a HK packet  ------------------------

                    tc_packet, timestamp, start_time = read_timecode(self._transport)

                    hk_packet, timestamp = read_hk_packet(self._transport)

                    self._dpu_internals.frame_number = hk_packet.type.frame_number
                    self._dpu_internals.clear_error_flags = True

                    # Create a new HDF5 file for each readout cycle ----------------------------

                    if self._dpu_internals.is_start_of_cycle():
                        with Timer(&#34;Creating a new data file&#34;):
                            new_spw_data_file(storage, self.register_map, origin_spw_data,
                                              origin_spw_data_type, mon_sock, dist_sock)
                            save_obsid(storage, origin_spw_data, cm.get_obsid().return_code)
                            save_num_cycles(storage, origin_spw_data, self._dpu_internals.num_cycles)

                    # Update the N-FEE state (FPGA) --------------------------------------------

                    if self._dpu_internals.is_400ms_pulse():
                        self._n_fee_state.update_at_400ms(self.register_map)
                    elif self._dpu_internals.is_200ms_pulse():
                        self._n_fee_state.update_at_200ms(self.register_map)
                    else:
                        pass  # we are entering the loop for the first time

                    # Update the DPU internals from the N-FEE state

                    self._dpu_internals.update(self._n_fee_state.get_state())

                    # Process and save the timecode and HK packet ------------------------------

                    process_timecode(tc_packet, timestamp, storage, origin_spw_data,
                                     self._dpu_internals.frame_number, mon_sock, dist_sock)

                    process_hk_packet(hk_packet, timestamp, storage, origin_spw_data,
                                      self._dpu_internals.frame_number, mon_sock, dist_sock)

                    process_high_priority_commands(self._priority_q, self._response_q,
                                                   self._n_fee_state.get_state(),
                                                   self._dpu_internals, self.register_map)

                    # On any new readout cycle (400ms pulse), update the state and the internals

                    # FIXME: Why is this test done here and not at the end of the while loop
                    #        when all data has been read?

                    if self._dpu_internals.is_400ms_pulse():

                        pickle_string = pickle.dumps(self._dpu_internals.num_cycles)
                        msg_id = MessageIdentifier.NUM_CYCLES.to_bytes(1, &#39;big&#39;)
                        num_cycles_msg = [msg_id, pickle_string]
                        dist_sock.send_multipart(num_cycles_msg)
                        mon_sock.send_multipart(num_cycles_msg)

                        # decrement num_cycles, this can go negative which is interpreted as
                        # not doing anything...

                        self._dpu_internals.num_cycles -= 1  # check issue #917 before changing this line

                        LOGGER.debug(
                            f&#34;HK: frame number={hk_packet.type.frame_number}, dump mode={self._dpu_internals.dump_mode}, num_cycles={self._dpu_internals.num_cycles}&#34;
                        )

                        LOGGER.debug(
                            f&#34;FEE mode in register map: {n_fee_mode(self.register_map[&#39;ccd_mode_config&#39;]).name}&#34;
                        )

                        save_slicing_parameter(storage, origin_spw_data, self._dpu_internals.slicing_num_cycles)

                    if self._dpu_internals.is_end_of_cycle():

                        # When we are at the end of our requested num_cycles, go to DUMP mode

                        # FIXME: review if this is the right place and if the dump command will
                        #        be executed at the right moment, e.g. are there no commands on
                        #        the queue anymore?

                        if self._dpu_internals.num_cycles == 0:
                            if self._dpu_internals.dump_mode_int:
                                dump_mode_command = command_set_dump_mode_int_sync
                            else:
                                dump_mode_command = command_set_dump_mode
                            self._command_q.put((dump_mode_command, [], {&#39;response&#39;: False}))

                    # Then we might get data packets depending on the FEE mode -----------------

                    mode = hk_packet.type.mode
                    LOGGER.debug(f&#34;FEE mode in HK packet: {n_fee_mode(mode).name}&#34;)

                    data_attr = update_data_attributes(data_attr, self._n_fee_state.get_state())

                    with Timer(&#34;Read and process data packets&#34;):
                        read_and_process_data_packets(
                            self._transport, storage, origin_spw_data, start_time, mode,
                            self.register_map, data_attr, self._dpu_internals, dist_sock)

                except NoBytesReceivedError as exc:
                    # LOGGER.debug(f&#34;No bytes received: {exc}&#34;)
                    pass
                except NoTimeCodeError as exc:
                    LOGGER.warning(&#34;Reading the next timecode packet failed.&#34;)
                    LOGGER.debug(&#34;Traceback for NoTimecodeError:&#34;, exc_info=exc)
                except NoHousekeepingPacketError as exc:
                    LOGGER.warning(&#34;Reading the next housekeeping packet failed.&#34;)
                    LOGGER.debug(&#34;Traceback for NoHousekeepingPacketError:&#34;, exc_info=exc)
                except NoDataPacketError as exc:
                    LOGGER.warning(&#34;Reading the next data packet failed.&#34;)
                    LOGGER.debug(&#34;Traceback for NoDataPacketError:&#34;, exc_info=exc)
                except TimecodeTimeoutError as exc:
                    # LOGGER.debug(&#34;Waiting for the next timecode.&#34;)
                    pass
                except TimeExceededError as exc:
                    LOGGER.warning(
                        &#34;Time to retrieve data packets in this readout cycle exceeded &#34;
                        &#34;4.0 seconds.&#34;
                    )
                    LOGGER.debug(&#34;Traceback for TimeExceededError:&#34;, exc_info=exc)
                # FIXME:
                #   same here as above, make sure the DPU Processor doesn&#39;t crash. This last
                #   catching also means that Commands on the Queue will still be executed if
                #   there is an error. What needs to be checked here is that the Command should
                #   probably be send in the &#39;save zone&#39; between 4.0s and 6.25s.
                except Exception as exc:
                    LOGGER.error(exc, exc_info=True)
                    traceback.print_exc()

                # LOGGER.info(
                #     f&#34;Time past after reading all packets from FEE:&#34;
                #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                # )

                # Process high priority commands

                process_high_priority_commands(
                    self._priority_q, self._response_q,
                    self._n_fee_state.get_state(), self._dpu_internals, self.register_map)

                # Then, we might want to send some RMAP commands -------------------------------

                # When we are in the 2s RMAP window, send the commands.
                # Waiting till 4s have passed is apparently not needed, commands can be sent as
                # soon as no packets will be received anymore, even if the time elapsed is
                # less than 4s.
                # But the following two lines might be uncommented for testing purposes.

                # while time.perf_counter() &lt; start_time + 4.0:
                #     time.sleep(0.1)

                try:
                    send_commands_to_n_fee(
                        self._transport, storage, origin_spw_data,
                        self.register_map, self._command_q, self._response_q,
                        self._dpu_internals
                    )
                except NFEECommandError as exc:
                    # Error is already logged in the send_commands_to_n_fee() function
                    pass

                # LOGGER.debug(
                #     f&#34;Time past after sending commands to FEE:&#34;
                #     f&#34; {time.perf_counter() - start_time:.3f}s&#34;
                # )

                # Terminate the DPU Processor when the quit event flag has been set by the
                # commanding protocol.

                if self._quit_event.is_set() or self._killer.term_signal_received:
                    LOGGER.info(&#34;Quit event is set, terminating..&#34;)
                    break

        except (Exception,) as exc:
            LOGGER.critical(
                &#34;A fatal error occurred in the DPU Processor, needs to be restarted!&#34;,
                exc_info=exc
            )
            # re-raise the exception such that it will bubble up at a higher level.
            raise
        finally:
            LOGGER.debug(&#34;Unregistering from Storage Manager.&#34;)
            unregister_from_storage_manager(storage, origin_spw_data)

    mon_sock.close(linger=0)
    dist_sock.close(linger=0)
    # ctx.destroy()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="egse.dpu.DPUProtocol"><code class="flex name class">
<span>class <span class="ident">DPUProtocol</span></span>
<span>(</span><span>control_server: <a title="egse.control.ControlServer" href="../control.html#egse.control.ControlServer">ControlServer</a>, transport: <a title="egse.spw.SpaceWireInterface" href="../spw.html#egse.spw.SpaceWireInterface">SpaceWireInterface</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>This class is the glue between the control servers and the hardware
controllers on one side, and between the control server and the connected
proxy classes on the other side.</p>
<p>The connection with the hardware controllers is when the <code>execute()</code> method
calls the <code>server_call()</code> method of the command class.</p>
<p>The connection with the proxy classes is when the <code>client_call()</code> method is added to the
interface of the Proxy subclass (by the <code>_add_commands()</code> method).</p>
<p>FIXME: Protocol is not used at the client side, i.e. the Proxy class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUProtocol(CommandProtocol):
    def __init__(self, control_server: ControlServer, transport: SpaceWireInterface):

        super().__init__()

        self.control_server = control_server

        # Set up two queue&#39;s to communicate with the DPU Processor Process.
        # The command queue is joinable because the Controller needs to wait for a response in
        # the response queue.

        self.command_queue = multiprocessing.Queue()
        self.response_queue = multiprocessing.Queue()
        self.priority_queue = multiprocessing.Queue()

        # Start a separate Process to handle FEE communication

        self.processor = DPUProcessor(
            transport, self.priority_queue, self.command_queue, self.response_queue)
        self.processor.name = &#34;dpu.processor&#34;
        self.processor.start()

        self.controller = DPUController(
            self.priority_queue, self.command_queue, self.response_queue)

        self.load_commands(COMMAND_SETTINGS.Commands, DPUCommand, DPUController)

        self.build_device_method_lookup_table(self.controller)

    def get_bind_address(self):
        return bind_address(
            self.control_server.get_communication_protocol(),
            self.control_server.get_commanding_port(),
        )

    def get_status(self) -&gt; dict:
        status = super().get_status()
        status[&#34;DPU Processor&#34;] = &#34;alive&#34; if self.processor.is_alive() else &#34;--&#34;
        return status

    def get_housekeeping(self) -&gt; dict:
        return {
            &#34;timestamp&#34;: format_datetime(),
        }

    def quit(self):
        self.processor.quit()

        def not_alive():
            return not self.processor.is_alive()

        if wait_until(not_alive, timeout=6.5) is False:
            self.processor.join()
            return

        LOGGER.warning(&#34;Terminating DPU Processor&#34;)
        self.processor.terminate()

        # Wait at least 6.25s which is the &#39;normal&#39; readout cycle time

        if wait_until(not_alive, timeout=6.5) is False:
            self.processor.join()
            return

        LOGGER.warning(&#34;Killing DPU Processor&#34;)
        self.processor.kill()
        self.processor.join()

    def is_alive(self) -&gt; bool:
        is_alive = self.processor.is_alive()

        if not is_alive:
            LOGGER.warning(
                f&#34;Process &#39;{self.processor.name}&#39; died for some reason, check for &#34;
                f&#34;an exception in the logging output.&#34;
            )

        return is_alive</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="egse.protocol.CommandProtocol" href="../protocol.html#egse.protocol.CommandProtocol">CommandProtocol</a></li>
<li><a title="egse.device.DeviceConnectionObserver" href="../device.html#egse.device.DeviceConnectionObserver">DeviceConnectionObserver</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="egse.protocol.CommandProtocol" href="../protocol.html#egse.protocol.CommandProtocol">CommandProtocol</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.protocol.CommandProtocol.bind" href="../protocol.html#egse.protocol.CommandProtocol.bind">bind</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.build_device_method_lookup_table" href="../protocol.html#egse.protocol.CommandProtocol.build_device_method_lookup_table">build_device_method_lookup_table</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.get_bind_address" href="../protocol.html#egse.protocol.CommandProtocol.get_bind_address">get_bind_address</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.get_housekeeping" href="../protocol.html#egse.protocol.CommandProtocol.get_housekeeping">get_housekeeping</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.get_status" href="../protocol.html#egse.protocol.CommandProtocol.get_status">get_status</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.handle_device_method" href="../protocol.html#egse.protocol.CommandProtocol.handle_device_method">handle_device_method</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.is_alive" href="../protocol.html#egse.protocol.CommandProtocol.is_alive">is_alive</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.load_commands" href="../protocol.html#egse.protocol.CommandProtocol.load_commands">load_commands</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.quit" href="../protocol.html#egse.protocol.CommandProtocol.quit">quit</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.receive" href="../protocol.html#egse.protocol.CommandProtocol.receive">receive</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.send" href="../protocol.html#egse.protocol.CommandProtocol.send">send</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.send_commands" href="../protocol.html#egse.protocol.CommandProtocol.send_commands">send_commands</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.state" href="../device.html#egse.device.DeviceConnectionObserver.state">state</a></code></li>
<li><code><a title="egse.protocol.CommandProtocol.update_connection_state" href="../device.html#egse.device.DeviceConnectionObserver.update_connection_state">update_connection_state</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="egse.dpu.DPUProxy"><code class="flex name class">
<span>class <span class="ident">DPUProxy</span></span>
<span>(</span><span>protocol='tcp', hostname='localhost', port=6600)</span>
</code></dt>
<dd>
<div class="desc"><p>The DPUProxy class is used to connect to the DPU Control Server and send commands to the FEE.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>protocol</code></strong></dt>
<dd>the transport protocol [default is taken from settings file]</dd>
<dt><strong><code>hostname</code></strong></dt>
<dd>location of the control server (IP address)
[default is taken from settings file]</dd>
<dt><strong><code>port</code></strong></dt>
<dd>TCP port on which the control server is listening for commands
[default is taken from settings file]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUProxy(Proxy, DPUInterface):
    &#34;&#34;&#34;
    The DPUProxy class is used to connect to the DPU Control Server and send commands to the FEE.
    &#34;&#34;&#34;

    def __init__(
        self,
        protocol=CTRL_SETTINGS.PROTOCOL,
        hostname=CTRL_SETTINGS.HOSTNAME,
        port=CTRL_SETTINGS.COMMANDING_PORT,
    ):
        &#34;&#34;&#34;
        Args:
            protocol: the transport protocol [default is taken from settings file]
            hostname: location of the control server (IP address)
                [default is taken from settings file]
            port: TCP port on which the control server is listening for commands
                [default is taken from settings file]
        &#34;&#34;&#34;
        super().__init__(connect_address(protocol, hostname, port), timeout=10_000)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="egse.proxy.Proxy" href="../proxy.html#egse.proxy.Proxy">Proxy</a></li>
<li><a title="egse.proxy.BaseProxy" href="../proxy.html#egse.proxy.BaseProxy">BaseProxy</a></li>
<li><a title="egse.proxy.ControlServerConnectionInterface" href="../proxy.html#egse.proxy.ControlServerConnectionInterface">ControlServerConnectionInterface</a></li>
<li><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="egse.proxy.Proxy" href="../proxy.html#egse.proxy.Proxy">Proxy</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.proxy.Proxy.connect_cs" href="../proxy.html#egse.proxy.ControlServerConnectionInterface.connect_cs">connect_cs</a></code></li>
<li><code><a title="egse.proxy.Proxy.disconnect_cs" href="../proxy.html#egse.proxy.ControlServerConnectionInterface.disconnect_cs">disconnect_cs</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_commanding_port" href="../proxy.html#egse.proxy.BaseProxy.get_commanding_port">get_commanding_port</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_commands" href="../proxy.html#egse.proxy.Proxy.get_commands">get_commands</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_endpoint" href="../proxy.html#egse.proxy.Proxy.get_endpoint">get_endpoint</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_ip_address" href="../proxy.html#egse.proxy.BaseProxy.get_ip_address">get_ip_address</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_monitoring_port" href="../proxy.html#egse.proxy.BaseProxy.get_monitoring_port">get_monitoring_port</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_service_port" href="../proxy.html#egse.proxy.BaseProxy.get_service_port">get_service_port</a></code></li>
<li><code><a title="egse.proxy.Proxy.get_service_proxy" href="../proxy.html#egse.proxy.BaseProxy.get_service_proxy">get_service_proxy</a></code></li>
<li><code><a title="egse.proxy.Proxy.has_commands" href="../proxy.html#egse.proxy.Proxy.has_commands">has_commands</a></code></li>
<li><code><a title="egse.proxy.Proxy.is_cs_connected" href="../proxy.html#egse.proxy.ControlServerConnectionInterface.is_cs_connected">is_cs_connected</a></code></li>
<li><code><a title="egse.proxy.Proxy.load_commands" href="../proxy.html#egse.proxy.Proxy.load_commands">load_commands</a></code></li>
<li><code><a title="egse.proxy.Proxy.reconnect_cs" href="../proxy.html#egse.proxy.ControlServerConnectionInterface.reconnect_cs">reconnect_cs</a></code></li>
<li><code><a title="egse.proxy.Proxy.reset_cs_connection" href="../proxy.html#egse.proxy.ControlServerConnectionInterface.reset_cs_connection">reset_cs_connection</a></code></li>
<li><code><a title="egse.proxy.Proxy.send" href="../proxy.html#egse.proxy.BaseProxy.send">send</a></code></li>
</ul>
</li>
<li><code><b><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.dpu.DPUInterface.get_register_map" href="#egse.dpu.DPUInterface.get_register_map">get_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_mode" href="#egse.dpu.DPUInterface.n_fee_get_mode">n_fee_get_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_sync_mode" href="#egse.dpu.DPUInterface.n_fee_get_sync_mode">n_fee_get_sync_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_high_precision_hk_mode" href="#egse.dpu.DPUInterface.n_fee_high_precision_hk_mode">n_fee_high_precision_hk_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_is_dump_mode" href="#egse.dpu.DPUInterface.n_fee_is_dump_mode">n_fee_is_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_reset" href="#egse.dpu.DPUInterface.n_fee_reset">n_fee_reset</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_clear_error_flags" href="#egse.dpu.DPUInterface.n_fee_set_clear_error_flags">n_fee_set_clear_error_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode">n_fee_set_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync">n_fee_set_dump_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_external_sync" href="#egse.dpu.DPUInterface.n_fee_set_external_sync">n_fee_set_external_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode">n_fee_set_full_image_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync">n_fee_set_full_image_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode">n_fee_set_full_image_pattern_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_immediate_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_immediate_on_mode">n_fee_set_immediate_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_internal_sync" href="#egse.dpu.DPUInterface.n_fee_set_internal_sync">n_fee_set_internal_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_on_mode">n_fee_set_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_register_value" href="#egse.dpu.DPUInterface.n_fee_set_register_value">n_fee_set_register_value</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_standby_mode" href="#egse.dpu.DPUInterface.n_fee_set_standby_mode">n_fee_set_standby_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_sync_register_map" href="#egse.dpu.DPUInterface.n_fee_sync_register_map">n_fee_sync_register_map</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="egse.dpu.DPUSimulator"><code class="flex name class">
<span>class <span class="ident">DPUSimulator</span></span>
</code></dt>
<dd>
<div class="desc"><p>This interface is for sending commands to the DPU Control Server. The commands are user
oriented and will be translated by the DPU Controller in proper FEE commands.</p>
<p>The interface should be implemented by the <code><a title="egse.dpu.DPUController" href="#egse.dpu.DPUController">DPUController</a></code> and the <code><a title="egse.dpu.DPUProxy" href="#egse.dpu.DPUProxy">DPUProxy</a></code> (and possibly
a <code><a title="egse.dpu.DPUSimulator" href="#egse.dpu.DPUSimulator">DPUSimulator</a></code> should we need that e.g. for testing purposes).</p>
<p>The command shall also be added to the <code>dpu.yaml</code> command definitions file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DPUSimulator(DPUInterface):
    # The DPUSimulator will stand by itself, which means it will not send commands to an FEE
    # nor will it request data or HK from the FEE. The methods in this implementation will return
    # a fake set of data.

    def n_fee_get_mode(self):
        return n_fee_mode.STAND_BY_MODE

    def n_fee_get_sync_mode(self):
        return NotImplemented

    def n_fee_set_on_mode(self):
        pass

    def n_fee_set_standby_mode(self):
        pass

    def n_fee_set_dump_mode(self, n_fee_parameters: dict):
        pass

    def n_fee_set_full_image_mode(self, n_fee_parameters):
        import pprint

        LOGGER.debug(f&#34;called: n_fee_set_full_image_mode({pprint.pformat(n_fee_parameters)})&#34;)

    def n_fee_set_full_image_mode_int_sync(self, n_fee_parameters):
        import pprint

        LOGGER.debug(f&#34;called: n_fee_set_full_image_mode_int_sync({pprint.pformat(n_fee_parameters)})&#34;)

    def n_fee_set_full_image_pattern_mode(self):
        pass

    def n_fee_high_precision_hk_mode(self, n_fee_parameters: dict):
        pass

    def n_fee_set_internal_sync(self, n_fee_parameters: dict):
        pass

    def n_fee_set_external_sync(self):
        pass

    def n_fee_set_clear_error_flags(self):
        pass

    def n_fee_set_fpga_defaults(self):
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="egse.dpu.DPUSimulator.n_fee_set_fpga_defaults"><code class="name flex">
<span>def <span class="ident">n_fee_set_fpga_defaults</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_fee_set_fpga_defaults(self):
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="egse.dpu.DPUInterface.get_register_map" href="#egse.dpu.DPUInterface.get_register_map">get_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_mode" href="#egse.dpu.DPUInterface.n_fee_get_mode">n_fee_get_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_sync_mode" href="#egse.dpu.DPUInterface.n_fee_get_sync_mode">n_fee_get_sync_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_high_precision_hk_mode" href="#egse.dpu.DPUInterface.n_fee_high_precision_hk_mode">n_fee_high_precision_hk_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_is_dump_mode" href="#egse.dpu.DPUInterface.n_fee_is_dump_mode">n_fee_is_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_reset" href="#egse.dpu.DPUInterface.n_fee_reset">n_fee_reset</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_clear_error_flags" href="#egse.dpu.DPUInterface.n_fee_set_clear_error_flags">n_fee_set_clear_error_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode">n_fee_set_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync">n_fee_set_dump_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_external_sync" href="#egse.dpu.DPUInterface.n_fee_set_external_sync">n_fee_set_external_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode">n_fee_set_full_image_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync">n_fee_set_full_image_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode">n_fee_set_full_image_pattern_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_immediate_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_immediate_on_mode">n_fee_set_immediate_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_internal_sync" href="#egse.dpu.DPUInterface.n_fee_set_internal_sync">n_fee_set_internal_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_on_mode">n_fee_set_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_register_value" href="#egse.dpu.DPUInterface.n_fee_set_register_value">n_fee_set_register_value</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_standby_mode" href="#egse.dpu.DPUInterface.n_fee_set_standby_mode">n_fee_set_standby_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_sync_register_map" href="#egse.dpu.DPUInterface.n_fee_sync_register_map">n_fee_sync_register_map</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="egse.dpu.NFEECommandError"><code class="flex name class">
<span>class <span class="ident">NFEECommandError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when sending a command to the N-FEE failed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NFEECommandError(Exception):
    &#34;&#34;&#34;Raised when sending a command to the N-FEE failed.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.NoBytesReceivedError"><code class="flex name class">
<span>class <span class="ident">NoBytesReceivedError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the zero or one bytes were received.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoBytesReceivedError(Exception):
    &#34;&#34;&#34;Raised when the zero or one bytes were received.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.NoDataPacketError"><code class="flex name class">
<span>class <span class="ident">NoDataPacketError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the expected data packet turns out to be something else.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoDataPacketError(Exception):
    &#34;&#34;&#34;Raised when the expected data packet turns out to be something else.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.NoHousekeepingPacketError"><code class="flex name class">
<span>class <span class="ident">NoHousekeepingPacketError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the expected Housekeeping packet turns out to be something else.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoHousekeepingPacketError(Exception):
    &#34;&#34;&#34;Raised when the expected Housekeeping packet turns out to be something else.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.NoTimeCodeError"><code class="flex name class">
<span>class <span class="ident">NoTimeCodeError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the expected Timecode packet turns out to be something else.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoTimeCodeError(Exception):
    &#34;&#34;&#34;Raised when the expected Timecode packet turns out to be something else.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.TimeExceededError"><code class="flex name class">
<span>class <span class="ident">TimeExceededError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when retrieving the data packets from the N-FEE takes too long.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TimeExceededError(Exception):
    &#34;&#34;&#34;Raised when retrieving the data packets from the N-FEE takes too long.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="egse.dpu.TimecodeTimeoutError"><code class="flex name class">
<span>class <span class="ident">TimecodeTimeoutError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Raised when the read_packet times out while waiting for a timecode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TimecodeTimeoutError(Exception):
    &#34;&#34;&#34;Raised when the read_packet times out while waiting for a timecode.&#34;&#34;&#34;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="egse" href="../index.html">egse</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="egse.dpu.ccd_ui" href="ccd_ui.html">egse.dpu.ccd_ui</a></code></li>
<li><code><a title="egse.dpu.dpu" href="dpu.html">egse.dpu.dpu</a></code></li>
<li><code><a title="egse.dpu.dpu_cs" href="dpu_cs.html">egse.dpu.dpu_cs</a></code></li>
<li><code><a title="egse.dpu.dpu_ui" href="dpu_ui.html">egse.dpu.dpu_ui</a></code></li>
<li><code><a title="egse.dpu.fitsgen" href="fitsgen.html">egse.dpu.fitsgen</a></code></li>
<li><code><a title="egse.dpu.fitsgen_test" href="fitsgen_test.html">egse.dpu.fitsgen_test</a></code></li>
<li><code><a title="egse.dpu.fitsgen_ui" href="fitsgen_ui.html">egse.dpu.fitsgen_ui</a></code></li>
<li><code><a title="egse.dpu.hdf5_model" href="hdf5_model.html">egse.dpu.hdf5_model</a></code></li>
<li><code><a title="egse.dpu.hdf5_ui" href="hdf5_ui.html">egse.dpu.hdf5_ui</a></code></li>
<li><code><a title="egse.dpu.hdf5_viewer" href="hdf5_viewer.html">egse.dpu.hdf5_viewer</a></code></li>
<li><code><a title="egse.dpu.hk_ui" href="hk_ui.html">egse.dpu.hk_ui</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="egse.dpu.create_expected_last_packet_flags" href="#egse.dpu.create_expected_last_packet_flags">create_expected_last_packet_flags</a></code></li>
<li><code><a title="egse.dpu.get_expected_last_packet_flags" href="#egse.dpu.get_expected_last_packet_flags">get_expected_last_packet_flags</a></code></li>
<li><code><a title="egse.dpu.get_index_for_last_packet_flags" href="#egse.dpu.get_index_for_last_packet_flags">get_index_for_last_packet_flags</a></code></li>
<li><code><a title="egse.dpu.got_all_last_packets" href="#egse.dpu.got_all_last_packets">got_all_last_packets</a></code></li>
<li><code><a title="egse.dpu.new_spw_data_file" href="#egse.dpu.new_spw_data_file">new_spw_data_file</a></code></li>
<li><code><a title="egse.dpu.process_high_priority_commands" href="#egse.dpu.process_high_priority_commands">process_high_priority_commands</a></code></li>
<li><code><a title="egse.dpu.process_hk_packet" href="#egse.dpu.process_hk_packet">process_hk_packet</a></code></li>
<li><code><a title="egse.dpu.process_timecode" href="#egse.dpu.process_timecode">process_timecode</a></code></li>
<li><code><a title="egse.dpu.read_and_process_data_packets" href="#egse.dpu.read_and_process_data_packets">read_and_process_data_packets</a></code></li>
<li><code><a title="egse.dpu.read_hk_packet" href="#egse.dpu.read_hk_packet">read_hk_packet</a></code></li>
<li><code><a title="egse.dpu.read_timecode" href="#egse.dpu.read_timecode">read_timecode</a></code></li>
<li><code><a title="egse.dpu.register_to_storage_manager" href="#egse.dpu.register_to_storage_manager">register_to_storage_manager</a></code></li>
<li><code><a title="egse.dpu.save_format_version" href="#egse.dpu.save_format_version">save_format_version</a></code></li>
<li><code><a title="egse.dpu.save_num_cycles" href="#egse.dpu.save_num_cycles">save_num_cycles</a></code></li>
<li><code><a title="egse.dpu.save_obsid" href="#egse.dpu.save_obsid">save_obsid</a></code></li>
<li><code><a title="egse.dpu.save_register_map" href="#egse.dpu.save_register_map">save_register_map</a></code></li>
<li><code><a title="egse.dpu.save_slicing_parameter" href="#egse.dpu.save_slicing_parameter">save_slicing_parameter</a></code></li>
<li><code><a title="egse.dpu.send_commands_to_n_fee" href="#egse.dpu.send_commands_to_n_fee">send_commands_to_n_fee</a></code></li>
<li><code><a title="egse.dpu.unregister_from_storage_manager" href="#egse.dpu.unregister_from_storage_manager">unregister_from_storage_manager</a></code></li>
<li><code><a title="egse.dpu.update_data_attributes" href="#egse.dpu.update_data_attributes">update_data_attributes</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="egse.dpu.DPUCommand" href="#egse.dpu.DPUCommand">DPUCommand</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.DPUController" href="#egse.dpu.DPUController">DPUController</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUController.get_slicing" href="#egse.dpu.DPUController.get_slicing">get_slicing</a></code></li>
<li><code><a title="egse.dpu.DPUController.is_simulator" href="#egse.dpu.DPUController.is_simulator">is_simulator</a></code></li>
<li><code><a title="egse.dpu.DPUController.marker" href="#egse.dpu.DPUController.marker">marker</a></code></li>
<li><code><a title="egse.dpu.DPUController.n_fee_set_charge_injection" href="#egse.dpu.DPUController.n_fee_set_charge_injection">n_fee_set_charge_injection</a></code></li>
<li><code><a title="egse.dpu.DPUController.n_fee_set_fpga_defaults" href="#egse.dpu.DPUController.n_fee_set_fpga_defaults">n_fee_set_fpga_defaults</a></code></li>
<li><code><a title="egse.dpu.DPUController.n_fee_set_reverse_clocking" href="#egse.dpu.DPUController.n_fee_set_reverse_clocking">n_fee_set_reverse_clocking</a></code></li>
<li><code><a title="egse.dpu.DPUController.n_fee_set_vgd" href="#egse.dpu.DPUController.n_fee_set_vgd">n_fee_set_vgd</a></code></li>
<li><code><a title="egse.dpu.DPUController.set_slicing" href="#egse.dpu.DPUController.set_slicing">set_slicing</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.DPUInterface" href="#egse.dpu.DPUInterface">DPUInterface</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUInterface.get_register_map" href="#egse.dpu.DPUInterface.get_register_map">get_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.get_slicing" href="#egse.dpu.DPUInterface.get_slicing">get_slicing</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.is_simulator" href="#egse.dpu.DPUInterface.is_simulator">is_simulator</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.marker" href="#egse.dpu.DPUInterface.marker">marker</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_mode" href="#egse.dpu.DPUInterface.n_fee_get_mode">n_fee_get_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_get_sync_mode" href="#egse.dpu.DPUInterface.n_fee_get_sync_mode">n_fee_get_sync_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_high_precision_hk_mode" href="#egse.dpu.DPUInterface.n_fee_high_precision_hk_mode">n_fee_high_precision_hk_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_is_dump_mode" href="#egse.dpu.DPUInterface.n_fee_is_dump_mode">n_fee_is_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_reset" href="#egse.dpu.DPUInterface.n_fee_reset">n_fee_reset</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_charge_injection" href="#egse.dpu.DPUInterface.n_fee_set_charge_injection">n_fee_set_charge_injection</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_clear_error_flags" href="#egse.dpu.DPUInterface.n_fee_set_clear_error_flags">n_fee_set_clear_error_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode">n_fee_set_dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_dump_mode_int_sync">n_fee_set_dump_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_external_sync" href="#egse.dpu.DPUInterface.n_fee_set_external_sync">n_fee_set_external_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_fpga_defaults" href="#egse.dpu.DPUInterface.n_fee_set_fpga_defaults">n_fee_set_fpga_defaults</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode">n_fee_set_full_image_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync" href="#egse.dpu.DPUInterface.n_fee_set_full_image_mode_int_sync">n_fee_set_full_image_mode_int_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode" href="#egse.dpu.DPUInterface.n_fee_set_full_image_pattern_mode">n_fee_set_full_image_pattern_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_immediate_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_immediate_on_mode">n_fee_set_immediate_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_internal_sync" href="#egse.dpu.DPUInterface.n_fee_set_internal_sync">n_fee_set_internal_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_on_mode" href="#egse.dpu.DPUInterface.n_fee_set_on_mode">n_fee_set_on_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_register_value" href="#egse.dpu.DPUInterface.n_fee_set_register_value">n_fee_set_register_value</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_reverse_clocking" href="#egse.dpu.DPUInterface.n_fee_set_reverse_clocking">n_fee_set_reverse_clocking</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_standby_mode" href="#egse.dpu.DPUInterface.n_fee_set_standby_mode">n_fee_set_standby_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_set_vgd" href="#egse.dpu.DPUInterface.n_fee_set_vgd">n_fee_set_vgd</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.n_fee_sync_register_map" href="#egse.dpu.DPUInterface.n_fee_sync_register_map">n_fee_sync_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUInterface.set_slicing" href="#egse.dpu.DPUInterface.set_slicing">set_slicing</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.DPUInternals" href="#egse.dpu.DPUInternals">DPUInternals</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUInternals.ccd_sides_enum" href="#egse.dpu.DPUInternals.ccd_sides_enum">ccd_sides_enum</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.clear_error_flags" href="#egse.dpu.DPUInternals.clear_error_flags">clear_error_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.dump_mode" href="#egse.dpu.DPUInternals.dump_mode">dump_mode</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.dump_mode_int" href="#egse.dpu.DPUInternals.dump_mode_int">dump_mode_int</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.expected_last_packet_flags" href="#egse.dpu.DPUInternals.expected_last_packet_flags">expected_last_packet_flags</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.frame_number" href="#egse.dpu.DPUInternals.frame_number">frame_number</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.internal_sync" href="#egse.dpu.DPUInternals.internal_sync">internal_sync</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.is_200ms_pulse" href="#egse.dpu.DPUInternals.is_200ms_pulse">is_200ms_pulse</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.is_400ms_pulse" href="#egse.dpu.DPUInternals.is_400ms_pulse">is_400ms_pulse</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.is_end_of_cycle" href="#egse.dpu.DPUInternals.is_end_of_cycle">is_end_of_cycle</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.is_start_of_cycle" href="#egse.dpu.DPUInternals.is_start_of_cycle">is_start_of_cycle</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.num_cycles" href="#egse.dpu.DPUInternals.num_cycles">num_cycles</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.sensor_sel_enum" href="#egse.dpu.DPUInternals.sensor_sel_enum">sensor_sel_enum</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.slicing_num_cycles" href="#egse.dpu.DPUInternals.slicing_num_cycles">slicing_num_cycles</a></code></li>
<li><code><a title="egse.dpu.DPUInternals.update" href="#egse.dpu.DPUInternals.update">update</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.DPUMonitoring" href="#egse.dpu.DPUMonitoring">DPUMonitoring</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUMonitoring.connect" href="#egse.dpu.DPUMonitoring.connect">connect</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.disconnect" href="#egse.dpu.DPUMonitoring.disconnect">disconnect</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.do" href="#egse.dpu.DPUMonitoring.do">do</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.monitor_all" href="#egse.dpu.DPUMonitoring.monitor_all">monitor_all</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.on_frame_number_do" href="#egse.dpu.DPUMonitoring.on_frame_number_do">on_frame_number_do</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.on_long_pulse_do" href="#egse.dpu.DPUMonitoring.on_long_pulse_do">on_long_pulse_do</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.subscribe" href="#egse.dpu.DPUMonitoring.subscribe">subscribe</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.unsubscribe" href="#egse.dpu.DPUMonitoring.unsubscribe">unsubscribe</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.unsubscribe_all" href="#egse.dpu.DPUMonitoring.unsubscribe_all">unsubscribe_all</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.wait_for_hdf5_filename" href="#egse.dpu.DPUMonitoring.wait_for_hdf5_filename">wait_for_hdf5_filename</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.wait_for_timecode" href="#egse.dpu.DPUMonitoring.wait_for_timecode">wait_for_timecode</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.wait_num_cycles" href="#egse.dpu.DPUMonitoring.wait_num_cycles">wait_num_cycles</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.wait_number_of_pulses" href="#egse.dpu.DPUMonitoring.wait_number_of_pulses">wait_number_of_pulses</a></code></li>
<li><code><a title="egse.dpu.DPUMonitoring.wait_until_synced_num_cycles_is_zero" href="#egse.dpu.DPUMonitoring.wait_until_synced_num_cycles_is_zero">wait_until_synced_num_cycles_is_zero</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.DPUProcessor" href="#egse.dpu.DPUProcessor">DPUProcessor</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUProcessor.initialise_register_map" href="#egse.dpu.DPUProcessor.initialise_register_map">initialise_register_map</a></code></li>
<li><code><a title="egse.dpu.DPUProcessor.quit" href="#egse.dpu.DPUProcessor.quit">quit</a></code></li>
<li><code><a title="egse.dpu.DPUProcessor.run" href="#egse.dpu.DPUProcessor.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.DPUProtocol" href="#egse.dpu.DPUProtocol">DPUProtocol</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.DPUProxy" href="#egse.dpu.DPUProxy">DPUProxy</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.DPUSimulator" href="#egse.dpu.DPUSimulator">DPUSimulator</a></code></h4>
<ul class="">
<li><code><a title="egse.dpu.DPUSimulator.n_fee_set_fpga_defaults" href="#egse.dpu.DPUSimulator.n_fee_set_fpga_defaults">n_fee_set_fpga_defaults</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="egse.dpu.NFEECommandError" href="#egse.dpu.NFEECommandError">NFEECommandError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.NoBytesReceivedError" href="#egse.dpu.NoBytesReceivedError">NoBytesReceivedError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.NoDataPacketError" href="#egse.dpu.NoDataPacketError">NoDataPacketError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.NoHousekeepingPacketError" href="#egse.dpu.NoHousekeepingPacketError">NoHousekeepingPacketError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.NoTimeCodeError" href="#egse.dpu.NoTimeCodeError">NoTimeCodeError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.TimeExceededError" href="#egse.dpu.TimeExceededError">TimeExceededError</a></code></h4>
</li>
<li>
<h4><code><a title="egse.dpu.TimecodeTimeoutError" href="#egse.dpu.TimecodeTimeoutError">TimecodeTimeoutError</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>