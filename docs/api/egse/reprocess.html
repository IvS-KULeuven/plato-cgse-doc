<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>egse.reprocess API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>egse.reprocess</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import glob
import logging
import os
from pathlib import Path

import numpy as np
import pandas as pd

from egse import h5
from egse.config import find_file
from egse.fee.n_fee_hk import ORIGIN as N_FEE_ORIGIN
from egse.fee.n_fee_hk import get_calibrated_nfee_supply_voltages, get_calibrated_temperatures
from egse.fee.n_fee_hk import read_hk_info as read_n_fee_hk_info
from egse.fee.nfee import HousekeepingData
from egse.fov import ORIGIN as FOV_ORIGIN
from egse.settings import Settings
from egse.setup import NavigableDict
from egse.spw import SpaceWirePacket
from egse.storage import HDF5
from egse.storage.persistence import CSV
from egse.synoptics import ORIGIN as SYN_ORIGIN
from egse.synoptics import read_hk_info as read_syn_info
from egse.tcs.tcs import ORIGIN as TCS_ORIGIN

LOGGER = logging.getLogger(__name__)


# def reprocess_campaign(od_start: str, od_end: str, data_dir: str = None):
#
#     data_dir = data_dir or os.environ.get(&#39;PLATO_DATA_STORAGE_LOCATION&#39;)
#
#     delta = timedelta(days=1)
#     date = datetime.strptime(od_start, &#34;%Y%m%d&#34;)
#     date_end = datetime.strptime(od_end, &#34;%Y-%m-%d&#34;)
#
#     # Re-process the daily N-FEE HK + synoptics
#     while date &lt;= date_end:
#
#         od = date.strftime(&#34;%Y%m%d&#34;)
#         reprocess_od(od, data_dir=data_dir)
#
#         date += delta
#
#
#     # Re-process the N-FEE-HK + synoptics for all observations
#
#     # Re-generate the FITS files for all observations


def reprocess_od(od: str, site: str, sensor_cal: NavigableDict, data_dir: str = None):
    &#34;&#34;&#34; Re-generate the N-FEE HK and synoptics for the given OD.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - sensor_cal: Calibration data for the N-FEE HK.
        - data_dir: Folder (with /daily and /obs sub-folders) in which all data is stored. If not specified,
                    the `PLATO_DATA_STORAGE_LOCATION` environment variable will be read out.
    &#34;&#34;&#34;

    data_dir = data_dir or os.environ.get(&#39;PLATO_DATA_STORAGE_LOCATION&#39;)
    day_dir = Path(f&#34;{data_dir}/daily/{od}&#34;)  # Sub-folder with the data for the given OD

    reprocess_daily_n_fee_hk(od, site, sensor_cal, day_dir)    # N-FEE HK
    reprocess_daily_synoptics(od, site, data_dir=data_dir)     # Synoptics


def reprocess_daily_n_fee_hk(od: str, site: str, sensor_cal: NavigableDict, day_dir: Path):
    &#34;&#34;&#34; Re-generate the N-FEE HK for the given OD.

    The procedure is as follows:
        - Read the N-FEE HK information from the TM dictionary.  This comprises the name conversion from the original
          name (used by the N-FEE itself and in the HDF5 files) to the conventional name starting with &#34;NFEE&#34;, and the
          calibration information for the supply voltages and temperatures.
        - Determine the filename for the N-FEE HK for the given OD. This will be used to throw away the old N-FEE HK
          and to store the new N-FEE HK.
        - Throw away the existing N-FEE HK file.
        - Determine the list of HDF5 filenames acquired during the given OD.
        - Determine the column names to use in the new N-FEE HK file and create a new N-FEE HK file with these.
        - Loop over all these HDF5 files.  For each of them, read the uncalibrated values and apply the calibration,
          according to the given calibration information.  Then append the raw and calibrated values to the N-FEE HK
          file.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - sensor_cal: Calibration data for the N-FEE HK.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    name_conversion, nfee_supply_voltage_cal = read_n_fee_hk_info()

    # Throw away the existing N-FEE HK
    # (Further on we will create a new N-FEE HK file with the same name)

    n_fee_hk_filename = str(find_file(f&#34;{od}_{site}_{N_FEE_ORIGIN}.csv&#34;, root=day_dir))     # TODO
    # os.remove(n_fee_hk_filename)     # TODO

    # Loop over all HDF5 files and extract the HK

    hdf5_filenames = glob.glob(str(day_dir / f&#34;*.{HDF5.extension}&#34;))

    column_names = [&#34;timestamp&#34;, *list(name_conversion.values())]
    with CSV(filename=n_fee_hk_filename, prep={&#34;column_names&#34;: column_names, &#34;mode&#34;: &#39;w&#39;}) as csv:

        for hdf5_filename in hdf5_filenames:

            with h5.get_file(hdf5_filename, mode=&#34;r&#34;) as hdf5_file:

                for group in h5.groups(hdf5_file):

                    # Read the HK from the HDF5 groups and rename them

                    if &#34;hk&#34; in group:

                        # Create a dictionary in which we will gather all the raw and calibrated data for the timestamp
                        # in the current group of the current HDF5 file

                        values = {&#34;timestamp&#34;: group[&#34;timecode&#34;].attrs[&#34;timestamp&#34;]}

                        hk_packet = SpaceWirePacket.create_packet(h5.get_data(group[&#34;hk&#34;])) # Fix for CCD numbering is incorporated here
                        hk_data = HousekeepingData(hk_packet.data)

                        for orig_name in hk_data:
                            try:
                                new_name = name_conversion[orig_name]
                                values[new_name] = hk_data[orig_name]
                            except KeyError:
                                print(orig_name)

                        # Apply the correct calibration

                        calibrated_supply_voltages = get_calibrated_nfee_supply_voltages(values, nfee_supply_voltage_cal)
                        values.update(calibrated_supply_voltages)
                        calibrated_temperatures = get_calibrated_temperatures(values, sensor_cal)
                        values.update(calibrated_temperatures)

                        # Store the new N-FEE HK

                        csv.create(values)


def reprocess_daily_synoptics(od: str, site: str, day_dir: Path):
    &#34;&#34;&#34; Re-generate the synoptics for the given OD.

    The procedure is as follows:
        - Read the synoptics information from the TM dictionary.  This comprises the name conversion from the original
          name (used by the contributing components) to the conventional name starting with &#34;GSYN&#34;.
        - Determine the filename for the synoptics for the given OD. This will be used to throw away the old synoptics
          and to store the new synoptics.
        - Throw away the existing synoptics file.
        - Determine from which HK files we need to fetch information (this is TH-specific).
        - Concatenate the HK from all these files, sorted according to the timestamp, and fill the gaps (the last real
          value before a gap is used);

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    syn_names, original_name_egse, original_name_th = read_syn_info()

    # Throw away the existing synoptics
    # (Further on we will create a synoptics file with the same name)

    synoptics_filename = str(find_file(f&#34;{od}_{site}_{SYN_ORIGIN}.csv&#34;, root=day_dir))     # TODO
    # os.remove(synoptics_filename)     # TODO

    syn_input_filenames = get_syn_input_filenames(od, site, day_dir)

    if len(syn_input_filenames) &gt; 0:

        # Concatenate the content of all contributing HK files

        concatenated_hk = pd.read_csv(syn_input_filenames[0])
        for syn_input_filename in syn_input_filenames[1:]:
            syn_input_file = pd.read_csv(syn_input_filename)
            concatenated_hk = concatenated_hk.append(syn_input_file)

        # Sort according to ascending timestamp

        concatenated_hk = concatenated_hk.sort_values(by=[&#39;timestamp&#39;])

        # Convert the HK names to synoptical names (starting with &#34;GSYN&#34;)

        concatenated_hk = concatenated_hk.rename(columns=original_name_egse)
        concatenated_hk = concatenated_hk.rename(columns=original_name_th)

        # Fill NaNs

        concatenated_hk = concatenated_hk.fillna(method=&#34;ffill&#34;)
        # concatenated_hk = concatenated_hk.fillna(method=&#34;bfill&#34;)    # This is only relevant for the first few seconds

        available_syn_names = np.delete(syn_names, np.where(syn_names == &#34;timestamp&#34;))
        missing_syn_names = np.array([])

        for syn_name in available_syn_names:
            if syn_name not in concatenated_hk:
                available_syn_names = np.delete(available_syn_names, np.where(available_syn_names == syn_name))
                missing_syn_names = np.append(missing_syn_names, syn_name)

        # For numerical columns, use the mean; for boolean columns, use any (unless they are all NaN)

        agg_dict = {syn_name: np.mean for syn_name in available_syn_names}

        def any_func(arr):
            if arr.isnull().values.all():
                return float(&#39;nan&#39;)
            return any(arr)

        agg_dict[&#34;GSYN_OGSE_LAMP_ON&#34;] = any_func
        agg_dict[&#34;GSYN_OGSE_LASER_ON&#34;] = any_func
        agg_dict[&#34;GSYN_OGSE_SHUTTER_OPEN&#34;] = any_func

        concatenated_hk = concatenated_hk.groupby(&#34;timestamp&#34;).agg(agg_dict)

        num_rows = len(concatenated_hk.index)
        for missing_syn_name in missing_syn_names:
            concatenated_hk[missing_syn_name] = [float(&#39;nan&#39;)] * num_rows

        syn_names_wo_timestamp = np.delete(syn_names, np.where(syn_names == &#34;timestamp&#34;))
        concatenated_hk.to_csv(synoptics_filename, columns=syn_names_wo_timestamp)


def get_syn_input_filenames(od: str, site: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at the given site.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    common_syn_input_filenames = [str(day_dir / f&#34;{od}_SRON_{N_FEE_ORIGIN}.{CSV.extension}&#34;),
                                  str(day_dir / f&#34;{od}_SRON_{FOV_ORIGIN}.{CSV.extension}&#34;),
                                  str(day_dir / f&#34;{od}_SRON_{TCS_ORIGIN}.{CSV.extension}&#34;)
                                  ]

    sitehash = {
        &#34;CSL&#34;:  csl_get_syn_input_filenames,
        &#34;IAS&#34;:  ias_get_syn_input_filenames,
        &#34;INTA&#34;: inta_get_syn_input_filenames,
        &#34;SRON&#34;: sron_get_syn_input_filenames,
    }

    th_syn_input_filenames = sitehash[site](od, day_dir)

    return [*common_syn_input_filenames, *th_syn_input_filenames]


def csl_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at CSL.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError


def sron_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at SRON.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    lampcontrol_origin = Settings.load(&#34;BeagleBone Lamp Control Server&#34;).STORAGE_MNEMONIC
    powermeter_origin = Settings.load(&#34;Thorlabs PM100 Control Server&#34;).STORAGE_MNEMONIC
    filterwheel_origin = Settings.load(&#34;Standa 8SMC5 Control Server&#34;).STORAGE_MNEMONIC
    shutter_origin = Settings.load(&#34;Thorlabs SC10 Control Server&#34;).STORAGE_MNEMONIC
    ag0_daq0_origin = Settings.load(&#34;Agilent 34970 Control Server&#34;).DAQ0[&#34;STORAGE_MNEMONIC&#34;]
    ag0_daq1_origin = Settings.load(&#34;Agilent 34970 Control Server&#34;).DAQ1[&#34;STORAGE_MNEMONIC&#34;]
    ag2_daq0_origin = Settings.load(&#34;Agilent 34972 Control Server&#34;).DAQ0[&#34;STORAGE_MNEMONIC&#34;]
    ag2_daq1_origin = Settings.load(&#34;Agilent 34972 Control Server&#34;).DAQ1[&#34;STORAGE_MNEMONIC&#34;]

    # For SRON: Fix the header for the Agilent HK (see #1856)
    repaired_dir = day_dir / &#34;..&#34; / &#34;..&#34; / &#34;..&#34; / &#34;plato-archive/plato-data-temp-corrected/daily&#34; / od

    return [str(day_dir / f&#34;{od}_SRON_{lampcontrol_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{powermeter_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{filterwheel_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{shutter_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{ag0_daq0_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{ag0_daq1_origin}.{CSV.extension}&#34;),
            str(repaired_dir / f&#34;{od}_SRON_{ag2_daq0_origin}.{CSV.extension}&#34;),
            str(repaired_dir / f&#34;{od}_SRON_{ag2_daq1_origin}.{CSV.extension}&#34;),
            ]


def ias_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at IAS.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError


def inta_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at INTA.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError


# def reprocess_obs(obsid: Union[str, int, ObservationIdentifier]):
#
#     # Determine where the files are supposed to be/go
#     # (we need to determine whether we used the TEST_LAB or TEST_LAB_SETUP naming convention)
#
#     obsid = obsid_from_storage(obsid)
#     data_dir = os.environ[&#34;PLATO_DATE_STORAGE_LOCATION&#34;]
#     obs_dir = f&#34;{data_dir}/obs/{obsid}&#34;
#
#     # Re-process N-FEE HK (temperature calibration)
#
#     n_fee_hk = str(find_file(f&#34;{obsid}_N-FEE-HK_*.csv&#34;, root=obs_dir))
#     reprocess_nfee_hk(n_fee_hk)
#
#     # Re-process synoptics HK
#
#     syn_hk = str(find_file(f&#34;{obsid}_SYN-HK_*.csv&#34;, root=obs_dir))
#     reprocess_synoptics(syn_hk)
#
#     # Re-process FITS files
#     # (delete existing FITS files first)
#
#     delete_fits_files(obsid)
#     reprocess_ccd_data(obsid, obs_dir)
#
# def get_timespan(obsid: str, obs_dir: str):
#
#     # TODO
#
# def delete_fits_files(obs_dir: str):
#
#     # Loop over all FITS files in the folder for the given obsid and remove them
#
#     fits_filenames = glob.glob(f&#34;{obs_dir}/*.fits&#34;)
#     for fits_filename in fits_filenames:
#         try:
#             os.remove(fits_filename)
#         except:
#             LOGGER.warning(f&#34;Error while deleting file {fits_filename}&#34;)
#
#
# def reprocess_ccd_data(obsid: str, obs_dir: str):
#
#     delete_fits_files(obsid)
#
#     fg = SubProcess(&#34;MyApp&#34;, [sys.executable, &#34;-m&#34;, &#34;egse.dpu.fitsgen&#34;, &#34;for-obsid&#34;, obsid])
#     fg.execute(detach_from_parent=True)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="egse.reprocess.csl_get_syn_input_filenames"><code class="name flex">
<span>def <span class="ident">csl_get_syn_input_filenames</span></span>(<span>od: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of HK files contributing to the synoptics for the given OD at CSL.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def csl_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at CSL.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.reprocess.get_syn_input_filenames"><code class="name flex">
<span>def <span class="ident">get_syn_input_filenames</span></span>(<span>od: str, site: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of HK files contributing to the synoptics for the given OD at the given site.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>site: Site ID (CSL/SRON/IAS/INTA).</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_syn_input_filenames(od: str, site: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at the given site.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    common_syn_input_filenames = [str(day_dir / f&#34;{od}_SRON_{N_FEE_ORIGIN}.{CSV.extension}&#34;),
                                  str(day_dir / f&#34;{od}_SRON_{FOV_ORIGIN}.{CSV.extension}&#34;),
                                  str(day_dir / f&#34;{od}_SRON_{TCS_ORIGIN}.{CSV.extension}&#34;)
                                  ]

    sitehash = {
        &#34;CSL&#34;:  csl_get_syn_input_filenames,
        &#34;IAS&#34;:  ias_get_syn_input_filenames,
        &#34;INTA&#34;: inta_get_syn_input_filenames,
        &#34;SRON&#34;: sron_get_syn_input_filenames,
    }

    th_syn_input_filenames = sitehash[site](od, day_dir)

    return [*common_syn_input_filenames, *th_syn_input_filenames]</code></pre>
</details>
</dd>
<dt id="egse.reprocess.ias_get_syn_input_filenames"><code class="name flex">
<span>def <span class="ident">ias_get_syn_input_filenames</span></span>(<span>od: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of HK files contributing to the synoptics for the given OD at IAS.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ias_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at IAS.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.reprocess.inta_get_syn_input_filenames"><code class="name flex">
<span>def <span class="ident">inta_get_syn_input_filenames</span></span>(<span>od: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of HK files contributing to the synoptics for the given OD at INTA.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inta_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at INTA.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="egse.reprocess.reprocess_daily_n_fee_hk"><code class="name flex">
<span>def <span class="ident">reprocess_daily_n_fee_hk</span></span>(<span>od: str, site: str, sensor_cal: egse.setup.NavigableDict, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Re-generate the N-FEE HK for the given OD.</p>
<p>The procedure is as follows:
- Read the N-FEE HK information from the TM dictionary.
This comprises the name conversion from the original
name (used by the N-FEE itself and in the HDF5 files) to the conventional name starting with "NFEE", and the
calibration information for the supply voltages and temperatures.
- Determine the filename for the N-FEE HK for the given OD. This will be used to throw away the old N-FEE HK
and to store the new N-FEE HK.
- Throw away the existing N-FEE HK file.
- Determine the list of HDF5 filenames acquired during the given OD.
- Determine the column names to use in the new N-FEE HK file and create a new N-FEE HK file with these.
- Loop over all these HDF5 files.
For each of them, read the uncalibrated values and apply the calibration,
according to the given calibration information.
Then append the raw and calibrated values to the N-FEE HK
file.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>site: Site ID (CSL/SRON/IAS/INTA).</li>
<li>sensor_cal: Calibration data for the N-FEE HK.</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reprocess_daily_n_fee_hk(od: str, site: str, sensor_cal: NavigableDict, day_dir: Path):
    &#34;&#34;&#34; Re-generate the N-FEE HK for the given OD.

    The procedure is as follows:
        - Read the N-FEE HK information from the TM dictionary.  This comprises the name conversion from the original
          name (used by the N-FEE itself and in the HDF5 files) to the conventional name starting with &#34;NFEE&#34;, and the
          calibration information for the supply voltages and temperatures.
        - Determine the filename for the N-FEE HK for the given OD. This will be used to throw away the old N-FEE HK
          and to store the new N-FEE HK.
        - Throw away the existing N-FEE HK file.
        - Determine the list of HDF5 filenames acquired during the given OD.
        - Determine the column names to use in the new N-FEE HK file and create a new N-FEE HK file with these.
        - Loop over all these HDF5 files.  For each of them, read the uncalibrated values and apply the calibration,
          according to the given calibration information.  Then append the raw and calibrated values to the N-FEE HK
          file.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - sensor_cal: Calibration data for the N-FEE HK.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    name_conversion, nfee_supply_voltage_cal = read_n_fee_hk_info()

    # Throw away the existing N-FEE HK
    # (Further on we will create a new N-FEE HK file with the same name)

    n_fee_hk_filename = str(find_file(f&#34;{od}_{site}_{N_FEE_ORIGIN}.csv&#34;, root=day_dir))     # TODO
    # os.remove(n_fee_hk_filename)     # TODO

    # Loop over all HDF5 files and extract the HK

    hdf5_filenames = glob.glob(str(day_dir / f&#34;*.{HDF5.extension}&#34;))

    column_names = [&#34;timestamp&#34;, *list(name_conversion.values())]
    with CSV(filename=n_fee_hk_filename, prep={&#34;column_names&#34;: column_names, &#34;mode&#34;: &#39;w&#39;}) as csv:

        for hdf5_filename in hdf5_filenames:

            with h5.get_file(hdf5_filename, mode=&#34;r&#34;) as hdf5_file:

                for group in h5.groups(hdf5_file):

                    # Read the HK from the HDF5 groups and rename them

                    if &#34;hk&#34; in group:

                        # Create a dictionary in which we will gather all the raw and calibrated data for the timestamp
                        # in the current group of the current HDF5 file

                        values = {&#34;timestamp&#34;: group[&#34;timecode&#34;].attrs[&#34;timestamp&#34;]}

                        hk_packet = SpaceWirePacket.create_packet(h5.get_data(group[&#34;hk&#34;])) # Fix for CCD numbering is incorporated here
                        hk_data = HousekeepingData(hk_packet.data)

                        for orig_name in hk_data:
                            try:
                                new_name = name_conversion[orig_name]
                                values[new_name] = hk_data[orig_name]
                            except KeyError:
                                print(orig_name)

                        # Apply the correct calibration

                        calibrated_supply_voltages = get_calibrated_nfee_supply_voltages(values, nfee_supply_voltage_cal)
                        values.update(calibrated_supply_voltages)
                        calibrated_temperatures = get_calibrated_temperatures(values, sensor_cal)
                        values.update(calibrated_temperatures)

                        # Store the new N-FEE HK

                        csv.create(values)</code></pre>
</details>
</dd>
<dt id="egse.reprocess.reprocess_daily_synoptics"><code class="name flex">
<span>def <span class="ident">reprocess_daily_synoptics</span></span>(<span>od: str, site: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Re-generate the synoptics for the given OD.</p>
<p>The procedure is as follows:
- Read the synoptics information from the TM dictionary.
This comprises the name conversion from the original
name (used by the contributing components) to the conventional name starting with "GSYN".
- Determine the filename for the synoptics for the given OD. This will be used to throw away the old synoptics
and to store the new synoptics.
- Throw away the existing synoptics file.
- Determine from which HK files we need to fetch information (this is TH-specific).
- Concatenate the HK from all these files, sorted according to the timestamp, and fill the gaps (the last real
value before a gap is used);</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>site: Site ID (CSL/SRON/IAS/INTA).</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reprocess_daily_synoptics(od: str, site: str, day_dir: Path):
    &#34;&#34;&#34; Re-generate the synoptics for the given OD.

    The procedure is as follows:
        - Read the synoptics information from the TM dictionary.  This comprises the name conversion from the original
          name (used by the contributing components) to the conventional name starting with &#34;GSYN&#34;.
        - Determine the filename for the synoptics for the given OD. This will be used to throw away the old synoptics
          and to store the new synoptics.
        - Throw away the existing synoptics file.
        - Determine from which HK files we need to fetch information (this is TH-specific).
        - Concatenate the HK from all these files, sorted according to the timestamp, and fill the gaps (the last real
          value before a gap is used);

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    syn_names, original_name_egse, original_name_th = read_syn_info()

    # Throw away the existing synoptics
    # (Further on we will create a synoptics file with the same name)

    synoptics_filename = str(find_file(f&#34;{od}_{site}_{SYN_ORIGIN}.csv&#34;, root=day_dir))     # TODO
    # os.remove(synoptics_filename)     # TODO

    syn_input_filenames = get_syn_input_filenames(od, site, day_dir)

    if len(syn_input_filenames) &gt; 0:

        # Concatenate the content of all contributing HK files

        concatenated_hk = pd.read_csv(syn_input_filenames[0])
        for syn_input_filename in syn_input_filenames[1:]:
            syn_input_file = pd.read_csv(syn_input_filename)
            concatenated_hk = concatenated_hk.append(syn_input_file)

        # Sort according to ascending timestamp

        concatenated_hk = concatenated_hk.sort_values(by=[&#39;timestamp&#39;])

        # Convert the HK names to synoptical names (starting with &#34;GSYN&#34;)

        concatenated_hk = concatenated_hk.rename(columns=original_name_egse)
        concatenated_hk = concatenated_hk.rename(columns=original_name_th)

        # Fill NaNs

        concatenated_hk = concatenated_hk.fillna(method=&#34;ffill&#34;)
        # concatenated_hk = concatenated_hk.fillna(method=&#34;bfill&#34;)    # This is only relevant for the first few seconds

        available_syn_names = np.delete(syn_names, np.where(syn_names == &#34;timestamp&#34;))
        missing_syn_names = np.array([])

        for syn_name in available_syn_names:
            if syn_name not in concatenated_hk:
                available_syn_names = np.delete(available_syn_names, np.where(available_syn_names == syn_name))
                missing_syn_names = np.append(missing_syn_names, syn_name)

        # For numerical columns, use the mean; for boolean columns, use any (unless they are all NaN)

        agg_dict = {syn_name: np.mean for syn_name in available_syn_names}

        def any_func(arr):
            if arr.isnull().values.all():
                return float(&#39;nan&#39;)
            return any(arr)

        agg_dict[&#34;GSYN_OGSE_LAMP_ON&#34;] = any_func
        agg_dict[&#34;GSYN_OGSE_LASER_ON&#34;] = any_func
        agg_dict[&#34;GSYN_OGSE_SHUTTER_OPEN&#34;] = any_func

        concatenated_hk = concatenated_hk.groupby(&#34;timestamp&#34;).agg(agg_dict)

        num_rows = len(concatenated_hk.index)
        for missing_syn_name in missing_syn_names:
            concatenated_hk[missing_syn_name] = [float(&#39;nan&#39;)] * num_rows

        syn_names_wo_timestamp = np.delete(syn_names, np.where(syn_names == &#34;timestamp&#34;))
        concatenated_hk.to_csv(synoptics_filename, columns=syn_names_wo_timestamp)</code></pre>
</details>
</dd>
<dt id="egse.reprocess.reprocess_od"><code class="name flex">
<span>def <span class="ident">reprocess_od</span></span>(<span>od: str, site: str, sensor_cal: egse.setup.NavigableDict, data_dir: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Re-generate the N-FEE HK and synoptics for the given OD.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>site: Site ID (CSL/SRON/IAS/INTA).</li>
<li>sensor_cal: Calibration data for the N-FEE HK.</li>
<li>data_dir: Folder (with /daily and /obs sub-folders) in which all data is stored. If not specified,
the <code>PLATO_DATA_STORAGE_LOCATION</code> environment variable will be read out.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reprocess_od(od: str, site: str, sensor_cal: NavigableDict, data_dir: str = None):
    &#34;&#34;&#34; Re-generate the N-FEE HK and synoptics for the given OD.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - site: Site ID (CSL/SRON/IAS/INTA).
        - sensor_cal: Calibration data for the N-FEE HK.
        - data_dir: Folder (with /daily and /obs sub-folders) in which all data is stored. If not specified,
                    the `PLATO_DATA_STORAGE_LOCATION` environment variable will be read out.
    &#34;&#34;&#34;

    data_dir = data_dir or os.environ.get(&#39;PLATO_DATA_STORAGE_LOCATION&#39;)
    day_dir = Path(f&#34;{data_dir}/daily/{od}&#34;)  # Sub-folder with the data for the given OD

    reprocess_daily_n_fee_hk(od, site, sensor_cal, day_dir)    # N-FEE HK
    reprocess_daily_synoptics(od, site, data_dir=data_dir)     # Synoptics</code></pre>
</details>
</dd>
<dt id="egse.reprocess.sron_get_syn_input_filenames"><code class="name flex">
<span>def <span class="ident">sron_get_syn_input_filenames</span></span>(<span>od: str, day_dir: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of HK files contributing to the synoptics for the given OD at SRON.</p>
<h2 id="args">Args</h2>
<ul>
<li>od: Observation day in the format YYYYMMDD.</li>
<li>day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sron_get_syn_input_filenames(od: str, day_dir: Path):
    &#34;&#34;&#34; Return list of HK files contributing to the synoptics for the given OD at SRON.

    Args:
        - od: Observation day in the format YYYYMMDD.
        - day_dir: Folder within the /daily directory in which the HK files are stored written for the given OD.
    &#34;&#34;&#34;

    lampcontrol_origin = Settings.load(&#34;BeagleBone Lamp Control Server&#34;).STORAGE_MNEMONIC
    powermeter_origin = Settings.load(&#34;Thorlabs PM100 Control Server&#34;).STORAGE_MNEMONIC
    filterwheel_origin = Settings.load(&#34;Standa 8SMC5 Control Server&#34;).STORAGE_MNEMONIC
    shutter_origin = Settings.load(&#34;Thorlabs SC10 Control Server&#34;).STORAGE_MNEMONIC
    ag0_daq0_origin = Settings.load(&#34;Agilent 34970 Control Server&#34;).DAQ0[&#34;STORAGE_MNEMONIC&#34;]
    ag0_daq1_origin = Settings.load(&#34;Agilent 34970 Control Server&#34;).DAQ1[&#34;STORAGE_MNEMONIC&#34;]
    ag2_daq0_origin = Settings.load(&#34;Agilent 34972 Control Server&#34;).DAQ0[&#34;STORAGE_MNEMONIC&#34;]
    ag2_daq1_origin = Settings.load(&#34;Agilent 34972 Control Server&#34;).DAQ1[&#34;STORAGE_MNEMONIC&#34;]

    # For SRON: Fix the header for the Agilent HK (see #1856)
    repaired_dir = day_dir / &#34;..&#34; / &#34;..&#34; / &#34;..&#34; / &#34;plato-archive/plato-data-temp-corrected/daily&#34; / od

    return [str(day_dir / f&#34;{od}_SRON_{lampcontrol_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{powermeter_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{filterwheel_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{shutter_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{ag0_daq0_origin}.{CSV.extension}&#34;),
            str(day_dir / f&#34;{od}_SRON_{ag0_daq1_origin}.{CSV.extension}&#34;),
            str(repaired_dir / f&#34;{od}_SRON_{ag2_daq0_origin}.{CSV.extension}&#34;),
            str(repaired_dir / f&#34;{od}_SRON_{ag2_daq1_origin}.{CSV.extension}&#34;),
            ]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="egse" href="index.html">egse</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="egse.reprocess.csl_get_syn_input_filenames" href="#egse.reprocess.csl_get_syn_input_filenames">csl_get_syn_input_filenames</a></code></li>
<li><code><a title="egse.reprocess.get_syn_input_filenames" href="#egse.reprocess.get_syn_input_filenames">get_syn_input_filenames</a></code></li>
<li><code><a title="egse.reprocess.ias_get_syn_input_filenames" href="#egse.reprocess.ias_get_syn_input_filenames">ias_get_syn_input_filenames</a></code></li>
<li><code><a title="egse.reprocess.inta_get_syn_input_filenames" href="#egse.reprocess.inta_get_syn_input_filenames">inta_get_syn_input_filenames</a></code></li>
<li><code><a title="egse.reprocess.reprocess_daily_n_fee_hk" href="#egse.reprocess.reprocess_daily_n_fee_hk">reprocess_daily_n_fee_hk</a></code></li>
<li><code><a title="egse.reprocess.reprocess_daily_synoptics" href="#egse.reprocess.reprocess_daily_synoptics">reprocess_daily_synoptics</a></code></li>
<li><code><a title="egse.reprocess.reprocess_od" href="#egse.reprocess.reprocess_od">reprocess_od</a></code></li>
<li><code><a title="egse.reprocess.sron_get_syn_input_filenames" href="#egse.reprocess.sron_get_syn_input_filenames">sron_get_syn_input_filenames</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>